\chapter{Теоретико-игровая модель биржевых торгов с дискретными ставками для рынка с
  двумя состояниями} \label{chapt1} 
{
%%% Chapter 1 commands
\newcommand{\generalGame}[2]{G_{#1}^m\left({#2}\right)}
\newcommand{\infiniteGame}[1]{G_{\infty}^m\left({#1}\right)}
\newcommand{\firstPlayerPayoff}[4]{K_{#1}^m\left({#2}, {#3}, {#4}\right)}
\newcommand{\infiniteFirstPlayerPayoff}[3]{K_{\infty}^m\left({#1}, {#2}, {#3}\right)}
\newcommand{\gameValue}[2]{V_{#1}^m\left({#2}\right)}
\newcommand{\infiniteGameValue}[1]{V_{\infty}^m\left({#1}\right)}
\newcommand{\symm}[1]{\overline{#1}}
\newcommand{\symmGameExpression}[2][\infty]{G_{#1}^{m, \DCo}\left({#2}\right)}
\newcommand{\upperBound}[1]{H_{\infty}^m\left({#1}\right)}
\newcommand{\fGeneral}[2][1]{\sigma_{#1}^{#2}}
\newcommand{\pEven}[1][k]{p^0_{#1}}
\newcommand{\pOdd}[1][k]{p^{\beta}_{#1}}
\newcommand{\fEven}[1][k]{\phi^0_{#1}}
\newcommand{\fOdd}[1][k]{\phi^{\beta}_{#1}}
\newcommand{\fOpt}{\sigma^*}
\newcommand{\lowerBound}[2][\infty]{L_{#1}^m\left({#2}\right)}

В разделе~\ref{ch1:intro} данной работы дано введение в теорию повторяющихся игр с неполной информацией, определены основные термины и понятия.
В разделе~\ref{ch1:model} приведено описание модели биржевых торгов с дискретными ставками, которая в разделе~\ref{ch1:formal-def} формализована в виде игры в нормальной форме.
Раздел~\ref{ch1:upper-bound} посвящен получению оценки сверху выигрыша инсайдера.
Оценка снизу выигрыша инсайдера найдена в разделе~\ref{ch1:lower-bound}.
В разделе~\ref{ch1:game-value} дана теорема о значении игры, исследована динамика апостериорных вероятностей при применении игроками оптимальных стратегий и проведено сравнение полученных результатов с результатами из~\cite{domansky07}.

Основные результаты данной главы опубликованы в работах~\cite{pyanykh14,pyanykh16:discr:ru} в журналах из перечня ВАК.

\section{Основные понятия}\label{ch1:intro}
Далее последует описание повторяющейся игры с неполной информацией, в которой множество состояний конечно, как и множества возможных действий игроков.
Теоретико-игровые постановки задач из глав~\ref{chapt2} и~\ref{chapt3} будут отличаться от данного классического описания, о чем будет сказано отдельно.

Рассмотрим антагонистическую игру двух лиц, которая повторяется $n$ раз, где $n\leq \infty$.
Будем считать, что первый игрок знает функцию выигрыша в данной игре, в то время как второй игрок такой информацией не обладает.
Однако второй игрок знает, что настоящая функция выигрыша является одной из $\kappa$ возможных альтернатив.
Каждой такой альтернативе второй игрок приписывает некоторую вероятность того, что данная функция выигрыша является истинной функцией выигрыша в рассматриваемой
игре.
Таким образом, априорные убеждения второго игрока задаются вероятностным вектором
\[
  \p = (p_1, p_2, \ldots, p_\kappa),\quad \sum_{i=1}^\kappa p_i = 1.
\]

С данными функциями выигрыша можно связать игры $G_1, G_2, \ldots, G_\kappa$.
В дальнейшем мы будем считать, что информационная неопределенность второго игрока заключается именно в том, что он не знает какая из игр $G_1, G_2, \ldots, G_\kappa$ разыгрывается.

На каждом шаге игры первый игрок может совершать действия из множества $I$, второй игрок --- действия из множества $J$, при этом мы считаем, что множества действий одного игрока известно другому.
Кроме того, положим, что второй игрок знает, что первый обладает точной информацией о том, какая именно игра разыгрывается, а первый игрок знает априорные убеждения второго.

\begin{figure}[t]
  \centering
  \input{figures/ch1-game-structure}
  \caption{Структура повторяющейся игры}
  \label{ch1:fig:game_structure}
\end{figure}

Игры $G_1, G_2, \ldots, G_\kappa$ будем называть \emph{одношаговыми играми}.
Все одношаговые игры описываются матрицами размера $|I| \times |J|$, где элементы матрицы задают выплаты первому игроку.
Мы предполагаем, что оба игрока точно знают платежные матрицы игр $G_1, G_2, \ldots, G_\kappa$.
На каждом шаге игры первый игрок выбирает номер строки, и одновременно с ним второй игрок выбирает номер столбца.
В конце каждого хода действия игроков оглашаются, и элемент из матрицы, отвечающей настоящей игре, прибавляется к выигрышу первого игрока и вычитается из выигрыша второго.
Таким образом, первый игрок знает свой выигрыш на каждом этапе игры, в то время как второй может лишь рассчитать свой ожидаемый выигрыш.
В завершение, мы считаем, что данное описание известно обоим игрокам.

Данная игра с неполной информацией описывается в виде игры в нормальной форме следующим образом.
Обозначим через $S = \{1, 2, \ldots, \kappa\}$ множество возможных альтернатив или \emph{состояний природы}.
Перед началом игры ходом случая в соответствии с вероятностным распределением $\po$ выбирается состояние $s \in S$.
Далее на протяжении $n$ шагов разыгрывается игра $G_s$.
Первый игрок информирован о результате хода случая, второй игрок "--- нет.
В остальном правила данной игры совпадают с описанными выше.

Пусть $h_t = \left((i_1, j_1), (i_2, j_2), \ldots, (i_t, j_t)\right)$ "--- история ходов после завершения шага $t$.
Множество все таких $h_t$ обозначим через $H_t$. 

Стратегией первого игрока в такой игре является последовательность ходов $\sigma = (\sigma_1, \sigma_2, \ldots, \sigma_n)$, где $\sigma_t = (\sigma^1_t, \sigma^2_t, \ldots, \sigma^\kappa_t)$, и $\sigma^s_t: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от предыдущих ходов, которую первый игрок использует если ходом случая реализовалось состояние $s$.

Аналогичным образом, определим стратегиею второго игрока как последовательность ходов $\tau = (\tau_1, \tau_2, \ldots, \tau_n)$, где $\tau_t: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от предыдущих ходов.
Как видно, ход второго игрока на каждом шаге игры зависит только от предыдущих ходов, и не зависит от состояния, в силу того, что второй игрок не информирован о результате хода случая.

Отметим, что, как показано в монографии Аумана, Машлера~\cite{aumann95}, достаточно рассматривать только стратегии, которые зависят только от предыдущих ходов первого игрока и не зависят от ходов второго.

Также нужно отметить, что в данной работе рассмотрены игры, в которых выигрыш равен суммарным выплатам, в отличие от постановки из \cite{aumann95}, в которых рассматривались игры с усредненными выплатами.

\section{Описание модели}\label{ch1:model}
Рассмотрим упрощенную модель финансового рынка, на котором два игрока ведут торговлю однотипными акциями на протяжении $n \leqslant \infty$ шагов, следуя работе~\cite{domansky07}.

Перед началом торгов случайный ход определяет цену акции на весь период торгов, которая может быть либо $m \in \N$ с вероятностью $p$, либо $0$ с вероятностью $1-p$.
Таким образом определенный ход случая является упрощенным аналогом некоторого шокового события на финансовом рынке.
Такого, например, как публикация отчетов о доходах некоторой компании.
Выбранная цена сообщается первому игроку и не сообщается второму, при этом второй игрок знает, что первый "--- инсайдер.

Рассмотрим $t$-й шаг торгов, где $t = \overline{1,n}$.
На данном шаге первый игрок выбирает ставку $i_t \in I = \{0, 1, \ldots, m\}$, а второй --- ставку $j_t \in J = \{0, 1, \ldots, m\}$.
Игрок предложивший б\'{о}льшую ставку покупает у другого акцию по цене равной
\[
  \Co \max(i_t, j_t) + \DCo \min(i_t, j_t),\ \text{где } %
  \Co \in (0, 1),\ \DCo = 1 - \Co.
\]
Если ставки равны, то сделка на $t$-м шаге не состоится.
Коэффициент $\Co$ можно интерпретировать как \emph{переговорную силу продавца} "--- чем ближе значение к $1$, тем большую сумму получит продавец акции в результате сделки.

Будем считать, что игроки обладают неограниченными запасами рисковых и безрисковых активов, т.е. торги не могут прекратиться по причине того, что у одного из игроков закончатся деньги или акции.
Цель игроков состоит в максимизации стоимости итогового портфеля, состоящего из некоторого числа купленных акций и суммы денег, полученных в результате торгов.
Таким образом, не ограничивая общности, можно положить, что в начальный момент времени оба игрока имеют нулевые портфели.

Фактически, в работах~\cite{domansky07, demeyer05}, а также в работах~\cite{domansky11, domansky13, domansky14}, посвященных обобщению дискретной модели, коэффициент $\Co = 1$.
Мотивацией к рассмотрению дискретной модели служит тот факт, что на реальных рынках расчеты ведутся пропорционально минимальной денежной единице.
При $\Co = 1$ все ставки будут целочисленными, как и финальные выплаты игрокам.
При рассмотрении модели с произвольным значением $\Co$ цена сделки перестает быть целочисленной, однако интерпретацию дискретности модели в этой постановке можно оставить неизменной, решив проблему нецелой финальной выплаты размера $a$ с помощью случайного механизма, который выберет либо выплату размера $[a]$, либо выплату размера $[a] + 1$.
Ожидаемый выигрыш при этом останется неизменным, но свойство дискретности сохранится.

\section{Определение игры $\mathbf{G^m_n(p)}$}\label{ch1:formal-def}

Определим формально повторяющуюся игру с неполной информацией, отвечающую данному выше описанию. 

Пусть множество состояний рынка $S = \{L, H\}$. Перед началом игры случай выбирает $s \in S $ с вероятностями $P(H) = p$ и $P(L) = 1 - p$.
После этого на протяжении $n \leq \infty$ шагов игроки участвуют в игре с матрицей $A^{s,\Co}$, где
\begin{equation*}
  A^{L,\Co}(i, j) = \begin{cases}
    \DCo i + \Co j, &\, i < j, \\
    0, &\, i = j, \\
    -\Co i - \DCo j, &\, i > j,
  \end{cases}
  \qquad
  A^{H,\Co}(i, j) = \begin{cases}
    \DCo i + \Co j - m, &\, i < j, \\
    0, &\, i = j, \\
    m - \Co i - \DCo j, &\, i > j.
  \end{cases}
\end{equation*}

Стратегией первого игрока в данной игре является последовательность ходов 
$\sigma = (\sigma_1, \sigma_2, \ldots, \sigma_t, \ldots)$, где 
$\sigma_t: S \times I^{t-1} \rightarrow \Delta(I)$.
Таким образом, на каждом шаге торгов первый игрок рандомизирует выбор ставки в зависимости от состояния и предыдущих ставок.
Как и в работе~\cite{domansky07}, мы ограничимся рассмотрением только тех стратегий $\sigma$, которые гарантируют первому игроку на каждом шаге игры неотрицательный выигрыш.
Множество таких стратегий первого игрока обозначим через $\Sigma$.

Аналогично стратегией второго игрока назовем последовательность ходов 
$\tau = (\tau_1, \tau_2, \ldots, \tau_t, \ldots),$ где 
$\tau_t: I^{t-1} \rightarrow \Delta(J)$.
Не имея информации о настоящем состоянии, второй игрок при выборе ставки опирается только на историю ставок инсайдера.
Множество стратегий второго игрока обозначим через $\Tau$.

Обозначим $\Pi[p, \sigma, \tau]$ вероятностное распределение на $(S, I^n, J^n)$ порожденное ходом случая и смешанными стратегиями $\sigma$ и $\tau$ игроков.
Также обозначим $\E_{\Pi[p,\sigma,\tau]}$ математическое ожидание по мере $\Pi[p, \sigma, \tau]$.

При применении первым игроком смешанной стратегии $\sigma$, а вторым игроком "--- смешанной стратегии $\tau$, ожидаемый выигрыш первого игрока
\begin{equation}
  \label{ch1:eq:firstPlayerPayoff}
  K^{m,\Co}_n(p, \sigma, \tau) = \E_{\Pi[p,\sigma,\tau]} \sum_{t=1}^n
  \left(
    pA^{H,\Co}(i_t^H, j_t) + (1 - p)A^{L,\Co}(i_t^L, j_t)
  \right).
\end{equation}

\begin{remark}
  В игре с произвольным значением $\Co$, в отличие от случая $\Co = 1$, стратегии, использующие ставку $m$, не являются доминируемыми.
  Проиллюстрировать это можно следующим образом.
  Пусть $\Co < 1$, цена акции равна $m$, и второй игрок делает ставку равную $m$.
  Тогда любая ставка $i < m$ будет давать первому игроку отрицательный выигрыш размера $\DCo (i - m)$, и только ставка $m$ даст первому игроку выигрыш равный нулю. 
\end{remark}

Полученную игру обозначим через $G^{m,\Co}_n(p)$. Ее верхнее и нижнее значения даются формулами
\begin{equation*}
  \underline{V}^{m,\Co}_n(p) = \sup_{\sigma \in \Sigma} \inf_{\tau \in \Tau}
  K^{m,\Co}_n(p, \sigma, \tau), \quad
  \overbar{V}^{m,\Co}_n(p) = \inf_{\tau \in \Tau} \sup_{\sigma \in \Sigma}
  K^{m,\Co}_n(p, \sigma, \tau).
\end{equation*}
Если верхнее и нижнее значения совпадают, то игра имеет значение, которое мы обозначим $V^{m,\Co}_n(p)$.

\begin{remark}
  В силу того, что игра $G^{m,\Co}_n(p)$ может быть представлена в виде матричной игры большой размерности, существование ее значения следует из основной теоремы матричных игр.
\end{remark}

Заметим, что имеют место следующие равенства:
\begin{equation*}
  A^{L,\Co}(i, j) = A^{H,\DCo}(m-i, m-j), \quad
  A^{H,\Co}(i, j) = A^{L,\DCo}(m-i, m-j).
\end{equation*}

\begin{remark}
  \label{ch1:rem:symm-payoffs}
  Определим для заданных стратегий $\sigma,\ \tau$ стратегии $\symm{\sigma}$ и $\symm{\tau}$ таким образом, что для $t$-го шага
  $\symm{\sigma_t} = (\symm{\sigma^H_t}, \symm{\sigma^L_t})$, где
  $\symm{\sigma^s_t}=(\sigma^s_{t,m},\ldots,\sigma^s_{t,0}) \in \Delta(I)$, и
  $\symm{\tau_t} = (\tau_{t,m},\ldots,\tau_{t,0}) \in \Delta(J)$.
  Легко видеть, что выигрыши игроков в играх $G^{m, \Co}_n(p)$ и $G^{m, 1-\Co}_n(1-p)$ при использовании, соответственно, стратегий $\sigma,\ \tau$ и $\symm{\sigma},\ \symm{\tau}$ совпадают.
\end{remark}

В дальнейшем мы часто будем опускать верхний индекс $\Co$.

\section{Оценка сверху выигрыша первого игрока.}\label{ch1:upper-bound}
Следуя \cite{domansky07}, рассмотрим чистую стратегию второго игрока $\tau^k, \, k \in J$:
\[
  \tau^k_1 = k, \quad \tau^k_t(i_{t-1}, j_{t-1}) = \begin{cases}
    j_{t-1} - 1, & \, i_{t-1} < j_{t-1}, \\
    j_{t-1},     & \, i_{t-1} = j_{t-1}, \\
    j_{t-1} + 1, & \, i_{t-1} > j_{t-1}.
  \end{cases}
\]
По сути, эта стратегия представляет собой стратегию подражания инсайдеру.
Доказательство следующего утверждения по форме повторяет доказательство утверждения 4.3 из \cite{domansky07} и приводится здесь в целях полноты изложения.

\begin{proposition}
  \label{ch1:prop:secondPlayerStrategyPayoffs}
  При применении стратегии $\tau^k$ в игре $\generalGame{n}{p}$ второй игрок гарантирует себе проигрыш не более
  \[
    h_n^L(\tau^k) = \sum_{t=0}^{n-1}(k - t - \DCo)^+, \quad h_n^H(\tau^k) =
    \sum_{t=0}^{n-1}(m - k - t - \Co)^+,
  \]
  в состояниях L и H соответственно.
\end{proposition}
\begin{proof}
  Проведем доказательство по индукции для $h^L_n(\tau^k)$.
  При $n=1$ справедливо
  \[
    h^L_1(\tau^k) = \max_{i \in I} A^L(i, k) = \max(0, k - \DCo) = (k - \DCo)^+.
  \]
  Пусть формула верна при $n \leq N$. Для $n=N+1$ оптимальный первый ход инсайдера использует ставку $\max(0, k - 1)$, что соответствует либо продаже
  акции по наибольшей цене в случае $k > 0$, либо отсутствию сделки. 
  Для случая $k > 0$ имеем
  \begin{gather*}
    h^L_{N+1}(\tau^k) = \DCo (k-1) + \Co k + h^L_N(\tau^{k-1}) =
    k - \DCo + \sum_{t=0}^{N-1}(k - 1 - t - \DCo)^+ = \\
    = k - \DCo + \sum_{t=1}^N(k-t-\DCo)^+ = \sum_{t=0}^N(k-t-\DCo)^+.
  \end{gather*}
  В случае $k = 0$ получаем
  \begin{gather*}
    h^L_{N+1}(\tau^k) = 0 = \sum_{t=0}^N(k-t-\DCo)^+.
  \end{gather*}
  Для $h^H_n(\tau^k)$ утверждение доказывается аналогично.
\end{proof}

Последовательности $\{h_n^L(\tau^k)\}$ и $\{h_n^H(\tau^k)\}$ не убывают и ограничены сверху по $n$.
Кроме того,
$h^s_m(\tau^k) = h^s_{m+1}(\tau^k) = h^s_{m+i}(\tau^k),\ i \in \N_+$.
Введем следующую функцию:
\begin{multline*}
  \upperBound{p} 
  = \min_{j \in J} \lim_{n \rightarrow \infty}\left(
    ph_n^H(\tau^j) + (1-p)h_n^L(\tau^j)
  \right) = \\
  %
  = \min_{j \in J} \frac{1}{2} \left[ p (m - j)(m - j + \DCo - \Co) + (1 - p)j(j + \Co
    - \DCo) \right] = \\
  = \min_{j \in J} \left[ j^2 + j(2\Co - 1 - 2 m p) + m p (1 + m - 2\Co) \right].
\end{multline*}

\begin{figure}[thb]
  \centering
  \input{figures/ch1-omega-x-p}
  \caption{Функция $\omega(x,p)$ при $p \in \{(k-\DCo)/m, (k+\Co)/m\}$}
  \label{ch1:fig:omega(x,p)}
\end{figure}

Функция $\omega(x, p) = x^2 + x(2\Co - 1 - 2mp)$ достигает минимума по $x$ в точке $m p - \Co + 1/2$.
Поэтому при $p \in \left( (k-\DCo)/m, (k+\Co)/m) \right]$ минимум функции $j^2 + j(2\Co - 1 - 2 m p)$ по $j \in J$ достигается при $j = k$ (\seename рис~\ref{ch1:fig:omega(x,p)}).

Таким образом, $\upperBound{p}$ является кусочно-линейной функцией, состоящей из $m~+~1$ линейных сегментов, и полностью определяется своими значениями в точках в следующих точках (\seename рис.~\ref{ch1:fig:Hm})
\begin{gather*}
  \upperBound{(k+\Co)/m} = \frac{1}{2} \left( (m - (k + \Co))(k + \Co) + \DCo\Co
  \right),\enskip
  k = \overline{0, m - 1},\\
  \upperBound{0} = \upperBound{1} = 0.
\end{gather*}

\begin{figure}[thb]
  \centering
  \begin{tikzpicture}[yscale=1.3,xscale=7]
    \draw[thick,->,>=stealth'] (-0.1,0) -- (1.1,0) node[right] {$p$};
    \draw[thick] (0,-0.1) -- (0,0.1);
    \node[anchor=north east] at (0,0) {$0$};
    \draw[thick] (1,-0.1) -- (1,0.1);
    \node[anchor=north west] at (1,0) {$1$};

    \draw[thick] plot file {plots/ch1-v0.75.dat};
    
    \draw[thick,dashed] (0.15, -0.1) -- (0.15, 3.2);
    \node[anchor=north] at (0.15, -0.1) {$\Co/m$};

    \draw[thick,dashed] (0.75, -0.1) -- (0.75, 3.2);
    \node[anchor=north] at (0.75, -0.1) {$(k+\Co)/m$};
    
    \node at (0.55, 2.6) {$V^\Co_ m(p)$};
  \end{tikzpicture}
  \caption{Графики функции $V^\Co_m(p)$}
  \label{ch1:fig:Hm}
\end{figure}

Пусть второй игрок при $p \in \left( (k-\DCo)/m, (k+\Co)/m) \right]$ применяет $\tau^k, \, k = \overline{0, m}$.
Обозначим эту стратегию через $\tau^*$.
Тогда справедлива следующая
\begin{lemma}
  \label{ch1:lemma:upperBound}
  При использовании вторым игроком стратегии $\tau^*$ в игре $\infiniteGame{p}$\textup{,} выигрыш первого игрока ограничен сверху функцией $\upperBound{p}$, т.е.
  \[
    \max_{\sigma \in \Sigma} \infiniteFirstPlayerPayoff{p}{\sigma}{\tau^*} \leq
    \upperBound{p}.
  \]
\end{lemma}

\section{Оценка снизу выигрыша первого игрока}\label{ch1:lower-bound}
Перейдем к описанию стратегии первого игрока, гарантирующей ему выигрыш не менее $\upperBound{p}$ в игре $\infiniteGame{p}$.

Пусть на первом шаге игры первый игрок применяет %
$\fGeneral{k} = \left(\fGeneral{H}, \fGeneral{L}\right)$, где %
$\fGeneral{H} = \left(\fGeneral[1,k]{H}, \fGeneral[1,k+1]{H}\right)$,
$\fGeneral{L} = \left(\fGeneral[1,k]{L}, \fGeneral[1,k+1]{L}\right)$ и
$\fGeneral[1,i]{s}$ -- вероятность сделать ставку $i$ в состоянии $s \in S$.
Применяя $\fGeneral{k}$, инсайдер делает ставки $k$ и $k+1$ с некоторыми заданными вероятностями.

Определим следующие параметры: полные вероятности использования действий $k$ и $k+1$, равные $q_k$ и $q_{k+1}$ соответственно, а также апостериорные вероятности $p(s|i)$ состояния $s$ при условии, что на предыдущем шаге первый игрок сделал ставку $i$.
Тогда вероятности $\fGeneral[1,i]{s}$ можно найти по формуле Байеса
\[
  \fGeneral[1,i]{s}~=~p(s|i)q_i/p(s), \: i = k, k + 1.
\]

\begin{proposition}
  \label{ch1:prop:stage-payoff}
  При использовании $\fGeneral{k}$ первый игрок гарантирует себе на первом шаге выигрыш
  \begin{equation}
    \label{ch1:eq:lowerPayoffGeneral}
    \firstPlayerPayoff{1}{p}{\fGeneral{k}}{j} =
    \begin{cases}
      mp - \Co k - \DCo j - \Co q_{k+1},      & \, j < k,     \\
      \left(m p(H|k+1) - k - \Co \right) q_{k+1}, & \, j = k,     \\
      \left(k + \Co - m p(H|k) \right) q_k,       & \, j = k + 1, \\
      \DCo k + \Co j - mp + \DCo q_{k+1}, & \, j > k + 1.
    \end{cases}
  \end{equation}
\end{proposition}
\begin{proof}
  Пусть $j < k$.
  Тогда из \eqref{ch1:eq:firstPlayerPayoff} и определения $\fGeneral{k}$ получаем
  \begin{align*}
    \firstPlayerPayoff{1}{p}{\fGeneral{k}}{j} &=
    p \left( 
      \fGeneral[1,k]{H} (m - \Co k - \DCo j) +
      \fGeneral[1,k+1]{H} (m - \Co (k+1) - \DCo j)
    \right) + \\
    &+ (1-p) \left( 
      \fGeneral[1,k]{L} (- \Co k - \DCo j) +
      \fGeneral[1,k+1]{L} (- \Co (k+1) - \DCo j)
    \right) = \\
    &=
    m p (\fGeneral[1,k]{H} + \fGeneral[1,k+1]{H}) -
    \left(
      p (\fGeneral[1,k]{H} + \fGeneral[1,k+1]{H}) +
      (1-p) (\fGeneral[1,k]{L} + \fGeneral[1,k+1]{L})
    \right) \times \\ 
    &\times (\Co k + \DCo j) -
    (p \fGeneral[1,k+1]{H} + (1-p) \fGeneral[1,k+1]{L}) \Co = \\
    &= mp - \Co k - \DCo j - \Co q_{k+1}.
  \end{align*}
  При $j = k$ имеет место равенство
  \begin{align*}
    \firstPlayerPayoff{1}{p}{\fGeneral{k}}{j} 
    &=
      p \fGeneral[1,k+1]{H} (m - \Co (k+1) - \DCo k) +
      (1-p) \fGeneral[1,k+1]{L} (- \Co (k+1) - \DCo k) = \\
    &= m p \fGeneral[1,k+1]{H} - 
      (p \fGeneral[1,k+1]{H} + (1-p) \fGeneral[1,k+1]{L}) (\Co (k+1) + \DCo k) =\\
    &= m p(H|k+1) q_{k+1} - q_{k+1} (\Co (k+1) + \DCo k) = \\
    &= (m p(H|k+1) - k - \Co) q_{k+1}.
  \end{align*}
  Случаи $j = k + 1$ и $j > k + 1$ разбираются аналогично.
\end{proof}

Построим оптимальную стратегию инсайдера. Рассмотрим на $[0,1]$ множество $P$ точек вида
\[
\pEven[i] = i/m, \, i = \overline{0, m}, \quad \pOdd[i] = (i + \Co)/m, \, i =
\overline{0, m - 1}.
\]

Для $p = \pEven,\ k = \overline{1, m-1}$ определим $\fEven$ как действие $\fGeneral{k}$ с параметрами
\begin{gather*}
  q_k = \Co, \quad p(H|k) = \pOdd[k-1],\\
  q_{k+1} = \DCo, \quad p(H|k + 1) = \pOdd[k].
\end{gather*}
Покомпонентно оно записывается как
\begin{gather*}
  \fGeneral[1,k]{H} = \frac{(k-\DCo)\Co}{k},\quad 
  \fGeneral[1,k+1]{H} = \frac{(k+\Co)\DCo}{k},\\
  \fGeneral[1,k]{L} = \frac{(m - k + \DCo)\Co}{m - k},\quad 
  \fGeneral[1,k+1]{L} = \frac{(m - k - \Co)\DCo}{m - k}.
\end{gather*}
Дополнительно определим $\fEven[0]$ как действие, состоящее в применении ставки $0$ с вероятностью $1$, а $\fEven[m]$ -- как действие, состоящее в применении ставки $m$ с вероятностью $1$.

Аналогично для $p = \pOdd,\ k = \overline{0, m-1}$ определим $\fOdd$ как действие $\fGeneral{k}$ с параметрами
\begin{gather*}
  q_k = \DCo, \quad p(H|k) = \pEven[k],\\
  q_{k+1} = \Co, \quad p(H|k + 1) = \pEven[k+1].
\end{gather*}
Покомпонентно оно записывается как
\begin{gather*}
  \fGeneral[1,k]{H} = \frac{k\DCo}{k + \Co},\quad 
  \fGeneral[1,k+1]{H} = \frac{(k+1)\Co}{k + \Co},\\
  \fGeneral[1,k]{L} = \frac{(m - k)\DCo}{m - k - \Co},\quad 
  \fGeneral[1,k+1]{L} = \frac{(m - k - 1)\Co}{m - k - \Co}.
\end{gather*}

\begin{proposition}
  \label{ch1:prop:K1-base}
  При $p \in P$ для значения $\firstPlayerPayoff{1}{p}{\sigma}{j}$ выигрыша первого игрока верны оценки
  \begin{equation}
    \label{ch1:eq:lowerBound:inequalities}
    \begin{gathered}
      \min_{j \in J}
      \firstPlayerPayoff{1}{\pEven}{\fEven}{j} \geq 0,\ k = \overline{0, m}, \\
      \min_{j \in J}
      \firstPlayerPayoff{1}{\pOdd}{\fOdd}{j} \geq \DCo\Co,\ k = \overline{0, m-1}.
    \end{gathered}
  \end{equation}
\end{proposition}
\begin{proof}
  Подставив полные вероятности действий и апостериорные вероятности состояний в \eqref{ch1:eq:firstPlayerPayoff}, получим для $p = \pOdd[k]$
  \begin{equation*}
    \firstPlayerPayoff{1}{\pOdd}{\fOdd}{j} = \begin{cases}
      k + \Co - \Co k - \DCo j - \Co^2 > \Co \DCo,\ & j < k,\\
      (k + 1 - k - \Co) \Co = \Co \DCo,\ & j = k,\\
      (k + \Co - k) \DCo = \Co \DCo,\ & j = k+1,\\
      \DCo k + \Co j - k - \Co + \Co \DCo > \Co \DCo,\ & j > k+1.
    \end{cases}
  \end{equation*}
  
  При $p = \pEven,\ k = \overline{1, m-1}$ получаем
  \begin{equation*}
    \firstPlayerPayoff{1}{\pEven}{\fEven}{j} = \begin{cases}
      k - \Co k - \DCo j - \Co \DCo \geq \DCo \DCo,\ & j < k,\\
      (k + \Co - k - \Co) \DCo = 0,\ & j = k,\\
      (k + \Co - k) \Co = \Co \Co,\ & j = k+1,\\
      \DCo k + \Co j - k - \Co + \DCo^2 \geq \Co + \DCo^2,\ & j > k+1.
    \end{cases}
  \end{equation*}

  Справедливость неравенства $\min_{j \in J} \firstPlayerPayoff{1}{\pEven}{\fEven}{j} \geq 0,\ k \in \{0, 1\}$, то есть, соответствующего $p \in \{0, 1\}$, очевидна.
\end{proof}

\begin{remark}
  \label{ch1:remark:posterior-probs}
  Если $p \in P$, то при применении инсайдером на первом шаге игры $\fEven$ и $\fOdd$, значения апостериорных вероятностей также принадлежат $P$.
  Таким образом, можно продолжить применение $\fEven$ и $\fOdd$ на последующих шагах игры, тем самым определив стратегию $\fOpt$ в игре $\generalGame{n}{p}$, при $p \in P, \, n \in \mathbb{N}$.
\end{remark}

Пусть $\lowerBound[n]{p}$ при $p \in P$ --- гарантированный выигрыш первого игрока в игре $\generalGame{n}{p}$ при применении стратегии $\fOpt$.

Следуя \cite{domansky07}, опишем рекурсивную структуру игры $\generalGame{n}{p}$.
Стратегию $\sigma$ первого игрока в $n$-шаговой игре можно представить как $(\sigma_1, \sigma(i),\ i \in I)$, где $\sigma_1$ "--- ход
первого игрока на первом шаге игры, а $\sigma(i)$ "--- стратегия в игре продолжительности $n-1$, зависящая от ставки $i$ на первом шаге.
Аналогично стратегию второго игрока можно представить как $(\tau_1, \tau(i),\ i \in I)$.
Тогда для функции выигрыша справедливо следующее представление
\begin{equation}
  \label{ch1:eq:recursive-structure}
  \firstPlayerPayoff{n}{p}{\sigma}{\tau} = 
  \firstPlayerPayoff{1}{p}{\sigma_1}{\tau_1} + 
  \sum_{i \in I} q(i) \firstPlayerPayoff{n-1}{p(H|i)}{\sigma(i)}{\tau(i)}.
\end{equation}

В силу неравенств (\ref{ch1:eq:lowerBound:inequalities}) и формулы \eqref{ch1:eq:recursive-structure} для максимального гарантированного выигрыша первого игрока в игре $\generalGame{n}{p}$ справедливы формулы
\begin{equation}
  \begin{gathered}
    \label{ch1:eq:lowerBound:recurrence:function}
    \lowerBound[n]{(k + \Co)/m} = \DCo\Co + \DCo\lowerBound[n-1]{k/m} +
    \Co\lowerBound[n-1]{(k + 1)/m}, \: k = \overline{0, m-1}, \\
    % 
    \lowerBound[n]{k/m} = \Co\lowerBound[n-1]{(k - 1 + \Co)/m} +
    \DCo\lowerBound[n-1]{(k + \Co)/m}, \: k = \overline{1, m-1}, \\
    % 
    \lowerBound[n]{0} = \lowerBound[n]{1} = 0.
  \end{gathered}
\end{equation}

Так как $\lowerBound[n]{p}$ не убывает по $n$ и ограничена сверху, то устремив $n$ к бесконечности, получим нижнюю оценку $\lowerBound{p}$ выигрыша первого игрока в игре $\infiniteGame{p}, \, p \in P$.

Введем следующие обозначения:
\begin{align*}
  L_{2k} = \lowerBound{k/m}, & \quad k = \overline{0, m},\\
  L_{2k+1} = \lowerBound{(k+\Co)/m)}, & \quad k = \overline{0, m-1}.
\end{align*}
Тогда справедливы формулы
\begin{equation}
  \label{ch1:eq:lowerRecurrence}
  \begin{gathered}
    L_{2k+1} = \DCo\Co + \DCo L_{2k} + \Co L_{2(k+1)}, \enskip k = \overline{0, m-1},\\
    L_{2k} = \Co L_{2k-1} + \DCo L_{2k+1}, \enskip k = \overline{1, m-1},\\
    L_0 = L_{2m} = 0.
  \end{gathered}
\end{equation}

Введем $(2m-1)\times(2m-1)$-матрицу $B$ и $(2m-1)$-вектор-столбец $b$:
\begin{equation*}
  B =
  \left(
    \begin{array}{cccccccc}
      1      & -\Co  & 0       & 0      & \cdots & 0      & 0       & 0       \\
      -\Co & 1       & -\DCo & 0      & \cdots & 0      & 0       & 0       \\
      0      & -\DCo & 1       & -\Co & \cdots & 0      & 0       & 0       \\
      \hdotsfor{8}                                                              \\
      0      & 0       & 0       & 0      & \cdots & -\Co & 1       & -\DCo \\
      0      & 0       & 0       & 0      & \cdots & 0      & -\DCo & 1 
    \end{array}
  \right),\quad
  %
  b = \left(
    \begin{array}{c}
      \DCo\Co \\
      0           \\
      \DCo\Co \\
      \cdots      \\
      0           \\
      \DCo\Co
    \end{array}
  \right).
\end{equation*}
Тогда (\ref{ch1:eq:lowerRecurrence}) перепишем в виде $ BL = b, L_0 = L_{2m} = 0, $ где $L = (L_1, L_2, \ldots, L_{2m-1})$.

Системы $ Mx = f $ с трехдиагональной матрицей $ M $, имеющей структуру
\[
  M = \left(\begin{array}{cccccccc}
              c_1 & b_1 & 0   & 0   & \cdots & 0       & 0       & 0       \\
              a_2 & c_2 & b_2 & 0   & \cdots & 0       & 0       & 0       \\
              0   & a_3 & c_3 & b_3 & \cdots & 0       & 0       & 0       \\
              \hdotsfor{8}                                                 \\
              0   & 0   & 0   & 0   & \cdots & a_{n-1} & c_{n-1} & b_{n-1} \\
              0   & 0   & 0   & 0   & \cdots & 0       & a_n     & c_n
            \end{array}\right),
\]
можно решать методом прогонки, используя следующие формулы для прогоночных коэффициентов и переменных (см. \cite{samarsky89}):
\begin{gather}
  \label{ch1:eq:tridiagonal-book}
  x_i = \gamma_{i+1} x_{i+1} + \delta_{i+1}, \: i = \overline{1,n-1},
  \quad
  x_n = \frac{f_n - a_n\delta_n}{c_n + a_n\gamma_n}, \\
  % 
  \gamma_{i+1} = -\frac{b_i}{c_i + a_i\gamma_i}, \: i = \overline{2,
    n-1}, \quad
  \gamma_2 = -\frac{b_1}{c_1}, \\
  % 
  \delta_{i+1} = \frac{f_i - a_i\delta_i}{c_i + a_i\gamma_i}, \: i =
  \overline{2, n-1}, \quad \delta_2 = \frac{f_1}{c_1}.
\end{gather}

\begin{proposition}
  \label{ch1:prop:tridiagonal:coefficients}
  Прогоночные коэффициенты для матрицы $B$ даются следующими формулами\textup{:}
  \begin{multline*}
    \gamma_{2k} = \frac{k-1+\Co}{k}, \,
    \gamma_{2k+1} = \frac{k}{k+\Co}, \\
    \delta_{2k} = \frac{\DCo(k-1+2\Co)}{2}, \, \delta_{2k+1} =
    \frac{k\Co(k-1+2\Co)}{2(k+\Co)}, \quad k = \overline{1,m-1}.
  \end{multline*}
\end{proposition}
\begin{proof}
  Проверим базу индукции для $\gamma_i,\ i = \overline{2, 2m-1}$.
  Имеем
  \begin{gather*}
    \gamma_2 = - \frac{-\Co}{1} = \Co,\\
    \gamma_3 = - \frac{-\DCo}{1 - \Co \cdot \Co} = \frac{1 - \Co}{(1 - \Co)(1 + \Co)} = \frac{1}{1 + \Co}.
  \end{gather*}
  Пусть утверждение верно для $\gamma_{2n}, \gamma_{2n+1}$ при $n \leq k$.
  Покажем, что соответствующие формулы имеют место при $n = k + 1$.
  Для $\gamma_{2(k+1)}$ имеем
  \begin{gather*}
    \gamma_{2(k+1)} =
    -\frac{b_{2k+1}}{c_{2k+1} + a_{2k+1} \gamma_{2k+1}} =
    \frac{\Co}{1 - \DCo k / (k+\Co)} = \frac{\Co (k + \Co)}{k + \Co - \DCo k} = \frac{k+\Co}{k + 1}.
  \end{gather*}
  Для $\gamma_{2k + 3}$ находим
  \begin{align*}
    \gamma_{2k+3} 
    &=
    - \frac{b_{2(k+1)}}{c_{2(k+1)} + a_{2(k+1)}\gamma_{2(k+1)}} = 
    \frac{\DCo}{1 - \Co (\Co + k)/(k+1)} = \\
    &= \frac{\DCo (k+1)}{k\DCo + \DCo(1+\Co)} =
    \frac{k + 1}{k + 1 + \Co}.
  \end{align*}
  Таким образом, утверждение доказано для $\gamma_i$.
  Проверим базу индукции для $\delta_i,\ i = \overline{2, 2m-1}$.
  Имеем
  \begin{gather*}
    \delta_2 = \frac{\Co \DCo}{1} = \frac{\DCo (1 - 1 + 2\Co)}{2},\\
    \delta_3 =
    \frac{f_2 - a_2 \delta_2}{c_2 + a_2 \gamma_2} =
    \frac{0 + \DCo \Co^2}{1 - \Co^2} =
    \frac{\Co^2}{1 + \Co} =
    \frac{1 \cdot \Co (1 - 1 + 2\Co)}{2(1+\Co)}.
  \end{gather*}
  Пусть утверждение верно для $\delta_{2n}, \delta_{2n+1}$ при $n \leq k$.
  Проверим справедливость соответствующих формул при $n = k+1$.
  Для $\delta_{2(k+1)}$ имеем
  \begin{align*}
    \delta_{2(k+1)} 
    &=
      \frac{f_{2k+1} - a_{2k+1}\delta_{2k+1}}{c_{2k+1} + a_{2k+1}\gamma_{2k+1}} =
      \frac{\DCo \Co + \DCo k\Co(k-1+2\Co)/(2(k+\Co))}{(k + \Co - \DCo k)/(k + \Co)} = \\
    &=
      \frac{\DCo \Co (k+\Co) + \DCo k \Co (k-1+2\Co)/2}{(k+1)\Co} =
      \frac{\DCo}{2(k+1)} \left( 
      2k + 2\Co + k^2 - k + 2 k \Co
      \right) = \\
    &=
      \frac{\DCo}{2(k+1)}\left(
      2\Co(k+1) + k(k+1)
      \right) =
      \frac{\DCo(k+2\Co)}{2}.
  \end{align*}
  Для $\delta_{2k+3}$ находим
  \begin{align*}
    \delta_{2k+3} 
    &=
      \frac{f_{2(k+1)} - a_{2(k+1)} \delta_{2(k+1)}}{c_{2(k+1)} + a_{2(k+1)}\gamma_{2(k+1)}} =
      \frac{0 + \Co \DCo (k + 2\Co)/2}{1 - \Co (\Co + k)/(k+1)} = \\
    &=
      \frac{\DCo \Co (k+2\Co)(k+1)}{2(k\DCo + \DCo(1+\Co))} =
      \frac{(k+1)\Co(k+2\Co)}{2(k+1+\Co)}.
  \end{align*}
  Таким образом, соответствующие формулы справедливы для $\delta_i$.
\end{proof}

\begin{proposition}
  \label{ch1:prop:lower:recurrence-solution}
  Решение системы {\normalfont(\ref{ch1:eq:lowerRecurrence})} дается
  следующими формулами\textup{:}
  \begin{gather}
    \label{ch1:eq:recurrence-solution:odd}
    L_{2k+1} = ((m - k - \Co)(k + \Co) + \DCo\Co)/2, \quad k = \overline{0, m-1},\\
    \label{ch1:eq:recurrence-solution:even}
    L_{2k} = k (m-k)/2, \quad k = \overline{0, m}.
  \end{gather}
\end{proposition}
\begin{proof}
  Из \eqref{ch1:eq:tridiagonal-book} следует, что
  \begin{equation*}
    L_{2k-1} = \gamma_{2k}\gamma_{2k+1}L_{2k+1} + \gamma_{2k}\delta_{2k+1} + \delta_{2k}, \, k = \overline{1, m-1}.
  \end{equation*}
  Покажем, что подстановкой $\upperBound{(k+\Co)/m}$ вместо $L_{2k+1}$ это равенство обращается в тождество.
  Для первого слагаемого имеем
  \begin{align*}
    &2 \gamma_{2k} \gamma_{2k+1} \upperBound{(k+\Co)/m} =
      \frac{k-1+\Co}{k+\Co} ((m-k-\Co)(k+\Co) + \DCo \Co) = \\
    &=
      (m-k-\Co)(k-1+\Co) + \DCo \Co - \frac{\DCo\Co}{k+\Co} = \\
    &=
      (m-(k-1+\Co))(k-1+\Co) - (k-1+\Co) + \DCo \Co - \frac{\DCo\Co}{k+\Co}.
  \end{align*}
  Для второго слагаемого находим
  \begin{align*}
    &2(\gamma_{2k} \delta_{2k+1} + \delta_{2k}) 
    = \frac{(k-1+\Co)\Co(k-1+2\Co)}{k+\Co} + \DCo(k-1+2\Co) = \\
    &= \Co (k-1+2\Co) - \frac{\Co (k-1+2\Co)}{k+\Co} + \DCo (k-1+2\Co) = \\
    &= k - 1 + 2\Co - \frac{\Co(k+\Co-\DCo)}{k+\Co} = (k-1+\Co) + \frac{\DCo\Co}{k+\Co}.
  \end{align*}
  Отсюда получаем
  \begin{align*}
    &\gamma_{2k} \gamma_{2k+1} \upperBound{(k+\Co)/m} + \gamma_{2k} \delta_{2k+1} + \delta_{2k} = \\
    &= \frac{1}{2}\biggl(
    (m-(k-1+\Co))(k-1+\Co) -
    (k-1+\Co) + \DCo \Co - \frac{\DCo\Co}{k+\Co} + \\
    &+ (k-1+\Co) + \frac{\DCo\Co}{k+\Co}
    \biggr) =
    \frac{1}{2} \left(
    (m-(k-1+\Co))(k-1+\Co) + \DCo\Co
    \right) =\\
    &= \upperBound{(k-1+\Co)/m}.
  \end{align*}
  Справедливость \eqref{ch1:eq:recurrence-solution:odd} установлена.
  Далее, имеем
  \begin{align*}
    2 \upperBound{(k-1+\Co)/m} 
    &= (m-k-\Co+1)(k-1+\Co) = \\
    &= (m-k-\Co)(k+\Co) - m + 2k + \Co - \DCo.
  \end{align*}
  Отсюда получаем
  \begin{align*}
    2 L_{2k} 
    &= 2 (\Co L_{2k-1} + \DCo L_{2k+1}) = (m-k-\Co)(k+\Co) + \Co \DCo - \Co (m - 2k - \Co + \DCo) = \\
    &= (m-k)k + \Co(m-2k-\Co+\DCo) - \Co(m-2k-\Co+\DCo) = (m-k)k.
  \end{align*}
  Таким образом, установлена справедливость \eqref{ch1:eq:recurrence-solution:even}.
\end{proof}

Итак, мы определили функцию $\lowerBound{p}$ при $p \in P$.
Для $p \in [0, 1] \setminus P$ стратегия инсайдера основана на применении выпуклой комбинации стратегий для крайних точек интервала, в котором находится $p$.

Для $p = \lambda \pOdd + (1-\lambda) \pEven[k+1],\ \lambda \in (0, 1)$ обозначим через $\lambda\fOdd[k] + (1-\lambda)\fEven[k+1]$ распределение, при котором первый игрок рандомизирует выбор ставок $k, k+1, k+2$ с параметрами
\begin{align*}
  q_k = \lambda\DCo, &\quad p(H|k) = \pEven,\\
  q_{k+1} = \Co, &\quad p(H|k+1) = \lambda \pEven[k+1] + (1-\lambda) \pOdd,\\
  q_{k+2} = (1-\lambda)\DCo, &\quad p(H|k+2) = \pOdd[k+1].
\end{align*}

Для $p = \lambda \pEven + (1-\lambda) \pOdd,\ \lambda \in (0, 1)$ через $\lambda\fEven + (1-\lambda)\fOdd$ обозначим распределение, при котором первый игрок рандомизирует выбор ставок $k$ и $k+1$ с параметрами
\begin{gather*}
  q_k = \lambda\Co + (1-\lambda)(1-\Co),\enskip
  p(H|k) = \frac{\lambda\Co}{q_k}\pOdd[k-1] + \frac{(1-\lambda)(1-\Co)}{q_k} \pEven,\\
  q_{k+1} = \lambda(1-\Co) + (1-\lambda)\Co,\enskip
  p(H|k+1) = \frac{\lambda(1-\Co)}{q_{k+1}}\pOdd[k] + \frac{(1-\lambda)\Co}{q_{k+1}}\pEven[k+1].
\end{gather*}

\begin{proposition}
  \label{ch1:prop:first:combination:step}
  При $\lambda \in (0, 1), \, k = \overline{0, m-1},$ для значения одношагового выигрыша первого игрока верны оценки
  \begin{align*}
    \min_{j \in J}
    \firstPlayerPayoff{1}{%
    \lambda \pEven + (1-\lambda) \pOdd}{%
    \lambda \fEven + (1-\lambda) \fOdd}{%
    j}
    &\geq \DCo \Co (1-\lambda), \\
    % 
    \min_{j \in J}
    \firstPlayerPayoff{1}{%
    \lambda \pOdd + (1-\lambda) \pEven[k+1]}{%
    \lambda \fOdd + (1-\lambda) \fEven[k+1]}{%
    j}
    &\geq \DCo \Co \lambda.
  \end{align*}
\end{proposition}
\begin{proof}
  Из \eqref{ch1:eq:firstPlayerPayoff} находим, что для произвольной одношаговой стратегии $\sigma$ с параметрами $(q_i, p(H|i),\ i \in I)$ выполняется
  \begin{align*}
    \firstPlayerPayoff{1}{p}{\sigma}{j} 
    &= \sum_{i \in I} p \sigma^H_i A^H(i, j) + (1-p) \sigma^L_i A^L(i, j) = \\
    &= \sum_{i \in I} q_i (p(H | i) a^H(i, j) + (1-p(H | i)) a^L(i, j)).
  \end{align*}
  
  Далее, пусть априорной вероятности $p_1 \in [0, 1]$ отвечает одношаговая стратегий $\sigma^1$ с параметрами $(q^1_i, p^1(H|i),\ i \in I)$, а априорной вероятности $p_2 \in [0, 1]$, отвечает стратегия $\sigma^2$ с параметрами $(q^2_i, p^2(H|i),\ i \in I)$.
  Определим для $p = \lambda p_1 + (1-\lambda) p_2$ одношаговую стратегию $\sigma^c$ с параметрами
  \begin{equation*}
    q^c_i = \lambda q^1_i + (1-\lambda) q^2_i, \enskip
    p^c(H|i) = \frac{\lambda q^1_i p^1(H|i) + (1-\lambda) q^2_i p^2(H|i)}{q^c_i}.
  \end{equation*}
  Одношаговый выигрыш при применении такой стратегии в игре с априорной вероятностью $p = \lambda p_1 + (1-\lambda) p_2$ равен
  \begin{multline*}
    K^m_1(\lambda p_1 + (1-\lambda) p_2, \sigma^c, j) = \sum_{i \in I} q^c_i \biggl(
     \frac{\lambda q^1_i p^1(H|i) + (1-\lambda) q^2_i p^2(H|i)}{q^c_i} a^H(i, j) + \\
    + \frac{\lambda q^1_i (1-p^1(H|i)) + (1-\lambda) q^2_i (1-p^2(H|i))}{q^c_i} a^L(i, j)
     \biggr) = \\
    = \lambda \sum_{i \in I} q^1_i (p^1(H|i) a^H(i, j) + (1-p^1(H|i)) a^L(i, j)) + \\
    + (1-\lambda) \sum_{i \in I} q^2_i (p^2(H|i) a^H(i, j) + (1-p^2(H|i)) a^L(i, j)) = \\
    = \lambda K^m_1(p_1, \sigma^1, j) + (1-\lambda) K^m(p_2, \sigma^2, j).
  \end{multline*}
  
  Нетрудно проверить, что определенные выше действия $\lambda \fOdd + (1-\lambda) \fEven[k+1]$ и $\lambda \fEven + (1-\lambda) \fOdd$ отвечают именно таким комбинациям соответствующих стратегий.
  Отсюда и из утверждения~\ref{ch1:prop:K1-base} следует справедливость данного утверждения.
\end{proof}

\begin{remark}
  Стратегия $\sigma^c$ из утверждения~\ref{ch1:prop:first:combination:step} не является линейной комбинацией стратегий $\sigma^1$ и $\sigma^2$ в смысле покомпонентного равенства 
  \[
    \sigma^{c,H}_i \neq \lambda \sigma^{1,H}_i + (1-\lambda) \sigma^{2,H}_i,\ i \in I.
  \]
\end{remark}

\begin{proposition}
  \label{ch1:prop:first:combination:game}
  При $\lambda \in (0, 1), \, k = \overline{0, m-1}$, для гарантированного выигрыша первого игрока в игре $\infiniteGame{p}$ справедливы равенства
  \begin{align*}
    \lowerBound{\lambda \pEven + (1-\lambda) \pOdd}      
    &= 
      \lambda \lowerBound{\pEven} + (1-\lambda) \lowerBound{\pOdd}, \\
    \lowerBound{\lambda \pOdd + (1-\lambda) \pEven[k+1]} 
    &= \lambda \lowerBound{\pOdd} + (1-\lambda) \lowerBound{\pEven}.
  \end{align*}
\end{proposition}
\begin{proof}
  Пусть $p = \lambda \pOdd + (1-\lambda) \pEven[k+1]$, где $k = \overline{0, m - 2}, \, \lambda \in (0, 1)$.
  Тогда по аналогии с \eqref{ch1:eq:lowerBound:recurrence:function} выписывается следующая рекуррентная формула:
  \begin{equation*}
    \lowerBound[n]{p} = \DCo \Co \lambda + \lambda \DCo
    \lowerBound[n-1]{\pEven} + (1-\lambda) \DCo \lowerBound[n-1]{\pOdd[k+1]} +
    \Co \lowerBound[n-1]{(1-\lambda) \pOdd + \lambda \pEven[k+1]},
  \end{equation*}
  откуда предельным переходом при $n \rightarrow \infty$ получаем
  \begin{equation}
    \label{ch1:eq:prop:L(comb)}
    \begin{aligned}
    \lowerBound{p} 
    &= \DCo \Co \lambda +
    \lambda \DCo \lowerBound{\pEven} +
    (1-\lambda) \DCo \lowerBound{\pOdd[k+1]} + \\
    &+ \Co \lowerBound{(1-\lambda) \pOdd + \lambda \pEven[k+1]}.
    \end{aligned}
  \end{equation}
  
  Так как $(1-\lambda)\pOdd + \lambda \pEven[k+1] \in (\pOdd, \pEven[k+1])$, то для $\lowerBound{(1-\lambda)\pOdd + \lambda \pEven[k+1]}$ справедливо аналогичное представление:
  \begin{align*}
    \lowerBound{(1-\lambda)\pOdd + \lambda \pEven[k+1]} 
    &=
    \DCo\Co(1-\lambda) +
    (1-\lambda)\DCo\lowerBound{\pEven} + \\
    &+ \lambda\DCo\lowerBound{\pOdd[k+1]} +
    \Co \lowerBound{p}.
  \end{align*}
  Подставив данное выражение в~\eqref{ch1:eq:prop:L(comb)} и приведя подобные члены, получим

  \begin{equation}
    \label{ch1:eq:first:combination:game:2}
    \begin{aligned}
      \lowerBound{p} 
      &= 
      \frac{1}{1-\Co^2}
      \left(
        \DCo\Co\lambda + 
        \DCo\lambda\lowerBound{\pEven} + 
        (1-\lambda)\DCo\lowerBound{\pOdd[k+1]} + 
      \right.\\
      % 
      &\left. 
        + \Co \left( 
          \DCo\Co(1-\lambda) +
          (1-\lambda)\DCo\lowerBound{\pEven} +
          \lambda\DCo\lowerBound{\pOdd[k+1]} 
        \right)
      \right) = \\
      % 
      &=
      \left( (k + 1)(m - k - 1) + \DCo\lambda(2k - m + 2\Co + 1)
      \right)/2 = \\
      &=
      \lambda\lowerBound{\pOdd} + (1-\lambda)\lowerBound{\pEven[k+1]}.
    \end{aligned}
  \end{equation}
  
  Пусть $p = \lambda\pEven + (1-\lambda)\pOdd$, где $k = \overline{1, m - 1}, \, \lambda \in (0, 1)$.
  Заметим, что $p(H|k) \in ( \pOdd[k-1], \pEven )$, а $p(H|k+1) \in ( \pOdd, \pEven[k+1] )$.
  Тогда с помощью \eqref{ch1:eq:first:combination:game:2} получим
  \begin{multline*}
    \lowerBound{p} =
    \lambda \Co \lowerBound{\pOdd[k-1]} + 
    (1-\lambda)(1-\Co)\lowerBound{\pEven} + \lambda(1-\Co)\lowerBound{\pOdd} + \\
    + (1-\lambda)\Co\lowerBound{\pEven[k+1]} 
    = \lambda \lowerBound{\pEven} + (1-\lambda) \lowerBound{\pOdd}.
  \end{multline*}
  
  При $p \in ( 0, \pOdd[1] )$ и $p \in ( \pOdd[m-1], 1 )$ доказательство проводится аналогично.
\end{proof}

Таким образом, мы определили стратегию $\fOpt$ и максимальный гарантированный выигрыш первого игрока $\lowerBound{p}$ для любых $p \in [0, 1], \, \Co \in (0, 1)$.
Отсюда вытекает справедливость следующей леммы.

\begin{lemma}
  \label{ch1:lemma:first:lower}
  При использовании первым игроком стратегии $\fOpt$ в игре $\infiniteGame{p}$\textup{,} его выигрыш ограничен снизу функцией $\lowerBound{p}$\textup{,} т.е.
  \[
    \min_{\tau \in \Tau} \infiniteFirstPlayerPayoff{p}{\fOpt}{\tau} \geq
    \lowerBound{p}.
  \]
\end{lemma}

\section{Значение игры $\mathbf{G^m_n(p)}$}\label{ch1:game-value}

\begin{theorem}
  Игра $\infiniteGame{p}$ имеет значение $\infiniteGameValue{p} = \upperBound{p} = \lowerBound{p}$.
  При этом $\fOpt$ -- оптимальная стратегия первого игрока\textup{,} а $\tau^*$ -- оптимальная стратегия второго игрока.
\end{theorem}
Доказательство данной теоремы непосредственно следует из лемм \ref{ch1:lemma:upperBound} и \ref{ch1:lemma:first:lower} и по форме повторяет доказательство аналогичной теоремы в \cite{domansky07}.

\begin{proposition}
  \label{ch1:prop:value-comparison}
  При любом значении $p \in [0,1]$, $\Co \in (0,1)$ и $m \geq 3$ справедливо неравенство
  \begin{equation*}
    V^{m, \Co}_\infty(p) \geq V^{m,1}_\infty(p) = V^{m,0}_\infty(p),
  \end{equation*}
  причем равенство достигается только при $p = k/m, k = \overline{0,m}$.
\end{proposition}
\begin{proof}
  Равенство $V^{m, 1}_\infty(p) = V^{m,0}_\infty(p)$ следует из замечания~\ref{ch1:rem:symm-payoffs} и того, что при $p = k/m$ выполняется
  \begin{equation*}
    V^{m, 0}_\infty(1-p) = \frac{(m-k)(m-(m-k))}{2} = \frac{k(m-k)}{2} = V^{m, 0}_\infty(p) = V^{m, 1}_\infty(p).
  \end{equation*}
  Далее, из (\ref{ch1:eq:recurrence-solution:even}) следует, что нам достаточно показать, что 
  \[
    V^\beta_m((k+\Co)/m) > V^1_m((k+\Co)/m).
  \]
  В силу того, что $(k+\Co)/m = \DCo k/m + \Co (k+1)/m$, получаем
  \begin{gather*}
    V^\Co_m((k+\beta)/m) - \DCo V^1_m(k/m) - \Co V^1_m((k+1)/m) = 2\DCo > 0.
  \end{gather*}
  Отсюда следует справедливость данного утверждения.
\end{proof}

\begin{figure}[b]
  \centering
  \begin{tikzpicture}[yscale=1.5,xscale=8]
    \draw[thick,->,>=stealth'] (-0.1,0) -- (1.1,0) node[right] {$p$};
    \draw[thick] (0,-0.1) -- (0,0.1);
    \node[anchor=north east] at (0,0) {$0$};
    \draw[thick] (1,-0.1) -- (1,0.1);
    \node[anchor=north west] at (1,0) {$1$};

    \draw[thick] plot file {plots/ch1-v0.5.dat};
    \draw[very thick,dashed] plot file {plots/ch1-v1.dat};
    
    \node at (0.86, 2.6) {$V^{m,1/2}_\infty(p)$};
    \node at (0.55, 2.6) {$V^{m,1}_\infty(p)$};
  \end{tikzpicture}
  \caption{Графики функции $V^{m,\Co}_\infty(p)$ при значениях $\Co = 1/2$ и $\Co = 1$}
  \label{ch1:fig:value-comparison}
\end{figure}

Таким образом, из всех рассматриваемых механизмов торгов, те механизмы, которые предписывают продавать акцию по наибольшей или наименьшей предложенной цене, гарантируют инсайдеру наименьший возможный выигрыш.

\section{Динамика апостериорных вероятностей}
Рассмотрим динамику апостериорных вероятностей, возникающую при применении игроками оптимальных стратегий.

Пусть $p \in P$. Обозначим через $p^t$ апостериорную вероятность состояния $H$ после $t$-го шага игры, причем $p^0 = p$ соответствует исходной априорной вероятности.
Тогда из замечания~\ref{ch1:remark:posterior-probs} и рекурсивной структуры игры $\infiniteGame{p}$ следует, что последовательность $(p^0, p^1, p^2, \ldots, p^t, \ldots)$ представляет собой однородную марковскую цепь с $2m$ состояниями и $2m \times 2m$-матрицей переходных вероятностей
\begin{equation}
  \label{ch1:eq:posterior-chain}
  \Pi = 
  \left(
    \begin{array}{ccccccccc}
      1    & 0   & 0   & 0    & \ldots & 0   & 0    & 0    & 0   \\
      \DCo & 0   & \Co & 0    & \ldots & 0   & 0    & 0    & 0   \\
      0    & \Co & 0   & \DCo & \ldots & 0   & 0    & 0    & 0   \\
      \hdotsfor{9}                                               \\
      0    & 0   & 0   &      & \ldots & \Co & 0    & \DCo & 0   \\
      0    & 0   & 0   &      & \ldots & 0   & \DCo & 0    & \Co \\
      0    & 0   & 0   &      & \ldots & 0   & 0    & 0    & 1
    \end{array}
 \right).
\end{equation}

Занумеруем состояния данной марковской цепи следующим образом:
\begin{gather*}
  p_{2k} = \frac{k}{m}, \quad k = \overline{0, m}, \quad
  p_{2k+1} = \frac{k+\Co}{m}, \quad k = \overline{0, m-1}.
\end{gather*}

Из \eqref{ch1:eq:posterior-chain} видно, что состояния $p_0$ и $p_{2m}$ являются поглощающими.
Они соответствуют моменту игры, в который происходит полное раскрытие приватной информации первого игрока, т.е. моменту, когда второму игроку становится доподлинно известно истинное состояние $s$.
Случайная величина
\begin{equation*}
  \xi = \min \left\{ 0 \leq t: p^t \in \{p_0, p_{2m}\} \right\}
\end{equation*}
соответствует моменту поглощения. Величина
\begin{equation*}
  \tau(p_k) = \E \{ \xi\ |\ p^0 = p_k \}
\end{equation*}
определяет ожидаемую продолжительность игры, при условии, что априорная вероятность равна $p_i$.

Обозначим через $\pi^l_i,\ \pi^r_i,\ i \in \overline{1, 2m-1}$ вероятности перехода из состояния $p_i$ в состояния $p_{i-1}$ и $p_{i+1}$ соответственно.

\begin{figure}[tb]
  \centering
  \input{figures/ch1-posterior-markov}
  \caption[Последовательность апостериорных вероятностей]{Марковская цепь,
    соответствующая последовательности апостериорных вероятностей}
  \label{ch1:fig:posterior-markov}
\end{figure}

\begin{proposition}
  \label{ch1:prop:game-duration}
  Игра $\infiniteGame{p_k}$ в среднем заканчивается за конечное количество шагов.
  Ее ожидаемая продолжительность выражается формулами
  \begin{equation*} 
    \tau(p_{2k+1}) = \frac{(m-k-\Co)(k+\Co)}{\Co \DCo},\quad
    \tau(p_{2k}) = \frac{k(m-k)}{\Co \DCo}.
  \end{equation*}
\end{proposition}
\begin{proof}
  Известно, что ожидаемое время до поглощения для марковских цепей имеющих структуру, изображенную на рисунке~\ref{ch1:fig:posterior-markov}, выражается следующим образом (\seename \cite[\S~12]{shiryaev11}):
  \begin{gather}
    \label{ch1:prop:game-duration:eq:1}
    \tau(p_j) =
    \sum_{i=0}^{j-1} \rho_i \cdot
    \frac{\sum_{i=0}^{2m-1} R_i}{\sum_{i=0}^{2m-1} \rho_i} -
    \sum_{i=0}^{j-1} R_i,
  \end{gather}
  где
  \begin{gather*}
  \rho_0 = 1, \quad
    \rho_j = \frac{\pi^l_1 \ldots \pi^l_j}{\pi^r_1 \ldots \pi^r_j}, \quad j \geq 1,\\
    R_0 = 0, \quad
    R_1 = \frac{1}{\pi^r_1}, \quad
    R_j = \frac{1}{\pi^r_j}\left( 
      1 + 
      \frac{\pi^l_j}{\pi^r_{j-1}} + 
      \ldots + \frac{\pi^l_j \ldots \pi^l_2}{\pi^r_{j-1} \ldots \pi^r_1}
    \right), \quad j \geq 2.
  \end{gather*}
  Нетрудно проверить, что для коэффициентов $\rho_j$, $R_j$ выполняются равенства
  \begin{gather*}
    \rho_{2k+1} = \frac{\DCo}{\Co},\quad k = \overline{0, m-1},\quad
    \rho_{2k} = 1,\quad k = \overline{1, m-1},\\
    R_k = \frac{k}{\pi^r_k},\quad k = \overline{1, 2m-1}.
  \end{gather*}
  Отсюда получаем
  \begin{equation}
    \label{ch1:prop:game-duration:eq:2}
    \begin{gathered}
      \sum_{i=0}^{2k-1} \rho_i = k + k \frac{\DCo}{\Co} = \frac{k}{\Co},\\
      \sum_{i=0}^{2k-1} R_i = \frac{k^2}{\Co} + \frac{k(k-1)}{\DCo} = \frac{k(k-\Co)}{\Co\DCo}.
    \end{gathered}
  \end{equation}
  Из \eqref{ch1:prop:game-duration:eq:1} и \eqref{ch1:prop:game-duration:eq:2} находим
  \begin{gather}
    \label{ch1:prop:game-duration:eq3}
    \tau(p_{2k}) =
    \frac{k}{\Co} \frac{m-\Co}{\DCo} - \frac{k(k-\Co)}{\Co\DCo} =
    \frac{k(m-k)}{\Co\DCo}.
  \end{gather}

  Заметим, что имеет место следующее равенство:
  \begin{equation}
    \label{ch1:prop:game-duration:eq4}
    \tau(p_{2k+1}) = 1 + \DCo \tau(p_{2k}) + \Co \tau(p_{2(k+1)}).
  \end{equation}
  Справедливость формулы для $\tau(p_{2k+1})$ проверяется подстановкой~\eqref{ch1:prop:game-duration:eq3} в выражение~\eqref{ch1:prop:game-duration:eq4}.
\end{proof}

В силу того, что первый игрок получает положительные выплаты размера $\Co\DCo$ только в состояниях $p_i$ с нечетными номерами, то его выигрыш за игру равен среднему количеству посещенных нечетных состояний, умноженных на одношаговую выплату. В частности при $p = p_{2k+1}$ и первое, и последнее состояние дают положительный выигрыш. Отсюда получаем
\begin{equation*}
  \frac{\tau(p_{2k+1}) + 1}{2} \cdot \Co\DCo = \frac{(m-k-\Co)(k+\Co) + \Co\DCo}{2}.
\end{equation*}
Аналогично при $p = p_{2k}$ имеем
\begin{equation*}
  \frac{\tau(p_{2k})}{2} \cdot \Co\DCo = \frac{k(m-k)}{2}.
\end{equation*}
Данные результаты согласуется с формулами (\ref{ch1:eq:recurrence-solution:odd},~\ref{ch1:eq:recurrence-solution:even}).

Нужно отметить, что в сравнении со случайным блужданием апостериорных вероятностей, порождаемым оптимальной стратегией инсайдера из \cite{domansky07}, случайное блуждание, рассмотренное выше, имеет более сложный характер: в дополнение к точками $k/m$ оно включает точки $(k+\Co)/m$, кроме того оно больше не является симметричным, кроме случая $\Co = 1/2$.

}
%%% Local Variables:
%%% coding: cp1251
%%% mode: latex
%%% TeX-master: "../dissertation"
%%% End:
