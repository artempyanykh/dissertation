\chapter{Теоретико-игровая модель биржевых торгов с дискретными ставками и двумя состояниями} \label{chapt1} 
{
%%% Chapter 1 commands
\newcommand{\symm}[1]{\overline{#1}}
\newcommand{\pEven}[1][k]{p^0_{#1}}
\newcommand{\pOdd}[1][k]{p^{\beta}_{#1}}
\newcommand{\fEven}[1][k]{\phi^0_{#1}}
\newcommand{\fOdd}[1][k]{\phi^{\beta}_{#1}}

В разделе~\ref{ch1:intro} данной работы дано введение в теорию повторяющихся игр с неполной информацией, определены основные термины и понятия.
В разделе~\ref{ch1:model} приведено описание модели биржевых торгов с дискретными ставками, которая в разделе~\ref{ch1:formal-def} формализована в виде игры в нормальной форме.
Раздел~\ref{ch1:upper-bound} посвящен получению оценки сверху выигрыша инсайдера.
Оценка снизу выигрыша инсайдера найдена в разделе~\ref{ch1:lower-bound}.
В разделе~\ref{ch1:game-value} дана теорема о значении игры, исследована динамика апостериорных вероятностей при применении игроками оптимальных стратегий и проведено сравнение полученных результатов с результатами из~\cite{domansky07}.

Основные результаты данной главы опубликованы в работах~\cite{pyanykh14,pyanykh16:discr:eng} в журналах из перечня ВАК.

\section{Основные понятия}\label{ch1:intro}
Далее последует описание повторяющейся игры с неполной информацией, в которой множество состояний конечно, как и множества возможных действий игроков.
Теоретико-игровые постановки задач из глав~\ref{chapt2} и~\ref{chapt3} будут отличаться от данного классического описания, о чем будет сказано отдельно.

Рассмотрим антагонистическую игру двух лиц, которая повторяется $n$ раз, где $n\leq \infty$.
Будем считать, что первый игрок знает функцию выигрыша в данной игре, в то время как второй игрок такой информацией не обладает.
Однако второй игрок знает, что настоящая функция выигрыша является одной из $\kappa$ возможных альтернатив.
Каждой такой альтернативе второй игрок приписывает некоторую вероятность того, что данная функция выигрыша является истинной функцией выигрыша в рассматриваемой
игре.
Таким образом, априорные убеждения второго игрока задаются вероятностным вектором
\[
  \pd = (\pc{1}, \pc{2}, \ldots, \pc{\kappa}),\quad \sum_{i=1}^\kappa \pc{i} = 1.
\]

С данными функциями выигрыша можно связать игры $G_1, G_2, \ldots, G_\kappa$.
В дальнейшем мы будем считать, что информационная неопределенность второго игрока заключается именно в том, что он не знает какая из игр $G_1, G_2, \ldots, G_\kappa$ разыгрывается.

На каждом шаге игры первый игрок может совершать действия из множества $I$, второй игрок --- действия из множества $J$, при этом мы считаем, что множества действий одного игрока известно другому.
Кроме того, положим, что второй игрок знает, что первый обладает точной информацией о том, какая именно игра разыгрывается, а первый игрок знает априорные убеждения второго.

\begin{figure}[t]
  \centering
  \input{figures/ch1-game-structure}
  \caption{Структура повторяющейся игры}
  \label{ch1:fig:game_structure}
\end{figure}

Игры $G_1, G_2, \ldots, G_\kappa$ будем называть \emph{одношаговыми играми}.
Все одношаговые игры описываются матрицами размера $|I| \times |J|$, где элементы матрицы задают выплаты первому игроку.
Мы предполагаем, что оба игрока точно знают платежные матрицы игр $G_1, G_2, \ldots, G_\kappa$.
На каждом шаге игры первый игрок выбирает номер строки, и одновременно с ним второй игрок выбирает номер столбца.
В конце каждого хода действия игроков оглашаются, и элемент из матрицы, отвечающей настоящей игре, прибавляется к выигрышу первого игрока и вычитается из выигрыша второго.
Таким образом, первый игрок знает свой выигрыш на каждом этапе игры, в то время как второй может лишь рассчитать свой ожидаемый выигрыш.
В завершение, мы считаем, что данное описание известно обоим игрокам.

Данная игра с неполной информацией описывается в виде игры в нормальной форме следующим образом.
Обозначим через $S = \{1, 2, \ldots, \kappa\}$ множество возможных альтернатив или \emph{состояний природы}.
Перед началом игры ходом случая в соответствии с вероятностным распределением $\pd$ выбирается состояние $s \in S$.
Далее на протяжении $n$ шагов разыгрывается игра $G_s$.
Первый игрок информирован о результате хода случая, второй игрок "--- нет.
В остальном правила данной игры совпадают с описанными выше.

Пусть $h_t = \left((i_1, j_1), (i_2, j_2), \ldots, (i_t, j_t)\right)$ "--- история ставок игроков после завершения шага $t$.
Множество все таких $h_t$ обозначим через $H_t$. 

Стратегией первого игрока в такой игре является последовательность ходов (отображений) $\sigmar = (\sigmas{1}, \sigmas{2}, \ldots, \sigmas{n})$, где $\sigmas{t} = (\sigmas[1]{t}, \sigmas[2]{t}, \ldots, \sigmas[\kappa]{t})$, и $\sigmas[s]{t}: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от предыдущих ходов, которую первый игрок использует, если ходом случая реализовалось состояние $s$.

Аналогичным образом определим стратегию второго игрока как последовательность ходов (отображений) $\taur = (\taus{1}, \taus{2}, \ldots, \taus{n})$, где $\taus{t}: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от предыдущих ходов.
Как видно, ход второго игрока на каждом шаге игры зависит только от предыдущих ходов, и не зависит от состояния, в силу того, что второй игрок не информирован о результате хода случая.

Отметим, что, как показано в монографии Аумана, Машлера~\cite{aumann95}, достаточно рассматривать только стратегии, которые зависят лишь от предыдущих ходов первого игрока и не зависят от ходов второго.

Также нужно отметить, что в данной работе рассмотрены игры, в которых выигрыш равен суммарным выплатам, в отличие от постановки из \cite{aumann95}, в которой рассматривались игры с усредненными выплатами.

\section{Описание модели}\label{ch1:model}
Рассмотрим упрощенную модель финансового рынка, на котором два игрока ведут торговлю однотипными акциями на протяжении $n \leqslant \infty$ шагов, следуя работе~\cite{domansky07}.

Перед началом торгов случайный ход определяет цену акции на весь период торгов, которая может быть либо $m \in \N$ с вероятностью $p$, либо $0$ с вероятностью $1-p$.
Таким образом определенный ход случая является упрощенным аналогом некоторого шокового события на финансовом рынке (такого, как, например, публикация отчетов о доходах некоторой компании).
Выбранная цена сообщается первому игроку и не сообщается второму, при этом второй игрок знает, что первый "--- инсайдер.

Рассмотрим $t$-й шаг торгов, где $t = \overline{1,n}$.
На данном шаге первый игрок выбирает ставку $i_t \in I = \{0, 1, \ldots, m\}$, а второй --- ставку $j_t \in J = \{0, 1, \ldots, m\}$.
Игрок, предложивший б\'{о}льшую ставку, покупает у другого акцию по цене равной
\[
  \Co \max(i_t, j_t) + \DCo \min(i_t, j_t),\ \text{где } %
  \Co \in (0, 1),\ \DCo = 1 - \Co.
\]
Если ставки равны, то сделка на $t$-м шаге не состоится.
Коэффициент $\Co$ можно интерпретировать как \emph{переговорную силу продавца}: чем ближе значение к $1$, тем большую сумму получит продавец акции в результате сделки.

Будем считать, что игроки обладают неограниченными запасами рисковых и безрисковых активов, т.е. торги не могут прекратиться по причине того, что у одного из игроков закончатся деньги или акции.
Цель игроков состоит в максимизации стоимости итогового портфеля, состоящего из некоторого числа купленных акций и суммы денег, полученных в результате торгов.
Таким образом, не ограничивая общности, можно положить, что в начальный момент времени оба игрока имеют нулевые портфели.

Фактически в работах~\cite{domansky07, demeyer05}, а также в работах~\cite{domansky11, domansky13, domansky14}, посвященных обобщению дискретной модели, коэффициент $\Co = 1$.
Мотивацией к рассмотрению дискретной модели служит тот факт, что на реальных рынках расчеты ведутся пропорционально минимальной денежной единице.
При $\Co = 1$ все ставки будут целочисленными, как и финальные выплаты игрокам.
При рассмотрении модели с произвольным значением $\Co$ цена сделки перестает быть целочисленной, однако интерпретацию дискретности модели в этой постановке можно оставить неизменной, решив проблему нецелой финальной выплаты размера $a$ с помощью случайного механизма, который выберет либо выплату размера $\floor{a}$, либо выплату размера $\ceil{a}$.
Ожидаемый выигрыш при этом останется неизменным, но свойство дискретности сохранится.

\section{Определение игры $\mathbf{G^{m,\beta}_n(p)}$}\label{ch1:formal-def}

Определим формально повторяющуюся игру с неполной информацией, отвечающую данному выше описанию. 

Пусть множество состояний рынка $S = \{L, H\}$. Перед началом игры случай выбирает $s \in S $ с вероятностями $P(s=H) = p$ и $P(s=L) = 1 - p$.
После этого на протяжении $n \leq \infty$ шагов игроки участвуют в игре с матрицей $A^{s,\Co}$, где элементы матрицы заданы следующим образом:
\begin{equation*}
  \as[L](i, j) = \begin{cases}
    \DCo i + \Co j, &\, i < j, \\
    0, &\, i = j, \\
    -\Co i - \DCo j, &\, i > j,
  \end{cases}
  \qquad
  \as[H](i, j) = \begin{cases}
    \DCo i + \Co j - m, &\, i < j, \\
    0, &\, i = j, \\
    m - \Co i - \DCo j, &\, i > j.
  \end{cases}
\end{equation*}

Стратегией первого игрока в данной игре является последовательность ходов (отображений) 
$\sigmar = (\sigmas{1}, \sigmas{2}, \ldots, \sigmas{t}, \ldots)$, где 
$\sigmas{t}: S \times I^{t-1} \rightarrow \Delta(I)$.
Таким образом, на каждом шаге торгов первый игрок рандомизирует выбор ставки в зависимости от состояния и предыдущих ставок.
Как и в работе~\cite{domansky07}, мы ограничимся рассмотрением только тех стратегий $\sigmar$, которые гарантируют первому игроку на каждом шаге игры неотрицательный выигрыш.
Множество таких стратегий первого игрока обозначим через $\Sigma$.

Аналогично, стратегией второго игрока назовем последовательность ходов (отображений) 
$\taur = (\taus{1}, \taus{2}, \ldots, \taus{t}, \ldots),$ где 
$\taus{t}: I^{t-1} \rightarrow \Delta(J)$.
Не имея информации о настоящем состоянии, второй игрок при выборе ставки опирается только на историю ставок инсайдера.
Множество стратегий второго игрока обозначим через $\Tau$.

Обозначим через $\E_{(p,\sigmar,\taur)}$ математическое ожидание по мере, индуцированной на $S \times I^n \times J^n$ ходом случая и смешанными стратегиями $\sigmar$ и $\taur$ игроков.

При применении первым игроком смешанной стратегии $\sigmar$, а вторым игроком "--- смешанной стратегии $\taur$, ожидаемый выигрыш первого игрока
\begin{equation}
  \label{ch1:eq:firstPlayerPayoff}
  \K*{n}(p, \sigmar, \taur) = \E_{(p,\sigmar,\taur)} \sum_{t=1}^n
  \left(
    p \as[H](i_t^H, j_t) + (1 - p)\as[L](i_t^L, j_t)
  \right).
\end{equation}

\begin{remark}
  В игре с произвольным значением $\Co$, в отличие от случая $\Co = 1$, стратегии, использующие ставку $m$, не являются доминируемыми.
  Проиллюстрировать это можно следующим образом.
  Рассмотрим одношаговую игру.
  Пусть $\Co < 1$, цена акции равна $m$, и второй игрок делает ставку равную $m$.
  Тогда любая ставка $i < m$ первого игрока будет давать ему выигрыш размера $\DCo (i - m) < 0$, и только ставка $m$ даст первому игроку выигрыш равный нулю. 
  Если же второй игрок делает ставку равную $m-2$, то ставка первого игрока $m-1$ даст ему выигрыш размера $2-\Co$, а ставка $m$ меньший выигрыш размера $2-2\Co$.
\end{remark}

Полученную игру обозначим через $\theG*{n}(p)$.
Ее верхнее и нижнее значения даются формулами
\begin{equation*}
  \LowV*{n}(p) = \max_{\sigmar \in \Sigma} \inf_{\taur \in \Tau}
  \K*{n}(p, \sigmar, \taur), \quad
  \HighV*{n}(p) = \min_{\taur \in \Tau} \sup_{\sigmar \in \Sigma}
  \K*{n}(p, \sigmar, \taur).
\end{equation*}
Если верхнее и нижнее значения совпадают, то игра имеет значение, которое мы обозначим $\V*{n}(p)$.

\begin{remark}
  В силу того, что игра $\theG*{n}(p)$ может быть представлена в виде матричной игры большой размерности, существование ее значения следует из основной теоремы матричных игр (\seename~\cite{morozov08}).
\end{remark}

Заметим, что имеют место следующие равенства:
\begin{equation}
  \label{ch1:eq:payoff-symmetry}
  \as[L][\Co](i, j) = \as[H][\DCo](m-i, m-j), \quad
  \as[H][\Co](i, j) = \as[L][\DCo](m-i, m-j).
\end{equation}

\begin{remark}
  \label{ch1:rem:symm-payoffs}
  Определим для заданных стратегий $\sigmar,\ \taur$ стратегии $\symm{\sigmar}$ и $\symm{\taur}$ таким образом, что для $t$-го шага
  $\symm{\sigmas{t}} = (\symm{\sigmas[H]{t}}, \symm{\sigmas[L]{t}})$, где
  $\symm{\sigmas[s]{t}}=(\sigmasc[s][t]{m},\ldots,\sigmasc[s][t]{0}) \in \Delta(I)$, и
  $\symm{\taus{t}} = (\tausc[t]{m},\ldots,\tausc[t]{0}) \in \Delta(J)$.
  Из равенств (\ref{ch1:eq:payoff-symmetry}) следует, что выигрыши игроков в играх $\theG*[\Co]{n}(p)$ и $\theG*[\DCo]{n}(1-p)$ при использовании соответственно стратегий $\sigmar,\ \taur$ и $\symm{\sigmar},\ \symm{\taur}$ совпадают.
\end{remark}

\section{Оценка сверху выигрыша первого игрока}\label{ch1:upper-bound}
Следуя \cite{domansky07}, рассмотрим чистую стратегию второго игрока $\tau^k, \, k \in J$:
\[
  \tau^k_1 = k, \quad \tau^k_t(i_{t-1}, j_{t-1}) = \begin{cases}
    j_{t-1} - 1, & \, i_{t-1} < j_{t-1}, \\
    j_{t-1},     & \, i_{t-1} = j_{t-1}, \\
    j_{t-1} + 1, & \, i_{t-1} > j_{t-1}.
  \end{cases}
\]
Другими словами, второй игрок делает ставку равную $k$ на первом шаге, а далее либо подражает инсайдеру, либо смещается на единицу к ставке инсайдера предыдущего шага.

Доказательство следующего утверждения по форме повторяет доказательство утверждения 4.3 из \cite{domansky07} и приводится здесь в целях полноты изложения.

\begin{proposition}
  \label{ch1:prop:secondPlayerStrategyPayoffs}
  При применении стратегии $\tau^k$ в игре $\theG*{n}(p)$ второй игрок гарантирует себе проигрыш не более
  \[
    h_n^L(\tau^k) = \sum_{t=0}^{n-1}(k - t - \DCo)^+, \quad h_n^H(\tau^k) =
    \sum_{t=0}^{n-1}(m - k - t - \Co)^+,
  \]
  в состояниях L и H соответственно.
  Последовательности $\{h_n^L(\tau^k)\}_{n=1}^\infty$ и $\{h_n^H(\tau^k)\}_{n=1}^\infty$ не убывают, ограничены сверху по $n$ и имеют следующие пределы:
  \begin{equation*}
    h_\infty^L(\tau^k) = \frac{(k+\Co-\DCo)k}{2},\quad
    h_\infty^H(\tau^k) = \frac{(m - k)(m - k + \DCo - \Co)}{2}.
  \end{equation*}
\end{proposition}
\begin{proof}
  Проведем доказательство по индукции для $h^L_n(\tau^k)$.
  При $n=1$ справедливо
  \[
    h^L_1(\tau^k) = \max_{i \in I} \as[L](i, k) = \max(0, k - \DCo) = (k - \DCo)^+.
  \]
  Предположим, что формула верна при $n \leq N$.
  Пусть $n=N+1$.
  Первым ходом второй игрок выбирает $k$.
  Следовательно, оптимальный выбор инсайдера на первом ходу равен $\max(0, k - 1)$, что соответствует либо продаже акции по наибольшей цене в случае $k > 0$, либо отсутствию сделки при $k=0$. 
  Для случая $k > 0$ имеем
  \begin{gather*}
    h^L_{N+1}(\tau^k) = \DCo (k-1) + \Co k + h^L_N(\tau^{k-1}) =
    k - \DCo + \sum_{t=0}^{N-1}(k - 1 - t - \DCo)^+ = \\
    = k - \DCo + \sum_{t=1}^N(k-t-\DCo)^+ = \sum_{t=0}^N(k-t-\DCo)^+.
  \end{gather*}
  В случае $k = 0$ получаем
  \begin{gather*}
    h^L_{N+1}(\tau^k) = 0 = \sum_{t=0}^N(k-t-\DCo)^+.
  \end{gather*}
  Далее заметим, что $h^L_k(\tau^k) = h^L_{k+i}(\tau^k),\ i \in \N_+$.
  Отсюда находим
  \begin{equation*}
    h_\infty^L(\tau^k) = \sum_{t=0}^{k-1} (k - t - \DCo) = \frac{(k+\Co-\DCo)k}{2}.
  \end{equation*}
  Для $h^H_n(\tau^k)$ утверждение доказывается аналогично.
\end{proof}

Введем следующую функцию:
\begin{multline*}
  \H*{\infty}(p) 
  = \min_{j \in J} \lim_{n \rightarrow \infty}\left(
    ph_n^H(\tau^j) + (1-p)h_n^L(\tau^j)
  \right) = \\
  %
  = \min_{j \in J} \frac{\left[ p (m - j)(m - j + \DCo - \Co) + (1 - p)j(j + \Co - \DCo) \right]}{2} = \\
  = \min_{j \in J} \frac{\left[ j^2 + j(2\Co - 1 - 2 m p) + m p (1 + m - 2\Co) \right]}{2}.
\end{multline*}

\begin{figure}[thb]
  \centering
  \input{figures/ch1-omega-x-p}
  \caption{График функции $\omega(x,p)$ при $p \in \{(k-\DCo)/m, (k+\Co)/m\}$}
  \label{ch1:fig:omega(x,p)}
\end{figure}

Функция $\omega(x, p) = x^2 + x(2\Co - 1 - 2mp)$ достигает минимума по $x \in \R$ в точке $m p - \Co + 1/2$.
Поэтому при $p \in \left( (k-\DCo)/m, (k+\Co)/m) \right]$ минимум функции $j^2 + j(2\Co - 1 - 2 m p)$ по $j \in J$ достигается при $j = k$ (\seename рис~\ref{ch1:fig:omega(x,p)}).

Таким образом, $\H*{\infty}(p)$ является вогнутой кусочно-линейной функцией, график которой состоит из $m~+~1$ линейных сегментов.
Она полностью определяется своими значениями в следующих точках (\seename~рис.~\ref{ch1:fig:Hm})
\begin{gather*}
  \H*{\infty}((k+\Co)/m) = \frac{1}{2} \left( (m - (k + \Co))(k + \Co) + \DCo\Co
  \right),\enskip
  k = \overline{0, m - 1},\\
  \H*{\infty}(0) = \H*{\infty}(1) = 0.
\end{gather*}

\begin{figure}[thb]
  \centering
  \begin{tikzpicture}[yscale=1.3,xscale=7]
    \draw[thick,->,>=stealth'] (-0.1,0) -- (1.1,0) node[right] {$p$};
    \draw[thick] (0,-0.1) -- (0,0.1);
    \node[anchor=north east] at (0,0) {$0$};
    \draw[thick] (1,-0.1) -- (1,0.1);
    \node[anchor=north west] at (1,0) {$1$};

    \draw[thick] plot file {plots/ch1-v0.75.dat};
    
    \draw[thick,dashed] (0.15, -0.1) -- (0.15, 3.2);
    \node[anchor=north] at (0.15, -0.1) {$\Co/m$};

    \draw[thick,dashed] (0.75, -0.1) -- (0.75, 3.2);
    \node[anchor=north] at (0.75, -0.1) {$(k+\Co)/m$};
    
    \node at (0.55, 2.6) {$\H*{\infty}(p)$};
  \end{tikzpicture}
  \caption{График функции $\H*{\infty}(p)$}
  \label{ch1:fig:Hm}
\end{figure}

Пусть второй игрок при $p \in \left( (k-\DCo)/m, (k+\Co)/m) \right]$ применяет $\tau^k, \, k = \overline{0, m}$.
Обозначим эту стратегию через $\taur^*$.
Тогда справедлива следующая
\begin{lemma}
  \label{ch1:lemma:upperBound}
  Зафиксируем вероятность $p \in [0,1]$.
  Тогда при использовании вторым игроком стратегии $\taur^*$ в игре $\theG*{\infty}(p)$\textup{,} выигрыш первого игрока ограничен сверху величиной $\H*{\infty}(p)$, т.е.
  \[
    \max_{\sigmar \in \Sigma} \K*{\infty}(p, \sigmar, \taur^*) \leq \H*{\infty}(p).
  \]
\end{lemma}

\section{Оценка снизу выигрыша первого игрока}\label{ch1:lower-bound}
Перейдем к описанию стратегии первого игрока, гарантирующей ему выигрыш не менее $\H*{\infty}(p)$ в игре $\theG*{\infty}(p)$.

Пусть на первом шаге игры первый игрок выбирает ход %
$\sigmak = \left(\sigmas[H]{1}, \sigmas[L]{1}\right)$, где %
$\sigmas[H]{1} = \left(\sigmasc[H]{k}, \sigmasc[H]{k+1}\right)$,
$\sigmas[L]{1} = \left(\sigmasc[L]{k}, \sigmasc[L]{k+1}\right)$ и
$\sigmasc[s]{i}$ -- вероятность сделать ставку $i$ в состоянии $s \in S$.
Применяя $\sigmak$, инсайдер делает ставки $k$ и $k+1$ с некоторыми заданными вероятностями.

В дальнейшем будем использовать эквивалентный способ задания хода.
Для этого определим следующие параметры: полные вероятности использования действий $k$ и $k+1$, равные $\qc{k}$ и $\qc{k+1}$ соответственно, а также апостериорные вероятности $\pac{s}{i}$ состояния $s$ при условии, что на предыдущем шаге первый игрок сделал ставку $i$.
Тогда вероятности $\sigmasc[s]{i}$ можно найти по формуле Байеса
\[
  \sigmasc[s]{i} = \pac{s}{i} \qc{i} / \pc{s}, \: i = k, k + 1.
\]

\begin{proposition}
  \label{ch1:prop:stage-payoff}
  При использовании $\sigmak$ первый игрок обеспечивает себе на первом шаге выигрыш
  \begin{equation}
    \label{ch1:eq:lowerPayoffGeneral}
    \K*{1}(p, \sigmak, j) =
    \begin{cases}
      mp - \Co k - \DCo j - \Co \qc{k+1},      & \, j < k,     \\
      \left(m \pac{H}{k+1} - k - \Co \right) \qc{k+1}, & \, j = k,     \\
      \left(k + \Co - m \pac{H}{k} \right) \qc{k},       & \, j = k + 1, \\
      \DCo k + \Co j - m p + \DCo \qc{k+1}, & \, j > k + 1.
    \end{cases}
  \end{equation}
\end{proposition}
\begin{proof}
  Пусть $j < k$.
  Тогда из \eqref{ch1:eq:firstPlayerPayoff} и определения $\sigmak$ получаем
  \begin{align*}
    \K*{1}(p, \sigmak, j) &=
    p \left( 
      \sigmasc[H]{k} (m - \Co k - \DCo j) +
      \sigmasc[H]{k+1} (m - \Co (k+1) - \DCo j)
    \right) + \\
    &+ (1-p) \left( 
      \sigmasc[L]{k} (- \Co k - \DCo j) +
      \sigmasc[L]{k+1} (- \Co (k+1) - \DCo j)
    \right) = \\
    &=
    m p (\sigmasc[H]{k} + \sigmasc[H]{k+1}) -
    \left(
      p (\sigmasc[H]{k} + \sigmasc[H]{k+1}) +
      (1-p) (\sigmasc[L]{k} + \sigmasc[L]{k+1})
    \right) \times \\ 
    &\times (\Co k + \DCo j) -
    (p \sigmasc[H]{k+1} + (1-p) \sigmasc[L]{k+1}) \Co = \\
    &= mp - \Co k - \DCo j - \Co \qc{k+1}.
  \end{align*}
  При $j = k$ имеет место равенство
  \begin{align*}
    \K*{1}(p, \sigmak, j) 
    &=
      p \sigmasc[H]{k+1} (m - \Co (k+1) - \DCo k) +
      (1-p) \sigmasc[L]{k+1} (- \Co (k+1) - \DCo k) = \\
    &= m p \sigmasc[H]{k+1} - 
      (p \sigmasc[H]{k+1} + (1-p) \sigmasc[L]{k+1}) (\Co (k+1) + \DCo k) =\\
    &= m \pac{H}{k+1} \qc{k+1} - \qc{k+1} (\Co (k+1) + \DCo k) = \\
    &= (m \pac{H}{k+1} - k - \Co) \qc{k+1}.
  \end{align*}
  При $j=k+1$ находим
  \begin{align*}
    \K*{1}(p, \sigmak, j) 
    &=
      p \sigmasc[H]{k} (\Co (k+1) + \DCo k - m) +
      (1-p) \sigmasc[L]{k} (\Co (k+1) + \DCo k) = \\
    &= (p \sigmasc[H]{k} + (1-p) \sigmasc[L]{k}) (\Co (k+1) + \DCo k)
      - m p \sigmasc[H]{k} =\\
    &= \qc{k} (\Co (k+1) + \DCo k) - m \pac{H}{k} \qc{k}  = \\
    &= (k + \Co - m \pac{H}{k})) \qc{k}.
  \end{align*}
  При $j>k+1$ получаем
  \begin{align*}
    \K*{1}(p, \sigmak, j) 
    &=
      p \left( 
      \sigmasc[H]{k} (\Co j - \DCo k - m) +
      \sigmasc[H]{k+1} (\Co j - \DCo (k+1) - m)
      \right) + \\
    &+ (1-p) \left( 
      \sigmasc[L]{k} (\Co j + \DCo k) +
      \sigmasc[L]{k+1} (\Co j + \DCo (k+1))
    \right) = \\
    &= (\DCo k + \Co j)
    \left(
      p (\sigmasc[H]{k} + \sigmasc[H]{k+1}) +
      (1-p) (\sigmasc[L]{k} + \sigmasc[L]{k+1})
    \right) - \\
    &- m p (\sigmasc[H]{k} + \sigmasc[H]{k+1}) +
    (p \sigmasc[H]{k+1} + (1-p) \sigmasc[L]{k+1}) \DCo = \\
    &= \DCo k + \DCo j - mp + \Co \qc{k+1}.
  \end{align*}
  Отсюда устанавливаем справедливость \eqref{ch1:eq:lowerPayoffGeneral}.
\end{proof}

Построим оптимальную стратегию инсайдера. Рассмотрим на $[0,1]$ множество $P$ точек вида
\[
\pEven[k] = k/m, \, k = \overline{0, m}, \quad \pOdd[k] = (k + \Co)/m, \, k = \overline{0, m - 1}.
\]

Для $p = \pEven,\ k = \overline{1, m-1}$ определим $\fEven$ как распределение $\sigmak$ с параметрами
\begin{align*}
  \qc{k} = \Co,& \quad \pac{H}{k} = \pOdd[k-1] = (k-1+\Co)/m,\\
  \qc{k+1} = \DCo,& \quad \pac{H}{k+1} = \pOdd[k] = (k+\Co)/m.
\end{align*}
Покомпонентно оно записывается как
\begin{gather*}
  \sigmasc[H]{k} = \frac{(k-\DCo)\Co}{k},\quad 
  \sigmasc[H]{k+1} = \frac{(k+\Co)\DCo}{k},\\
  \sigmasc[L]{k} = \frac{(m - k + \DCo)\Co}{m - k},\quad 
  \sigmasc[L]{k+1} = \frac{(m - k - \Co)\DCo}{m - k}.
\end{gather*}
Дополнительно определим $\fEven[0]$ как распределение, состоящее в применении ставки $0$ с вероятностью $1$, а $\fEven[m]$ -- как распределение, состоящее в применении ставки $m$ с вероятностью $1$.

Аналогично для $p = \pOdd,\ k = \overline{0, m-1}$ определим $\fOdd$ как распределение $\sigmak$ с параметрами
\begin{align*}
  \qc{k} = \DCo,& \quad \pac{H}{k} = \pEven[k] = k/m,\\
  \qc{k+1} = \Co,& \quad \pac{H}{k+1} = \pEven[k+1] = (k+1)/m.
\end{align*}
Покомпонентно оно записывается как
\begin{gather*}
  \sigmasc[H]{k} = \frac{k\DCo}{k + \Co},\quad 
  \sigmasc[H]{k+1} = \frac{(k+1)\Co}{k + \Co},\\
  \sigmasc[L]{k} = \frac{(m - k)\DCo}{m - k - \Co},\quad 
  \sigmasc[L]{k+1} = \frac{(m - k - 1)\Co}{m - k - \Co}.
\end{gather*}

\begin{proposition}
  \label{ch1:prop:K1-base}
  При $p \in P$ и использовании на первом шаге распределений $\fEven$ и $\fOdd$ одношаговый гарантированный выигрыш первого игрока равен
  \begin{equation}
    \label{ch1:eq:lowerBound:inequalities}
    \begin{gathered}
      \min_{j \in J}
      \K*{1}(\pEven, \fEven, j) = 0,\ k = \overline{0, m}, \\
      \min_{j \in J}
      \K*{1}(\pOdd, \fOdd, j) = \DCo\Co,\ k = \overline{0, m-1}.
    \end{gathered}
  \end{equation}
\end{proposition}
\begin{proof}
  Подставив полные вероятности действий и апостериорные вероятности состояний в \eqref{ch1:eq:lowerPayoffGeneral}, получим для $p = \pEven,\ k = \overline{1, m-1}$
  \begin{equation*}
    \K*{1}(\pEven, \fEven, j) = \begin{cases}
      k - \Co k - \DCo j - \Co \DCo \geq \DCo \DCo,\ & j < k,\\
      (k + \Co - k - \Co) \DCo = 0,\ & j = k,\\
      (k + \Co - k) \Co = \Co \Co,\ & j = k+1,\\
      \DCo k + \Co j - k - \Co + \DCo^2 \geq \Co + \DCo^2,\ & j > k+1.
    \end{cases}
  \end{equation*}

  При $p = \pOdd[k],\ k = \overline{1,m-1}$ получаем
  \begin{equation*}
    \K*{1}(\pOdd, \fOdd, j) = \begin{cases}
      k + \Co - \Co k - \DCo j - \Co^2 > \Co \DCo,\ & j < k,\\
      (k + 1 - k - \Co) \Co = \Co \DCo,\ & j = k,\\
      (k + \Co - k) \DCo = \Co \DCo,\ & j = k+1,\\
      \DCo k + \Co j - k - \Co + \Co \DCo > \Co \DCo,\ & j > k+1.
    \end{cases}
  \end{equation*}
  

  Справедливость неравенства $\min_{j \in J} \K*{1}(\pEven, \fEven, j) \geq 0,\ k \in \{0, m\}$, то есть, соответствующего значению $p \in \{0, 1\}$, очевидна.
\end{proof}

\begin{remark}
  \label{ch1:remark:posterior-probs}
  Если $p \in P$, то при применении инсайдером на первом шаге игры $\fEven$ и $\fOdd$, значения апостериорных вероятностей также принадлежат $P$.
  Таким образом, можно продолжить применение $\fEven$ и $\fOdd$ на последующих шагах игры, тем самым определив стратегию $\sigmar^*$ в игре $\theG*{n}(p),\ p \in P, \, n \in \mathbb{N}$.
\end{remark}

Обозначим гарантированный выигрыш первого игрока в игре $\theG*{n}(p)$ при применении стратегии $\sigmar$ через
\begin{equation*}
  \L*{n}(p, \sigmar) = \min_{\taur \in \Tau} \K*{n}(p, \sigmar, \taur).
\end{equation*}
Из утверждения~\ref{ch1:prop:K1-base} непосредственно следует, что
\begin{equation}
  \label{ch1:eq:L_1(p)}
  \begin{gathered}
  \L*{1}(\pEven, \fEven) = 0,\ k = \overline{0,m},\\
  \L*{1}(\pOdd, \fOdd) = \Co \DCo,\ k = \overline{0,m-1}.
  \end{gathered}
\end{equation}

Следуя \cite{domansky07}, опишем рекурсивную структуру игры $\theG*{n}(p)$.
Стратегию $\sigmar$ первого игрока в $n$-шаговой игре можно представить как
$(\sigmas{1}, \sigmara{i},\ i \in I)$, где $\sigmas{1}$ "--- ход первого игрока на первом шаге игры, а $\sigmara{i}$ "--- стратегия в игре продолжительности $n-1$, зависящая от ставки $i$ на первом шаге.
Аналогично стратегию второго игрока можно представить как $(\taus{1}, \taura{i},\ i \in I)$.
Тогда для функции выигрыша справедливо следующее представление
\begin{equation}
  \label{ch1:eq:recursive-structure}
  \K*{n}(p, \sigmar, \taur) = 
  \K*{1}(p, \sigmas{1}, \taus{1}) + 
  \sum_{i \in I} \qc{i} \K*{n-1}(\pac{H}{i}, \sigmara{i}, \taura{i}).
\end{equation}

При использовании стратегии $\sigmar^*$ в силу \eqref{ch1:eq:L_1(p)} и \eqref{ch1:eq:recursive-structure} для гарантированного выигрыша первого игрока в игре $\theG*{n}(p)$ справедливы формулы
\begin{equation}
  \begin{aligned}
    \label{ch1:eq:lowerBound:recurrence:function}
    \L*{n}\left(\frac{k + \Co}{m}, \sigmar^*\right)
    = \DCo\Co &+ \DCo\L*{n-1}\left(\frac{k}{m}, \sigmaran{*}{k}\right) + \\
    &+\Co\L*{n-1}\left(\frac{k+1}{m}, \sigmaran{*}{k+1}\right), \: k = \overline{0, m-1}, \\
    % 
    \L*{n}\left(\frac{k}{m}, \sigmar^*\right)
    &= \Co\L*{n-1}\left(\frac{k - 1 + \Co}{m}, \sigmaran{*}{k}\right) + \\
    &+ \DCo\L*{n-1}\left(\frac{k + \Co}{m}, \sigmaran{*}{k+1}\right), \: k = \overline{1, m-1}, \\
    % 
    \L*{n}(0, \sigmar^*) &= \L*{n}(1, \sigmar^*) = 0.
  \end{aligned}
\end{equation}

Так как $\L*{n}(p, \sigmar^*)$ не убывает по $n$ и ограничена сверху, то устремив $n$ к бесконечности, получим нижнюю оценку $\L*{\infty}(p)$ выигрыша первого игрока в игре $\theG*{\infty}(p), \, p \in P$.

Введем следующие обозначения:
\begin{align*}
  L_{2k} = \L*{\infty}(k/m), & \quad k = \overline{0, m},\\
  L_{2k+1} = \L*{\infty}((k+\Co)/m), & \quad k = \overline{0, m-1}.
\end{align*}
Тогда справедлива система уравнений:
\begin{equation}
  \label{ch1:eq:lowerRecurrence}
  \begin{gathered}
    L_{2k+1} = \DCo\Co + \DCo L_{2k} + \Co L_{2(k+1)}, \enskip k = \overline{0, m-1},\\
    L_{2k} = \Co L_{2k-1} + \DCo L_{2k+1}, \enskip k = \overline{1, m-1},\\
    L_0 = L_{2m} = 0.
  \end{gathered}
\end{equation}

Введем $(2m-1)\times(2m-1)$-матрицу $B$ и $(2m-1)$-вектор-столбец $b$:
\begin{equation*}
  B =
  \left(
    \begin{array}{cccccccc}
      1      & -\Co  & 0       & 0      & \cdots & 0      & 0       & 0       \\
      -\Co & 1       & -\DCo & 0      & \cdots & 0      & 0       & 0       \\
      0      & -\DCo & 1       & -\Co & \cdots & 0      & 0       & 0       \\
      \hdotsfor{8}                                                              \\
      0      & 0       & 0       & 0      & \cdots & -\Co & 1       & -\DCo \\
      0      & 0       & 0       & 0      & \cdots & 0      & -\DCo & 1 
    \end{array}
  \right),\quad
  %
  b = \left(
    \begin{array}{c}
      \DCo\Co \\
      0           \\
      \DCo\Co \\
      \cdots      \\
      0           \\
      \DCo\Co
    \end{array}
  \right).
\end{equation*}
Тогда (\ref{ch1:eq:lowerRecurrence}) перепишем в виде $ BL = b, L_0 = L_{2m} = 0, $ где $L = (L_1, L_2, \ldots, L_{2m-1})$.

Системы $ Mx = f $ с трехдиагональной матрицей $ M $, имеющей структуру
\[
  M = \left(\begin{array}{cccccccc}
              c_1 & b_1 & 0   & 0   & \cdots & 0       & 0       & 0       \\
              a_2 & c_2 & b_2 & 0   & \cdots & 0       & 0       & 0       \\
              0   & a_3 & c_3 & b_3 & \cdots & 0       & 0       & 0       \\
              \hdotsfor{8}                                                 \\
              0   & 0   & 0   & 0   & \cdots & a_{n-1} & c_{n-1} & b_{n-1} \\
              0   & 0   & 0   & 0   & \cdots & 0       & a_n     & c_n
            \end{array}\right),
\]
можно решать методом прогонки, используя следующие формулы для прогоночных коэффициентов и переменных (см. \cite{samarsky89}):
\begin{gather}
  \label{ch1:eq:tridiagonal-book}
  x_i = \gamma_{i+1} x_{i+1} + \delta_{i+1}, \: i = \overline{1,n-1},
  \quad
  x_n = \frac{f_n - a_n\delta_n}{c_n + a_n\gamma_n}, \\
  % 
  \gamma_{i+1} = -\frac{b_i}{c_i + a_i\gamma_i}, \: i = \overline{2,
    n-1}, \quad
  \gamma_2 = -\frac{b_1}{c_1}, \\
  % 
  \delta_{i+1} = \frac{f_i - a_i\delta_i}{c_i + a_i\gamma_i}, \: i =
  \overline{2, n-1}, \quad \delta_2 = \frac{f_1}{c_1}.
\end{gather}

\begin{proposition}
  \label{ch1:prop:tridiagonal:coefficients}
  Прогоночные коэффициенты для матрицы $B$ даются следующими формулами\textup{:}
  \begin{multline*}
    \gamma_{2k} = \frac{k-1+\Co}{k}, \,
    \gamma_{2k+1} = \frac{k}{k+\Co}, \\
    \delta_{2k} = \frac{\DCo(k-1+2\Co)}{2}, \, \delta_{2k+1} =
    \frac{k\Co(k-1+2\Co)}{2(k+\Co)}, \quad k = \overline{1,m-1}.
  \end{multline*}
\end{proposition}
\begin{proof}
  Проверим базу индукции для $\gamma_i,\ i = \overline{2, 2m-1}$.
  Имеем
  \begin{gather*}
    \gamma_2 = - \frac{-\Co}{1} = \Co,\\
    \gamma_3 = - \frac{-\DCo}{1 - \Co \cdot \Co} = \frac{1 - \Co}{(1 - \Co)(1 + \Co)} = \frac{1}{1 + \Co}.
  \end{gather*}
  Пусть утверждение верно для $\gamma_{2n}, \gamma_{2n+1}$ при $n \leq k$.
  Покажем, что соответствующие формулы имеют место при $n = k + 1$.
  Для $\gamma_{2(k+1)}$ имеем
  \begin{gather*}
    \gamma_{2(k+1)} =
    -\frac{b_{2k+1}}{c_{2k+1} + a_{2k+1} \gamma_{2k+1}} =
    \frac{\Co}{1 - \DCo k / (k+\Co)} = \frac{\Co (k + \Co)}{k + \Co - \DCo k} = \frac{k+\Co}{k + 1}.
  \end{gather*}
  Для $\gamma_{2k + 3}$ находим
  \begin{align*}
    \gamma_{2k+3} 
    &=
    - \frac{b_{2(k+1)}}{c_{2(k+1)} + a_{2(k+1)}\gamma_{2(k+1)}} = 
    \frac{\DCo}{1 - \Co (\Co + k)/(k+1)} = \\
    &= \frac{\DCo (k+1)}{k\DCo + \DCo(1+\Co)} =
    \frac{k + 1}{k + 1 + \Co}.
  \end{align*}
  Таким образом, утверждение доказано для $\gamma_i$.
  Проверим базу индукции для $\delta_i,\ i = \overline{2, 2m-1}$.
  Имеем
  \begin{gather*}
    \delta_2 = \frac{\Co \DCo}{1} = \frac{\DCo (1 - 1 + 2\Co)}{2},\\
    \delta_3 =
    \frac{f_2 - a_2 \delta_2}{c_2 + a_2 \gamma_2} =
    \frac{0 + \DCo \Co^2}{1 - \Co^2} =
    \frac{\Co^2}{1 + \Co} =
    \frac{1 \cdot \Co (1 - 1 + 2\Co)}{2(1+\Co)}.
  \end{gather*}
  Пусть утверждение верно для $\delta_{2n}, \delta_{2n+1}$ при $n \leq k$.
  Проверим справедливость соответствующих формул при $n = k+1$.
  Для $\delta_{2(k+1)}$ имеем
  \begin{align*}
    \delta_{2(k+1)} 
    &=
      \frac{f_{2k+1} - a_{2k+1}\delta_{2k+1}}{c_{2k+1} + a_{2k+1}\gamma_{2k+1}} =
      \frac{\DCo \Co + \DCo k\Co(k-1+2\Co)/(2(k+\Co))}{(k + \Co - \DCo k)/(k + \Co)} = \\
    &=
      \frac{\DCo \Co (k+\Co) + \DCo k \Co (k-1+2\Co)/2}{(k+1)\Co} =
      \frac{\DCo}{2(k+1)} \left( 
      2k + 2\Co + k^2 - k + 2 k \Co
      \right) = \\
    &=
      \frac{\DCo}{2(k+1)}\left(
      2\Co(k+1) + k(k+1)
      \right) =
      \frac{\DCo(k+2\Co)}{2}.
  \end{align*}
  Для $\delta_{2k+3}$ находим
  \begin{align*}
    \delta_{2k+3} 
    &=
      \frac{f_{2(k+1)} - a_{2(k+1)} \delta_{2(k+1)}}{c_{2(k+1)} + a_{2(k+1)}\gamma_{2(k+1)}} =
      \frac{0 + \Co \DCo (k + 2\Co)/2}{1 - \Co (\Co + k)/(k+1)} = \\
    &=
      \frac{\DCo \Co (k+2\Co)(k+1)}{2(k\DCo + \DCo(1+\Co))} =
      \frac{(k+1)\Co(k+2\Co)}{2(k+1+\Co)}.
  \end{align*}
  Таким образом, соответствующие формулы справедливы для $\delta_i$.
\end{proof}

\begin{proposition}
  \label{ch1:prop:lower:recurrence-solution}
  Решение системы {\normalfont(\ref{ch1:eq:lowerRecurrence})} дается
  следующими формулами\textup{:}
  \begin{gather}
    \label{ch1:eq:recurrence-solution:odd}
    L_{2k+1} = \frac{(m - k - \Co)(k + \Co) + \DCo\Co}{2} = \H*{\infty}(( k+\Co )/m), \quad k = \overline{0, m-1},\\
    \label{ch1:eq:recurrence-solution:even}
    L_{2k} = \frac{k (m-k)}{2} = \H*{\infty}( k/m ), \quad k = \overline{0, m}.
  \end{gather}
\end{proposition}
\begin{proof}
  Из \eqref{ch1:eq:tridiagonal-book} следует, что
  \begin{equation*}
    L_{2k-1} = \gamma_{2k}\gamma_{2k+1}L_{2k+1} + \gamma_{2k}\delta_{2k+1} + \delta_{2k}, \, k = \overline{1, m-1}.
  \end{equation*}
  Покажем, что подстановкой $\H*{\infty}((k+\Co)/m)$ вместо $L_{2k+1}$ это равенство обращается в тождество.
  Для первого слагаемого имеем
  \begin{align*}
    &2 \gamma_{2k} \gamma_{2k+1} \H*{\infty}( (k+\Co)/m ) =
      \frac{k-1+\Co}{k+\Co} ((m-k-\Co)(k+\Co) + \DCo \Co) = \\
    &=
      (m-k-\Co)(k-1+\Co) + \DCo \Co - \frac{\DCo\Co}{k+\Co} = \\
    &=
      (m-(k-1+\Co))(k-1+\Co) - (k-1+\Co) + \DCo \Co - \frac{\DCo\Co}{k+\Co}.
  \end{align*}
  Для второго слагаемого находим
  \begin{align*}
    &2(\gamma_{2k} \delta_{2k+1} + \delta_{2k}) 
    = \frac{(k-1+\Co)\Co(k-1+2\Co)}{k+\Co} + \DCo(k-1+2\Co) = \\
    &= \Co (k-1+2\Co) - \frac{\Co (k-1+2\Co)}{k+\Co} + \DCo (k-1+2\Co) = \\
    &= k - 1 + 2\Co - \frac{\Co(k+\Co-\DCo)}{k+\Co} = (k-1+\Co) + \frac{\DCo\Co}{k+\Co}.
  \end{align*}
  Отсюда получаем
  \begin{align*}
    &\gamma_{2k} \gamma_{2k+1} \H*{\infty}( (k+\Co)/m ) + \gamma_{2k} \delta_{2k+1} + \delta_{2k} = \\
    &= \frac{1}{2}\biggl(
    (m-(k-1+\Co))(k-1+\Co) -
    (k-1+\Co) + \DCo \Co - \frac{\DCo\Co}{k+\Co} + \\
    &+ (k-1+\Co) + \frac{\DCo\Co}{k+\Co}
    \biggr) =
    \frac{1}{2} \left(
    (m-(k-1+\Co))(k-1+\Co) + \DCo\Co
    \right) =\\
    &= \H*{\infty}( (k-1+\Co)/m ).
  \end{align*}
  Справедливость \eqref{ch1:eq:recurrence-solution:odd} установлена.
  Далее, имеем
  \begin{align*}
    2 \H*{\infty}( (k-1+\Co)/m ) 
    &= (m-k-\Co+1)(k-1+\Co) = \\
    &= (m-k-\Co)(k+\Co) - m + 2k + \Co - \DCo.
  \end{align*}
  Отсюда получаем
  \begin{align*}
    2 L_{2k} 
    &= 2 (\Co L_{2k-1} + \DCo L_{2k+1}) = (m-k-\Co)(k+\Co) + \Co \DCo - \Co (m - 2k - \Co + \DCo) = \\
    &= (m-k)k + \Co(m-2k-\Co+\DCo) - \Co(m-2k-\Co+\DCo) = (m-k)k.
  \end{align*}
  Таким образом, установлена справедливость \eqref{ch1:eq:recurrence-solution:even}.
\end{proof}

Итак, мы определили функцию $\L*{\infty}(p)$ при $p \in P$.
Для $p \in [0, 1] \setminus P$ стратегия инсайдера основана на применении выпуклых комбинаций (с разными коэффициентами) распределений полных и апостериорных вероятностей, отвечающих одношаговым стратегиям вида $\fOdd$, которые соответствуют концам интервала, в котором находится $p$.

Для $p = \lambda \pOdd + (1-\lambda) \pEven[k+1],\ \lambda \in (0, 1)$ обозначим через $\lambda\fOdd[k] + (1-\lambda)\fEven[k+1]$ распределение, при котором первый игрок рандомизирует выбор ставок $k, k+1, k+2$ с параметрами
\begin{align*}
  \qc{k} = \lambda\DCo, &\quad \pac{H}{k} = \pEven,\\
  \qc{k+1} = \Co, &\quad \pac{H}{k+1} = \lambda \pEven[k+1] + (1-\lambda) \pOdd,\\
  \qc{k+2} = (1-\lambda)\DCo, &\quad \pac{H}{k+2} = \pOdd[k+1].
\end{align*}

Для $p = \lambda \pEven + (1-\lambda) \pOdd,\ \lambda \in (0, 1)$ через $\lambda\fEven + (1-\lambda)\fOdd$ обозначим распределение, при котором первый игрок рандомизирует выбор ставок $k$ и $k+1$ с параметрами
\begin{gather*}
  \qc{k} = \lambda\Co + (1-\lambda)(1-\Co),\enskip
  \pac{H}{k} = \frac{\lambda\Co}{\qc{k}}\pOdd[k-1] + \frac{(1-\lambda)(1-\Co)}{\qc{k}} \pEven,\\
  \qc{k+1} = \lambda(1-\Co) + (1-\lambda)\Co,\enskip
  \pac{H}{k+1} = \frac{\lambda(1-\Co)}{\qc{k+1}}\pOdd[k] + \frac{(1-\lambda)\Co}{\qc{k+1}}\pEven[k+1].
\end{gather*}

\begin{proposition}
  \label{ch1:prop:first:combination:step}
  При $\lambda \in (0, 1), \, k = \overline{0, m-1},$ при использовании распределений $\lambda\fEven + (1-\lambda)\fOdd$ и $\lambda\fOdd[k] + (1-\lambda)\fEven[k+1]$ для одношагового гарантированного выигрыша первого игрока верны оценки
  \begin{align*}
    \min_{j \in J}
    \K*{1}(%
    \lambda \pEven + (1-\lambda) \pOdd,\
    \lambda \fEven + (1-\lambda) \fOdd,\
    j)
    &\geq \DCo \Co (1-\lambda), \\
    % 
    \min_{j \in J}
    \K*{1}(%
    \lambda \pOdd + (1-\lambda) \pEven[k+1],\
    \lambda \fOdd + (1-\lambda) \fEven[k+1],\
    j)
    &\geq \DCo \Co \lambda.
  \end{align*}
\end{proposition}
\begin{proof}
  Из \eqref{ch1:eq:firstPlayerPayoff} находим, что для произвольной одношаговой стратегии $\sigmar$ с параметрами $(\qc{i}, \pac{H}{i},\ i \in I)$ выполняется
  \begin{align*}
    \K*{1}(p, \sigmar, j) 
    &= \sum_{i \in I} p \sigmas[H]{i} \as[H](i, j) + (1-p) \sigmas[L]{i} \as[L](i, j) = \\
    &= \sum_{i \in I} \qc{i} (\pac{H}{i} \as[H](i, j) + (1-\pac{H}{i}) \as[L](i, j)).
  \end{align*}
  
  Далее, пусть априорной вероятности $p_1 \in [0, 1]$ отвечает одношаговая стратегия $\sigmar^1$ с параметрами $(\qcn{1}{i}, \pacn{1}{H}{i},\ i \in I)$, а априорной вероятности $p_2 \in [0, 1]$, отвечает стратегия $\sigmar^2$ с параметрами $(\qcn{2}{i}, \pacn{2}{H}{i},\ i \in I)$.
  Определим для $p = \lambda p_1 + (1-\lambda) p_2$ одношаговую стратегию $\sigmar^c$ с параметрами
  \begin{equation*}
    \qcn{c}{i} = \lambda \qcn{1}{i} + (1-\lambda) \qcn{2}{i}, \enskip
    \pacn{c}{H}{i} = \frac{\lambda \qcn{1}{i} \pacn{1}{H}{i} + (1-\lambda) \qcn{2}{i} \pacn{2}{H}{i}}{\qcn{c}{i}}.
  \end{equation*}
  Одношаговый выигрыш при применении такой стратегии в игре с априорной вероятностью $p = \lambda p_1 + (1-\lambda) p_2$ равен
  \begin{multline*}
    \K*{1}(\lambda p_1 + (1-\lambda) p_2, \sigmar^c, j) = \sum_{i \in I} \qcn{c}{i} \biggl(
    \frac{\lambda \qcn{1}{i} \pacn{1}{H}{i}
      + (1-\lambda) \qcn{2}{i} \pacn{2}{H}{i}}{\qcn{c}{i}} \times \\
    \times \as[H](i, j)
    + \frac{\lambda \qcn{1}{i} (1-\pacn{1}{H}{i})
      + (1-\lambda) \qcn{2}{i} (1-\pacn{2}{H}{i})}{\qcn{c}{i}} \as[L](i, j)
     \biggr) = \\
    = \lambda \sum_{i \in I} \qcn{1}{i} (\pacn{1}{H}{i} \as[H](i, j) + (1-\pacn{1}{H}{i}) \as[L](i, j)) + \\
    + (1-\lambda) \sum_{i \in I} \qcn{2}{i} (\pacn{2}{H}{i} \as[H](i, j) + (1-\pacn{2}{H}{i}) \as[L](i, j)) = \\
    = \lambda \K*{1}(p_1, \sigmar^1, j) + (1-\lambda) \K*{1}(p_2, \sigmar^2, j).
  \end{multline*}
  
  Нетрудно проверить, что определенные выше распределения $\lambda \fOdd + (1-\lambda) \fEven[k+1]$ и $\lambda \fEven + (1-\lambda) \fOdd$ отвечают именно таким выпуклым комбинациям распределений полных и апостериорных вероятностей.
  Отсюда и из утверждения~\ref{ch1:prop:K1-base} следует справедливость данного утверждения.
\end{proof}

\begin{remark}
  Одношаговая стратегия $\sigmar^c$ из утверждения~\ref{ch1:prop:first:combination:step} не является линейной комбинацией одношаговых стратегий $\sigmar^1$ и $\sigmar^2$ в смысле покомпонентного равенства:
  \[
    \sigma^{c,H}_i \neq \lambda \sigma^{1,H}_i + (1-\lambda) \sigma^{2,H}_i,\ i \in I.
  \]
\end{remark}

Пусть $\sigmar^*$ для $p \in [0,1] \setminus P$ состоит в применении $\sigmar^c$ из утверждения~\ref{ch1:prop:first:combination:step}, причем на последующих шагах игры $\theG*{n}(p),\ n \in \N$ одношаговая стратегия $\sigmar^c$ рекурсивно применяется для соответствующих значений апостериорных вероятностей.

\begin{proposition}
  \label{ch1:prop:first:combination:game}
  При $\lambda \in (0, 1), \, k = \overline{0, m-1}$, и использовании первым игроком стратегии $\sigmar^*$ для его одношаговых гарантированных выигрышей в игре $\theG*{\infty}(p)$ справедливы равенства
  \begin{align*}
    \L*{\infty}(\lambda \pEven + (1-\lambda) \pOdd)      
    &= 
      \lambda \L*{\infty}(\pEven) + (1-\lambda) \L*{\infty}(\pOdd), \\
    \L*\infty(\lambda \pOdd + (1-\lambda) \pEven[k+1]) 
    &= \lambda \L*{\infty}( \pOdd ) + (1-\lambda) \L*{\infty}(\pEven).
  \end{align*}
\end{proposition}
\begin{proof}
  Пусть $p = \lambda \pOdd + (1-\lambda) \pEven[k+1],\ k = \overline{0, m - 2}, \, \lambda \in (0, 1)$.
  Тогда по аналогии с \eqref{ch1:eq:lowerBound:recurrence:function} выписывается следующая рекуррентная формула:
  \begin{align*}
    \L*{n}(p, \sigmar^*)
    &= \DCo \Co \lambda +
      \lambda \DCo \L*{n-1}(\pEven, \sigmaran{*}{k}) +
      (1-\lambda) \DCo \L*{n-1}(\pOdd[k+1], \sigmaran{*}{k+2}) + \\
    &+ \Co \L*{n-1}((1-\lambda) \pOdd + \lambda \pEven[k+1], \sigmaran{*}{k+1}),
  \end{align*}
  откуда предельным переходом при $n \rightarrow \infty$ получаем
  \begin{equation}
    \label{ch1:eq:prop:L(comb)}
    \begin{aligned}
    \L*{\infty}(p) 
    &= \DCo \Co \lambda +
    \lambda \DCo \L*{\infty}(\pEven) +
    (1-\lambda) \DCo \L*{\infty}(\pOdd[k+1]) + \\
    &+ \Co \L*{\infty}( (1-\lambda) \pOdd + \lambda \pEven[k+1] ).
    \end{aligned}
  \end{equation}
  
  Так как $(1-\lambda)\pOdd + \lambda \pEven[k+1] \in (\pOdd, \pEven[k+1])$, то для
  $\L*{\infty}( (1-\lambda)\pOdd + \lambda \pEven[k+1] )$ справедливо аналогичное представление:
  \begin{align*}
    \L*{\infty}( (1-\lambda)\pOdd + \lambda \pEven[k+1] ) 
    &=
    \DCo\Co(1-\lambda) +
    (1-\lambda)\DCo\L*{\infty}( \pEven ) + \\
    &+ \lambda\DCo\L*{\infty}( \pOdd[k+1] ) +
    \Co \L*{\infty}( p ).
  \end{align*}
  Подставив данное выражение в~\eqref{ch1:eq:prop:L(comb)} и приведя подобные члены, получим

  \begin{equation}
    \label{ch1:eq:first:combination:game:2}
    \begin{aligned}
      \L*{\infty}(p) 
      &= 
      \frac{1}{1-\Co^2}
      \left(
        \DCo\Co\lambda + 
        \DCo\lambda\L*{\infty}(\pEven) + 
        (1-\lambda)\DCo\L*{\infty}(\pOdd[k+1]) + 
      \right.\\
      % 
      &\left. 
        + \Co \left( 
          \DCo\Co(1-\lambda) +
          (1-\lambda)\DCo\L*{\infty}(\pEven) +
          \lambda\DCo\L*{\infty}(\pOdd[k+1]) 
        \right)
      \right) = \\
      % 
      &=
      \left( (k + 1)(m - k - 1) + \DCo\lambda(2k - m + 2\Co + 1)
      \right)/2 = \\
      &=
      \lambda\L*{\infty}(\pOdd) + (1-\lambda)\L*{\infty}(\pEven[k+1]).
    \end{aligned}
  \end{equation}
  
  Пусть $p = \lambda\pEven + (1-\lambda)\pOdd$, где $k = \overline{1, m - 1}, \, \lambda \in (0, 1)$.
  Заметим, что $\pac{H}{k} \in ( \pOdd[k-1], \pEven )$, а $\pac{H}{k+1} \in ( \pOdd, \pEven[k+1] )$.
  Тогда с помощью \eqref{ch1:eq:first:combination:game:2} получим
  \begin{multline*}
    \L*{\infty}(p) =
    \lambda \Co \L*{\infty}(\pOdd[k-1]) + 
    (1-\lambda)(1-\Co)\L*{\infty}(\pEven) + \lambda(1-\Co)\L*{\infty}(\pOdd) + \\
    + (1-\lambda)\Co\L*{\infty}(\pEven[k+1]) 
    = \lambda \L*{\infty}(\pEven) + (1-\lambda) \L*{\infty}(\pOdd).
  \end{multline*}
  
  При $p \in ( 0, \pOdd[1] )$ и $p \in ( \pOdd[m-1], 1 )$ доказательство проводится аналогично.
\end{proof}

Таким образом, мы определили соответствующий гарантированный выигрыш первого игрока $\L*{\infty}(p)$ для любых $p \in [0, 1], \, \Co \in (0, 1)$.
Отсюда вытекает справедливость следующей леммы.

\begin{lemma}
  \label{ch1:lemma:first:lower}
  При использовании первым игроком стратегии $\sigmar^*$ в игре $\theG*{\infty}(p)$\textup{,} его выигрыш ограничен снизу величиной $\L*{\infty}(p)$\textup{,} т.е.
  \[
    \min_{\taur \in \Tau} \K*{\infty}(p, \sigmar^*, \taur) \geq \L*{\infty}(p).
  \]
\end{lemma}

\section{Значение игры $\mathbf{G^{m,\beta}_\infty(p)}$}\label{ch1:game-value}

\begin{theorem}
  Игра $\theG*{\infty}(p)$ имеет значение $\V*{\infty}(p) = \H*{\infty}(p) = \L*{\infty}(p)$.
  При этом $\sigmar^*$ -- оптимальная стратегия первого игрока\textup{,} а $\taur^*$ -- оптимальная стратегия второго игрока.
\end{theorem}
Доказательство данной теоремы непосредственно следует из леммы~\ref{ch1:lemma:upperBound} и утверждения~\ref{ch1:prop:lower:recurrence-solution} и по форме повторяет доказательство аналогичной теоремы в~\cite{domansky07}.

\begin{proposition}
  \label{ch1:prop:value-comparison}
  При любом значении $p \in [0,1]$, $\Co \in (0,1)$ и $m \geq 3$ справедливо неравенство
  \begin{equation*}
    \V*[\Co]{\infty}(p) \geq \V*[1]{\infty}(p) = \V*[0]{\infty}(p),
  \end{equation*}
  причем равенство достигается только при $p = k/m, k = \overline{0,m}$.
\end{proposition}
\begin{proof}
  Равенство $\V*[1]{\infty}(p) = \V*[0]{\infty}(p)$ следует из замечания~\ref{ch1:rem:symm-payoffs} и того, что при $p = k/m$ выполняется
  \begin{equation*}
    \V*[1]{\infty}(p) = \V*[0]{\infty}(1-p) = \frac{(m-k)(m-(m-k))}{2} = \frac{k(m-k)}{2} = \V*[0]{\infty}(p).
  \end{equation*}
  Далее, из (\ref{ch1:eq:recurrence-solution:even}) следует, что нам достаточно показать, что 
  \[
    \V*[\Co]{\infty}((k+\Co)/m) > \V*[1]{\infty}((k+\Co)/m).
  \]
  В силу того, что $(k+\Co)/m = \DCo k/m + \Co (k+1)/m$, получаем
  \begin{gather*}
    \V*[\Co]{\infty}((k+\beta)/m) - \DCo \V*[1]{\infty}(k/m) - \Co \V*[1]{\infty}((k+1)/m) = 2\DCo > 0.
  \end{gather*}
  Отсюда следует справедливость данного утверждения.
\end{proof}

\begin{figure}[b]
  \centering
  \begin{tikzpicture}[yscale=1.5,xscale=8]
    \draw[thick,->,>=stealth'] (-0.1,0) -- (1.1,0) node[right] {$p$};
    \draw[thick] (0,-0.1) -- (0,0.1);
    \node[anchor=north east] at (0,0) {$0$};
    \draw[thick] (1,-0.1) -- (1,0.1);
    \node[anchor=north west] at (1,0) {$1$};

    \draw[thick] plot file {plots/ch1-v0.5.dat};
    \draw[very thick,dashed] plot file {plots/ch1-v1.dat};
    
    \node at (0.86, 2.6) {$\V*[1/2]{\infty}(p)$};
    \node at (0.55, 2.6) {$\V*[1]{\infty}(p)$};
  \end{tikzpicture}
  \caption{Графики функции $\V*{\infty}(p)$ при значениях $\Co = 1/2$ и $\Co = 1$}
  \label{ch1:fig:value-comparison}
\end{figure}

Таким образом, из всех рассматриваемых механизмов торгов, те механизмы, которые предписывают продавать акцию по наибольшей или наименьшей предложенной цене, гарантируют инсайдеру наименьший возможный выигрыш.

\section{Динамика апостериорных вероятностей}
Рассмотрим динамику апостериорных вероятностей, возникающую при применении игроками оптимальных стратегий.

Пусть $p \in P$. Обозначим через $p^t$ апостериорную вероятность состояния $H$ после $t$-го шага игры, причем $p^0 = p$ соответствует исходной априорной вероятности.
Тогда из замечания~\ref{ch1:remark:posterior-probs} и рекурсивной структуры игры $\theG*{\infty}(p)$ следует, что последовательность $(p^0, p^1, p^2, \ldots, p^t, \ldots)$ представляет собой однородную марковскую цепь с $2m$ состояниями и $2m \times 2m$-матрицей переходных вероятностей
\begin{equation}
  \label{ch1:eq:posterior-chain}
  \Pi = 
  \left(
    \begin{array}{ccccccccc}
      1    & 0   & 0   & 0    & \ldots & 0   & 0    & 0    & 0   \\
      \DCo & 0   & \Co & 0    & \ldots & 0   & 0    & 0    & 0   \\
      0    & \Co & 0   & \DCo & \ldots & 0   & 0    & 0    & 0   \\
      \hdotsfor{9}                                               \\
      0    & 0   & 0   &      & \ldots & \Co & 0    & \DCo & 0   \\
      0    & 0   & 0   &      & \ldots & 0   & \DCo & 0    & \Co \\
      0    & 0   & 0   &      & \ldots & 0   & 0    & 0    & 1
    \end{array}
 \right).
\end{equation}

Занумеруем состояния данной марковской цепи следующим образом:
\begin{gather*}
  p_{2k} = \frac{k}{m}, \quad k = \overline{0, m}, \quad
  p_{2k+1} = \frac{k+\Co}{m}, \quad k = \overline{0, m-1}.
\end{gather*}

Из \eqref{ch1:eq:posterior-chain} видно, что состояния $p_0$ и $p_{2m}$ являются поглощающими.
Они соответствуют моменту игры, в который происходит полное раскрытие приватной информации первого игрока, т.е. моменту, когда второму игроку становится доподлинно известно истинное состояние $s$.
Случайная величина
\begin{equation*}
  \xi \eqdef \min \left\{ t \geq 0: p^t \in \{p_0, p_{2m}\} \right\}
\end{equation*}
соответствует моменту поглощения. Величина
\begin{equation*}
  \tau(p_k) \eqdef \E \{ \xi\ |\ p^0 = p_k \}
\end{equation*}
определяет ожидаемую продолжительность игры, при условии, что априорная вероятность равна $p_k$.

Обозначим через $\pi^l_i,\ \pi^r_i,\ i \in \overline{1, 2m-1}$ вероятности перехода из состояния $p_i$ в состояния $p_{i-1}$ и $p_{i+1}$ соответственно.

\begin{figure}[tb]
  \centering
  \input{figures/ch1-posterior-markov}
  \caption[Последовательность апостериорных вероятностей]{Марковская цепь,
    соответствующая последовательности апостериорных вероятностей}
  \label{ch1:fig:posterior-markov}
\end{figure}

\begin{proposition}
  \label{ch1:prop:game-duration}
  Ожидаемая продолжительность игры $\theG*{\infty}(p_k)$ выражается формулами
  \begin{equation*} 
    \tau(p_{2k+1}) = \frac{(m-k-\Co)(k+\Co)}{\Co \DCo},\quad
    \tau(p_{2k}) = \frac{k(m-k)}{\Co \DCo}.
  \end{equation*}
\end{proposition}
\begin{proof}
  Известно, что ожидаемое время до поглощения для марковских цепей имеющих структуру, изображенную на рисунке~\ref{ch1:fig:posterior-markov}, выражается следующим образом (\seename \cite[\S~12]{shiryaev11}):
  \begin{gather}
    \label{ch1:prop:game-duration:eq:1}
    \tau(p_j) =
    \sum_{i=0}^{j-1} \rho_i \cdot
    \frac{\sum_{i=0}^{2m-1} R_i}{\sum_{i=0}^{2m-1} \rho_i} -
    \sum_{i=0}^{j-1} R_i,
  \end{gather}
  где
  \begin{gather*}
  \rho_0 = 1, \quad
    \rho_j = \frac{\pi^l_1 \ldots \pi^l_j}{\pi^r_1 \ldots \pi^r_j}, \quad j \geq 1,\\
    R_0 = 0, \quad
    R_1 = \frac{1}{\pi^r_1}, \quad
    R_j = \frac{1}{\pi^r_j}\left( 
      1 + 
      \frac{\pi^l_j}{\pi^r_{j-1}} + 
      \ldots + \frac{\pi^l_j \ldots \pi^l_2}{\pi^r_{j-1} \ldots \pi^r_1}
    \right), \quad j \geq 2.
  \end{gather*}
  Нетрудно проверить, что для коэффициентов $\rho_j$, $R_j$ выполняются равенства
  \begin{gather*}
    \rho_{2k+1} = \frac{\DCo}{\Co},\quad k = \overline{0, m-1},\quad
    \rho_{2k} = 1,\quad k = \overline{1, m-1},\\
    R_k = \frac{k}{\pi^r_k},\quad k = \overline{1, 2m-1}.
  \end{gather*}
  Отсюда получаем
  \begin{equation}
    \label{ch1:prop:game-duration:eq:2}
    \begin{gathered}
      \sum_{i=0}^{2k-1} \rho_i = k + k \frac{\DCo}{\Co} = \frac{k}{\Co},\\
      \sum_{i=0}^{2k-1} R_i = \frac{k^2}{\Co} + \frac{k(k-1)}{\DCo} = \frac{k(k-\Co)}{\Co\DCo}.
    \end{gathered}
  \end{equation}
  Из \eqref{ch1:prop:game-duration:eq:1} и \eqref{ch1:prop:game-duration:eq:2} находим
  \begin{gather}
    \label{ch1:prop:game-duration:eq3}
    \tau(p_{2k}) =
    \frac{k}{\Co} \frac{m-\Co}{\DCo} - \frac{k(k-\Co)}{\Co\DCo} =
    \frac{k(m-k)}{\Co\DCo}.
  \end{gather}

  Заметим, что имеет место следующее равенство:
  \begin{equation}
    \label{ch1:prop:game-duration:eq4}
    \tau(p_{2k+1}) = 1 + \DCo \tau(p_{2k}) + \Co \tau(p_{2(k+1)}).
  \end{equation}
  Справедливость формулы для $\tau(p_{2k+1})$ проверяется подстановкой~\eqref{ch1:prop:game-duration:eq3} в выражение~\eqref{ch1:prop:game-duration:eq4}.
\end{proof}

В силу того, что первый игрок получает положительные выплаты размера $\Co\DCo$ только в состояниях $p_i$ с нечетными номерами, то его выигрыш за игру равен среднему количеству посещенных нечетных состояний, умноженных на одношаговую выплату. В частности, при $p = p_{2k+1}$ и первое, и последнее состояние дают положительный выигрыш. Отсюда получаем
\begin{equation*}
  \frac{\tau(p_{2k+1}) + 1}{2} \cdot \Co\DCo = \frac{(m-k-\Co)(k+\Co) + \Co\DCo}{2}.
\end{equation*}
Аналогично при $p = p_{2k}$ имеем
\begin{equation*}
  \frac{\tau(p_{2k})}{2} \cdot \Co\DCo = \frac{k(m-k)}{2}.
\end{equation*}
Данные результаты согласуется с формулами (\ref{ch1:eq:recurrence-solution:odd},~\ref{ch1:eq:recurrence-solution:even}).

Нужно отметить, что в сравнении со случайным блужданием апостериорных вероятностей, порождаемым оптимальной стратегией инсайдера из \cite{domansky07}, случайное блуждание, рассмотренное выше, имеет более сложный характер: в дополнение к точками $k/m$ оно включает точки $(k+\Co)/m$, кроме того, оно больше не является симметричным, за исключением случая $\Co = 1/2$.

}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../dissertation"
%%% End:
