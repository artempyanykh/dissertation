\chapter{Теоретико-игровая модель биржевых торгов с дискретными ставками для рынка с
  двумя состояниями} \label{chapt1} 
{
%%% Chapter 1 commands
\newcommand{\generalGame}[2]{G_{#1}^m\left({#2}\right)}
\newcommand{\infiniteGame}[1]{G_{\infty}^m\left({#1}\right)}
\newcommand{\firstPlayerPayoff}[4]{K_{#1}^m\left({#2}, {#3}, {#4}\right)}
\newcommand{\infiniteFirstPlayerPayoff}[3]{K_{\infty}^m\left({#1}, {#2}, {#3}\right)}
\newcommand{\gameValue}[2]{V_{#1}^m\left({#2}\right)}
\newcommand{\infiniteGameValue}[1]{V_{\infty}^m\left({#1}\right)}
\newcommand{\symm}[1]{\overline{#1}}
\newcommand{\symmGameExpression}[2][\infty]{G_{#1}^{m, \DCo}\left({#2}\right)}
\newcommand{\upperBound}[1]{H_{\infty}^m\left({#1}\right)}
\newcommand{\fGeneral}[2][1]{\sigma_{#1}^{#2}}
\newcommand{\pEven}[1][k]{p^0_{#1}}
\newcommand{\pOdd}[1][k]{p^{\beta}_{#1}}
\newcommand{\fEven}[1][k]{\phi^0_{#1}}
\newcommand{\fOdd}[1][k]{\phi^{\beta}_{#1}}
\newcommand{\fOpt}{\sigma^*}
\newcommand{\lowerBound}[2][\infty]{L_{#1}^m\left({#2}\right)}

В разделе~\ref{ch1:intro} данной работы дано введение в теорию повторяющихся игр с неполной информацией, определены основные термины и понятия.
В разделе~\ref{ch1:model} приведено описание модели биржевых торгов с дискретными ставками, которая в разделе~\ref{ch1:formal-def} формализована в виде игры в нормальной форме.
Раздел~\ref{ch1:upper-bound} посвящен получению оценки сверху выигрыша инсайдера.
Оценка снизу выигрыша инсайдера найдена в разделе~\ref{ch1:lower-bound}.
В разделе~\ref{ch1:game-value} дана теорема о значении игры, исследована динамика апостериорных вероятностей при применении игроками оптимальных стратегий и проведено сравнение полученных результатов с результатами из~\cite{domansky07}.

Основные результаты данной главы опубликованы в работах~\cite{pyanykh14,pyanykh16:discr:ru} в журналах из перечня ВАК.

\section{Основные понятия}\label{ch1:intro}
Далее последует описание повторяющейся игры с неполной информацией в смысле Аумана"--~Машлера, т.е. такие игры, в которых множество состояний конечно, как и множества возможных действий игроков (см. монографию \cite{aumann95}). 
Теоретико-игровые постановки задач из глав~\ref{chapt2} и~\ref{chapt3} будут отличаться от данного классического описания, о чем будет сказано отдельно.

Рассмотрим антагонистическую игру двух лиц, которая повторяется $n$ раз, где $n\leq \infty$.
Будем считать, что игрок~1 знает функцию выигрыша в данной игре, в то время как игрок~2 такой информацией не обладает.
Однако второй игрок знает, что настоящая функция выигрыша является одной из $\kappa$ возможных альтернатив.
Каждой такой альтернативе игрок~2 приписывает некоторую вероятность того, что данная функция выигрыша является истинной функцией выигрыша в рассматриваемой
игре.
Таким образом, априорные убеждения игрока~2 задаются вероятностным вектором %
$
  \po = (p^0_1, p^0_2, \ldots, p^0_\kappa),\ \text{где } \sum_{i=1}^\kappa p^0_i = 1.
$

С данными функциями выигрыша можно связать игры $G_1, G_2, \ldots, G_\kappa$.
В дальнейшем мы будем считать, что информационная неопределенность игрока~2 заключается именно в том, что он не знает какая из игр $G_1, G_2, \ldots, G_\kappa$ разыгрывается.

На каждом шаге игры первый игрок может совершать действия из множества $I$, второй игрок --- действия из множества $J$, при этом мы считаем, что множества действий одного игрока известно другому.
Кроме того, положим, что игрок~2 знает, что первый обладает точной информацией о том, какая именно игра разыгрывается, а игрок~1 знает априорные убеждения второго.

\begin{figure}[t]
  \centering
  \input{figures/ch1-game-structure}
  \caption{Структура повторяющейся игры}
  \label{ch1:fig:game_structure}
\end{figure}

Игры $G_1, G_2, \ldots, G_\kappa$ будем называть \emph{одношаговыми играми}.
Все одношаговые игры описываются матрицами размера $|I| \times |J|$, где элементы матрицы задают выплаты игроку~1.
Мы предполагаем, что оба игрока точно знают платежные матрицы игр $G_1, G_2, \ldots, G_\kappa$.
На каждом шаге игры первый игрок выбирает номер строки, и одновременно с ним второй игрок выбирает номер столбца.
В конце каждого хода действия игроков оглашаются, и элемент из матрицы, отвечающей настоящей игре, прибавляется к выигрышу игрока 1 и вычитается из выигрыша игрока 2.
Таким образом, игрок 1 знает свой выигрыш на каждом этапе игры, в то время как игрок 2 может лишь рассчитать свой ожидаемый выигрыш.
В завершение, мы считаем, что данное описание известно обоим игрокам.

Данная игра с неполной информацией сводится к игре с полной информацией следующим образом.
Обозначим через $S = \{1, 2, \ldots, \kappa\}$ множество возможных альтернатив или \emph{состояний природы}.
Перед началом игры ходом случая в соответствии с вероятностным распределением $\po$ выбирается состояние $s \in S$.
Далее на протяжении $n$ шагов разыгрывается игра $G_s$.
Игрок 1 информирован о результате хода случая, игрок 2 "--- нет.
В остальном правила данной игры совпадают с описанными выше.

Обозначим $h_t = \left((i_1, j_1), (i_2, j_2), \ldots, (i_t, j_t)\right)$ историю ходов игроков к шагу $t = \overline{1, n}$. Также обозначим через $H_t$ множество всех историй, которые могли реализоваться к шагу $t$. 

Стратегией игрока~1 в такой игре является последовательность ходов $\sigma = (\sigma_1, \sigma_2, \ldots, \sigma_n)$, где $\sigma_t = (\sigma^1_t, \sigma^2_t, \ldots, \sigma^\kappa_t)$, и $\sigma^s_t: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от предыдущих ходов, которую игрок~1 использует если ходом случая реализовалось состояние $s$.

Аналогичным образом, определим стратегиею игрока~2 как последовательность ходов $\tau = (\tau_1, \tau_2, \ldots, \tau_n)$, где $\tau_t: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от предыдущих ходов.
Как видно, ход второго игрока на каждом шаге игры зависит только от предыдущих ходов, и не зависит от состояния, в силу того, что второй игрок не информирован о результате хода случая.

Обозначим описанную таким образом игру через $G_n(\po)$. Предположим, что эта игра имеет значение, и стратегии $\sigma^*,\ \tau^*$ являются оптимальными\footnote{Точные определения значения игры и оптимальных стратегий будут даны позднее.}.
Тогда стратегия $\tau^*$ является оптимальной и в изначальной игре с неполной информацией, как и стратегия $\sigma^{*s}$, полученная из $\sigma^*$ отбрасыванием на каждом шаге всех компонент кроме $s$-ой.
Справедливо и обратное.
Если существуют такие $(\sigma^{*1}, \tau^*), (\sigma^{*2}, \tau^*), \ldots, (\sigma^{*\kappa}, \tau^*)$, что пара $(\sigma^{*s}, \tau)$ является оптимальной в оригинальной игре с неполной информацией при условии, что на самом деле разыгрывается $G_s$, то стратегия $\sigma^*$, полученная из $(\sigma^{*1}, \sigma^{*2}, \ldots, \sigma^{*\kappa})$, и стратегия $\tau^*$ являются оптимальными в игре $G_n(\po)$.

Таким образом, для того, чтобы найти решение исходной игры с неполной информацией, достаточно проанализировать игру $G_n(\po)$.
Отметим также, что, как показано в~\cite{aumann95}, достаточно рассматривать только стратегии, которые зависят только от предыдущих ходов игрока~1 и не зависят от ходов игрока~2.

\section{Описание модели}\label{ch1:model}
Рассмотрим упрощенную модель финансового рынка, на котором два игрока ведут торговлю однотипными акциями на протяжении $n \leqslant \infty$ шагов, следуя работе~\cite{domansky07}.

Перед началом торгов случайный ход определяет цену акции на весь период торгов, которая может быть либо $m \in \N$ с вероятностью $p$, либо $0$ с вероятностью $1-p$.
Таким образом определенный ход случая является упрощенным аналогом некоторого шокового события на финансовом рынке.
Такого, например, как публикация отчетов о доходах некоторой компании.
Выбранная цена сообщается первому игроку и не сообщается второму, при этом второй игрок знает, что первый "--- инсайдер.

Рассмотрим $t$-й шаг торгов, где $t = \overline{1,n}$.
На данном шаге первый игрок выбирает ставку $i_t \in I = \{0, 1, \ldots, m\}$, а второй --- ставку $j_t \in J = \{0, 1, \ldots, m\}$.
Игрок предложивший б\'{о}льшую ставку покупает у другого акцию по цене равной
\[
  \Co \max(i_t, j_t) + \DCo \min(i_t, j_t),\ \text{где } %
  \Co \in (0, 1),\ \DCo = 1 - \Co.
\]
Если ставки равны, то сделка на $t$-м шаге не состоится.
Коэффициент $\Co$ можно интерпретировать как \emph{переговорную силу продавца} "--- чем ближе значение к $1$, тем большую сумму получит продавец акции в результате сделки.

Будем считать, что игроки обладают неограниченными запасами рисковых и безрисковых активов, т.е. торги не могут прекратиться по причине того, что у одного из игроков закончатся деньги или акции.
Цель игроков состоит в максимизации стоимости итогового портфеля, состоящего из некоторого числа купленных акций и суммы денег, полученных в результате торгов.
Таким образом, не ограничивая общности, можно положить, что в начальный момент времени оба игрока имеют нулевые портфели.

Фактически, в работах~\cite{domansky07, demeyer05}, а также в работах~\cite{domansky11, domansky13, domansky14}, посвященных обобщению дискретной модели, коэффициент $\Co = 1$.
Мотивацией к рассмотрению дискретной модели служит тот факт, что на реальных рынках расчеты ведутся пропорционально минимальной денежной единице.
При $\Co = 1$ все ставки будут целочисленными, как и финальные выплаты игрокам.
При рассмотрении модели с произвольным значением $\Co$ цена сделки перестает быть целочисленной, однако интерпретацию дискретности модели в этой постановке можно оставить неизменной, решив проблему нецелой финальной выплаты размера $a$ с помощью случайного механизма, который выберет либо выплату размера $[a]$, либо выплату размера $[a] + 1$.
Ожидаемый выигрыш при этом останется неизменным, но свойство дискретности сохранится.

\section{Формальная постановка задачи}\label{ch1:formal-def}

Определим формально повторяющуюся игру с неполной информацией, отвечающую данному выше описанию. 

Пусть множество состояний рынка $S = \{L, H\}$. Перед началом игры случай выбирает $s \in S $ с вероятностями $p(H) = p$ и $p(L) = 1 - p$.
После этого на протяжении $n \leq \infty$ шагов игроки играют в игру с матрицей $A^{s,\Co}$, где
\begin{equation*}
  A^{L,\Co}(i, j) = \begin{cases}
    \DCo i + \Co j, &\, i < j, \\
    0, &\, i = j, \\
    -\Co i - \DCo j, &\, i > j,
  \end{cases}
  \qquad
  A^{H,\Co}(i, j) = \begin{cases}
    \DCo i + \Co j - m, &\, i < j, \\
    0, &\, i = j, \\
    m - \Co i - \DCo j, &\, i > j.
  \end{cases}
\end{equation*}

Стратегией первого игрока в данной игре является последовательность ходов 
$\sigma = (\sigma_1, \sigma_2, \ldots, \sigma_t, \ldots)$, где 
$\sigma_t: S \times I^{t-1} \rightarrow \Delta(I)$.
Таким образом, на каждом шаге торгов игрок~1 рандомизирует выбор ставки в зависимости от состояния и предыдущих ставок.
Как и в работе~\cite{domansky07}, мы ограничимся рассмотрением только тех стратегий $\sigma$, которые гарантируют первому игроку на каждом шаге игры неотрицательный выигрыш.
Множество таких стратегий первого игрока обозначим через $\Sigma$.

Аналогично стратегией второго игрока назовем последовательность ходов 
$\tau = (\tau_1, \tau_2, \ldots, \tau_t, \ldots),$ где 
$\tau_t: I^{t-1} \rightarrow \Delta(J)$.
Не имея информации о настоящем состоянии, второй игрок при выборе ставки опирается только на историю ставок инсайдера.
Множество стратегий второго игрока обозначим через $\Tau$.

Обозначим $\Pi[p, \sigma, \tau]$ вероятностное распределение на $(S, I, J)$ порожденное ходом случая и смешанными стратегиями $\sigma$ и $\tau$ игроков.
Также обозначим $\E_{p,\sigma,\tau}$ математическое ожидание по мере $\Pi[p, \sigma, \tau]$.

При применении первым игроком смешанной стратегии $\sigma$, а вторым игроком "--- смешанной стратегии $\tau$, ожидаемый выигрыш первого игрока
\begin{equation}
  \label{ch1:eq:firstPlayerPayoff}
  K^{m,\Co}_n(p, \sigma, \tau) = \E_{p,\sigma,\tau} \sum_{t=1}^n
  \left(
    pA^{H,\Co}(i_t^H, j_t) + (1 - p)A^{L,\Co}(i_t^L, j_t)
  \right).
\end{equation}

\begin{remark}
  В игре с произвольным значением $\Co$, в отличие от случая $\Co = 1$, стратегии использующие ставку $m$ не являются доминируемыми.
  При цене акции равной $m$ и ставках $m-1$ и $m$, акция будет продана по цене $m - \DCo$, что дает ненулевой выигрыш одному из игроков при $\Co < 1$.
\end{remark}

Полученную игру обозначим через $G^{m,\Co}_n(p)$. Ее верхнее и нижнее значения даются формулами
\begin{equation*}
  \underline{V}^{m,\Co}_n(p) = \sup_{\sigma \in \Sigma} \inf_{\tau \in \Tau}
  K^{m,\Co}_n(p, \sigma, \tau), \quad
  \overbar{V}^{m,\Co}_n(p) = \inf_{\tau \in \Tau} \sup_{\sigma \in \Sigma}
  K^{m,\Co}_n(p, \sigma, \tau).
\end{equation*}
Если верхнее и нижнее значения совпадают, то игра имеет значение, которое мы обозначим $V^{m,\Co}_n(p)$.

\begin{remark}
  В силу того, что игра $G^{m,\Co}_n(p)$ может быть представлена в виде матричной игры большой размерности, существование ее значения следует из общей теори матричных игр.
\end{remark}

Заметим, что имеют место следующие равенства:
\begin{equation*}
  A^{L,\Co}(i, j) = A^{H,\DCo}(m-i, m-j), \quad
  A^{H,\Co}(i, j) = A^{L,\DCo}(m-i, m-j).
\end{equation*}
Определим симметричные по отношению к $\sigma$ и $\tau$ стратегии игроков
$\symm{\sigma}$ и $\symm{\tau}$ следующим образом. 
Для $t$-го шага
 $\symm{\sigma_t} = (\symm{\sigma^H_t}, \symm{\sigma^L})$, где
$\symm{\sigma^s_t}=(\sigma^s_{t,m},\ldots,\sigma^s_{t,0}) \in \Delta(I)$, и
$\symm{\tau_t} = (\tau_{t,m},\ldots,\tau_{t,0}) \in \Delta(J)$.
Легко видеть, что выигрыши игроков в играх $G^{m,\Co}_n(p)$ и $\symmGameExpression[n]{1-p}$ при использовании симметричных стратегий совпадают.

В дальнейшем мы часто будем опускать верхний индекс $\Co$.

\section{Оценка сверху выигрыша первого игрока.}\label{ch1:upper-bound}
Следуя \cite{domansky07}, рассмотрим чистую стратегию второго игрока $\tau^k, \, k \in J$:
\[
  \tau^k_1 = k, \quad \tau^k_t(i_{t-1}, j_{t-1}) = \begin{cases}
    j_{t-1} - 1, & \, i_{t-1} < j_{t-1}, \\
    j_{t-1},     & \, i_{t-1} = j_{t-1}, \\
    j_{t-1} + 1, & \, i_{t-1} > j_{t-1}.
  \end{cases}
\]
По сути эта стратегия представляет собой стратегию подражания инсайдеру.
Доказательство следующего утверждения по форме повторяет доказательство утверждения 4.3 из \cite{domansky07} и приводится в целях полноты изложения.

\begin{proposition}
  \label{ch1:prop:secondPlayerStrategyPayoffs}
  При применении стратегии $\tau^k$ в игре $\generalGame{n}{p}$ второй игрок гарантирует себе проигрыш не более
  \[
    h_n^L(\tau^k) = \sum_{t=0}^{n-1}(k - t - \DCo)^+, \quad h_n^H(\tau^k) =
    \sum_{t=0}^{n-1}(m - k - t - \Co)^+,
  \]
  в состояниях L и H соответственно.
\end{proposition}
\begin{proof}
  Проведем доказательство по индукции для $h^L_n(\tau^k)$.
  При $n=1$ справедливо
  \[
    h^L_1(\tau^k) = \max_{i \in I} A^L(i, k) = \max(0, k - \DCo) = (k - \DCo)^+.
  \]
  Пусть формула верна при $n \leq N$. Для $n=N+1$ оптимальный первый ход инсайдера использует ставку $\max(0, k - 1)$, что соответствует либо продаже
  акции по наибольшей цене в случае $k > 0$, либо отсутствию сделки. 
  Для случая $k > 0$ имеем
  \begin{gather*}
    h^L_{N+1}(\tau^k) = \DCo (k-1) + \Co k + h^L_N(\tau^{k-1}) =
    k - \DCo + \sum_{t=0}^{N-1}(k - 1 - t - \DCo)^+ = \\
    = k - \DCo + \sum_{t=1}^N(k-t-\DCo)^+ = \sum_{t=0}^N(k-t-\DCo)^+.
  \end{gather*}
  В случае $k = 0$ получаем
  \begin{gather*}
    h^L_{N+1}(\tau^k) = 0 + h^L_N(\tau^k) = \sum_{t=0}^{N-1}(k-t-\DCo)^+ = \sum_{t=0}^N(k-t-\DCo)^+.
  \end{gather*}
  Для $h^H_n(\tau^k)$ утверждение доказывается аналогично.
\end{proof}

Последовательности $\{h_n^L(\tau^k)\}$ и $\{h_n^H(\tau^k)\}$ не убывают и ограничены сверху по $n$.
Кроме того
$h^s_m(\tau^k) = h^s_{m+1}(\tau^k) = \ldots = h^s_{m+i}(\tau^k),\ i \in \N$.
Введем следующую функцию:
\begin{multline*}
  \upperBound{p} 
  = \min_{j \in J} \lim_{n \rightarrow \infty}\left(
    ph_n^H(\tau^j) + (1-p)h_n^L(\tau^j)
  \right) = \\
  %
  = \min_{j \in J} \left[ p (m - j)(m - j + \DCo - \Co) + (1 - p)j(j + \Co
    - \DCo) \right] / 2 = \\
  = \min_{j \in J} \left[ j^2 + j(2\Co - 1 - 2 m p) + m p (1 + m - 2\Co) \right].
\end{multline*}

\begin{figure}[b]
  \centering
  \input{figures/ch1-omega-x-p}
  \caption{Функция $\omega(x,p)$ при $p \in \{(k-\DCo)/m, (k+\Co)/m\}$}
  \label{ch1:fig:omega(x,p)}
\end{figure}

Функция $\omega(x, p) = x^2 + x(2\Co - 1 - 2mp)$ достигает минимума по $x$ в точке $m p - \Co + 1/2$.
Поэтому при $p \in \left( (k-\DCo)/m, (k+\Co)/m) \right]$ минимум функции $j^2 + j(2\Co - 1 - 2 m p)$ по $j \in J$ достигается при $j = k$ (\seename рис~\ref{ch1:fig:omega(x,p)}).

Таким образом, $\upperBound{p}$ является кусочно-линейной функцией, состоящей из $m~+~1$ линейных сегментов, и полностью определяется своими значениями в точках
\begin{gather*}
  \upperBound{(k+\Co)/m} = \left( (m - (k + \Co))(k + \Co) + \DCo\Co
  \right) / 2, \enskip
  k = \overline{0, m - 1},\\
  \upperBound{0} = \upperBound{1} = 0.
\end{gather*}

Пусть второй игрок при $p \in \left( (k-\DCo)/m, (k+\Co)/m) \right]$ применяет $\tau^k, \, k = \overline{0, m}$.
Обозначим эту стратегию через $\tau^*$.
Тогда справедлива следующая
\begin{lemma}
  \label{ch1:lemma:upperBound}
  При использовании вторым игроком стратегии $\tau^*$ в игре $\infiniteGame{p}$\textup{,} выигрыш первого игрока ограничен сверху функцией $\upperBound{p}$, т.е.
  \[
    \max_{\sigma \in \Sigma} \infiniteFirstPlayerPayoff{p}{\sigma}{\tau^*} \leq
    \upperBound{p}.
  \]
\end{lemma}

\section{Оценка снизу выигрыша первого игрока}\label{ch1:lower-bound}
Перейдем к описанию стратегии первого игрока, гарантирующей ему выигрыш не менее $\upperBound{p}$ в игре $\infiniteGame{p}$.

Пусть на первом шаге игры первый игрок применяет %
$\fGeneral{k} = \left(\fGeneral{H}, \fGeneral{L}\right)$, где %
$\fGeneral{H} = \left(\fGeneral[1,k]{H}, \fGeneral[1,k+1]{H}\right)$,
$\fGeneral{L} = \left(\fGeneral[1,k]{L}, \fGeneral[1,k+1]{L}\right)$ и
$\fGeneral[1,i]{s}$ -- вероятность сделать ставку $i$ в состоянии $s \in S$.
Применяя $\fGeneral{k}$, инсайдер делает ставки $k$ и $k+1$ с некоторыми заданными вероятностями.

Определим следующие параметры: полные вероятности использования действий $k$ и $k+1$, равные $q_k$ и $q_{k+1}$ соответственно, а также апостериорные вероятности $p(s|i)$ состояния $s$ при условии, что на предыдущем шаге первый игрок сделал ставку $i$.
Тогда вероятности $\fGeneral[1,i]{s}$ можно найти по формуле Байеса
\[
  \fGeneral[1,i]{s}~=~p(s|i)q_i/p(s), \: i = k, k + 1.
\]

\begin{proposition}
  \label{ch1:prop:stage-payoff}
  При использовании $\fGeneral{k}$ первый игрок гарантирует себе на первом шаге выигрыш
  \begin{equation}
    \label{ch1:eq:lowerPayoffGeneral}
    \firstPlayerPayoff{1}{p}{\fGeneral{k}}{j} =
    \begin{cases}
      mp - \Co k - \DCo j - \Co q_{k+1},      & \, j < k,     \\
      \left(m p(H|k+1) - k - \Co \right) q_{k+1}, & \, j = k,     \\
      \left(k + \Co - m p(H|k) \right) q_k,       & \, j = k + 1, \\
      \DCo k + \Co j - mp + \DCo q_{k+1}, & \, j > k + 1.
    \end{cases}
  \end{equation}
\end{proposition}
\begin{proof}
  Пусть $j < k$. Тогда из \eqref{ch1:eq:firstPlayerPayoff} и определения $\fGeneral{k}$ получаем
  \begin{align*}
    \firstPlayerPayoff{1}{p}{\fGeneral{k}}{j} &=
    p \left( 
      \fGeneral[1,k]{H} (m - \Co k - \DCo j) +
      \fGeneral[1,k+1]{H} (m - \Co (k+1) - \DCo j)
    \right) + \\
    &+ (1-p) \left( 
      \fGeneral[1,k]{L} (- \Co k - \DCo j) +
      \fGeneral[1,k+1]{L} (- \Co (k+1) - \DCo j)
    \right) = \\
    &=
    m p (\fGeneral[1,k]{H} + \fGeneral[1,k+1]{H}) -
    \left(
      p (\fGeneral[1,k]{H} + \fGeneral[1,k+1]{H}) +
      (1-p) (\fGeneral[1,k]{L} + \fGeneral[1,k+1]{L})
    \right) \times \\ 
    &\times (\Co k + \DCo j) -
    (p \fGeneral[1,k+1]{H} + (1-p) \fGeneral[1,k+1]{L}) \Co = \\
    &= mp - \Co k - \DCo j - \Co q_{k+1}.
  \end{align*}
  При $j = k$ имеет место равенство
  \begin{align*}
    \firstPlayerPayoff{1}{p}{\fGeneral{k}}{j} 
    &=
      p \fGeneral[1,k+1]{H} (m - \Co (k+1) - \DCo k) +
      (1-p) \fGeneral[1,k+1]{L} (- \Co (k+1) - \DCo k) = \\
    &= m p \fGeneral[1,k+1]{H} - 
      (p \fGeneral[1,k+1]{H} + (1-p) \fGeneral[1,k+1]{L}) (\Co (k+1) + \DCo k) =\\
    &= m p(H|k+1) q_{k+1} - q_{k+1} (\Co (k+1) + \DCo k) = \\
    &= (m p(H|k+1) - k - \Co) q_{k+1}.
  \end{align*}
  Случаи $j = k + 1$ и $j > k + 1$ разбираются аналогично.
\end{proof}

Построим оптимальную стратегию инсайдера. Рассмотрим на $[0,1]$ множество $P$ точек вида
\[
\pEven[i] = i/m, \, i = \overline{0, m}, \quad \pOdd[i] = (i + \Co)/m, \, i =
\overline{0, m - 1}.
\]

Для $p = \pEven$ определим $\fEven$ как действие $\fGeneral{k}$ с параметрами
\begin{gather*}
  q_k = \Co, \quad p(H|k) = \pOdd[k-1],\\
  q_{k+1} = \DCo, \quad \p(H|k + 1) = \pOdd[k].
\end{gather*}
Дополнительно определим $\fEven[0]$ как действие, состоящее в применении ставки $0$ с вероятностью $1$, а $\fEven[m]$ -- как действие, состоящее в применении ставки $m$ с вероятностью $1$.
Аналогично для $p = \pOdd$ определим $\fOdd$ как действие $\fGeneral{k}$ с параметрами
\begin{gather*}
  q_k = \DCo, \quad p(H|k) = \pEven[k],\\
  q_{k+1} = \Co, \quad p(H|k + 1) = \pEven[k+1].
\end{gather*}

\begin{proposition}
  При $p \in P$ для значения $\firstPlayerPayoff{1}{p}{\sigma}{j}$ выигрыша первого игрока верны оценки
  \begin{equation}
    \label{ch1:eq:lowerBound:inequalities}
    \min_{j \in J}
    \firstPlayerPayoff{1}{\pEven}{\fEven}{j} \geq 0,
    \quad
    \min_{j \in J}
    \firstPlayerPayoff{1}{\pOdd}{\fOdd}{j} \geq \DCo\Co.
  \end{equation}
\end{proposition}
\begin{proof}
  Подставив полные вероятности действий и апостериорные вероятности состояний в \eqref{ch1:eq:firstPlayerPayoff}, получим для $p = \pOdd[k]$
  \begin{equation*}
    \firstPlayerPayoff{1}{\pOdd}{\fOdd}{j} = \begin{cases}
      k + \Co - \Co k - \DCo j - \Co^2 > \Co \DCo,\ & j < k,\\
      (k + 1 - k - \Co) \Co = \Co \DCo,\ & j = k,\\
      (k + \Co - k) \DCo = \Co \DCo,\ & j = k+1,\\
      \DCo k + \Co j - k - \Co + \Co \DCo > \Co \DCo,\ & j > k+1.
    \end{cases}
  \end{equation*}
  Справедливость неравенства $\min_{j \in J} \firstPlayerPayoff{1}{\pEven}{\fEven}{j} \geq 0$ устанавливается аналогично.
\end{proof}

\begin{remark}
  \label{ch1:remark:posterior-probs}
  Если $p \in P$, то при применении инсайдером на первом шаге игры $\fEven$ и $\fOdd$, значения апостериорных вероятностей также принадлежат $P$.
  Таким образом, можно продолжить применение $\fEven$ и $\fOdd$ на последующих шагах игры, тем самым определив стратегию $\fOpt$ в игре $\generalGame{n}{p}$, при $p \in P, \, n \in \mathbb{N}$.
\end{remark}

Пусть $\lowerBound[n]{p}$ при $p \in P$ --- гарантированный выигрыш первого игрока в игре $\generalGame{n}{p}$ при применении стратегии $\fOpt$.

Следуя \cite{domansky07}, опишем рекурсивную структуру игры $\generalGame{n}{p}$.
Стратегию $\sigma$ первого игрока в $n$-шаговой игре можно представить как $(\sigma_1, \sigma(i),\ i \in I)$, где $\sigma_1$ "--- ход
игрока~1 на первом шаге игры, а $\sigma(i)$ "--- стратегия в игре продолжительности $n-1$, зависящая от ставки $i$ на первом шаге.
Аналогично стратегию игрока~2 можно представить как $(\tau_1, \tau(i),\ i \in I)$.
Тогда для функции выигрыша справедливо следующее представление
\begin{equation}
  \label{ch1:eq:recursive-structure}
  \firstPlayerPayoff{n+1}{p}{\sigma}{\tau} = 
  \firstPlayerPayoff{1}{p}{\sigma_1}{\tau_1} + 
  \sum_{i \in I} q(i) \firstPlayerPayoff{n}{p(H|i)}{\sigma(i)}{\tau(i)}.
\end{equation}

В силу неравенств (\ref{ch1:eq:lowerBound:inequalities}) и формулы \eqref{ch1:eq:recursive-structure} для максимального гарантированного выигрыша первого игрока в игре $\generalGame{n}{p}$ справедливы формулы
\begin{equation}
  \begin{gathered}
    \label{ch1:eq:lowerBound:recurrence:function}
    \lowerBound[n]{(k + \Co)/m} = \DCo\Co + \DCo\lowerBound[n-1]{k/m} +
    \Co\lowerBound[n-1]{(k + 1)/m}, \: k = \overline{0, m-1}, \\
    % 
    \lowerBound[n]{k/m} = \Co\lowerBound[n-1]{(k - 1 + \Co)/m} +
    \DCo\lowerBound[n-1]{(k + \Co)/m}, \: k = \overline{1, m-1}, \\
    % 
    \lowerBound[n]{0} = \lowerBound[n]{1} = 0.
  \end{gathered}
\end{equation}

Так как $\lowerBound[n]{p}$ не убывает по $n$ и ограничена сверху, то устремив $n$ к бесконечности, получим нижнюю оценку $\lowerBound{p}$ выигрыша первого игрока в игре $\infiniteGame{p}, \, p \in P$.

Введем следующие обозначения:
\begin{align*}
  L_{2k} = \lowerBound{k/m}, & \quad k = \overline{0, m},\\
  L_{2k+1} = \lowerBound{(k+\Co)/m)}, & \quad k = \overline{0, m-1}.
\end{align*}
Тогда справедливы формулы
\begin{equation}
  \label{ch1:eq:lowerRecurrence}
  \begin{gathered}
    L_{2k+1} = \DCo\Co + \DCo L_{2k} + \Co L_{2(k+1)}, \enskip k = \overline{0, m-1},\\
    L_{2k} = \Co L_{2k-1} + \DCo L_{2k+1}, \enskip k = \overline{1, m-1},\\
    L_0 = L_{2m} = 0.
  \end{gathered}
\end{equation}

Введем $(2m-1)\times(2m-1)$-матрицу $B$ и $(2m-1)$-вектор-столбец $b$:
\begin{equation*}
  B =
  \left(
    \begin{array}{cccccccc}
      1      & -\Co  & 0       & 0      & \cdots & 0      & 0       & 0       \\
      -\Co & 1       & -\DCo & 0      & \cdots & 0      & 0       & 0       \\
      0      & -\DCo & 1       & -\Co & \cdots & 0      & 0       & 0       \\
      \hdotsfor{8}                                                              \\
      0      & 0       & 0       & 0      & \cdots & -\Co & 1       & -\DCo \\
      0      & 0       & 0       & 0      & \cdots & 0      & -\DCo & 1 
    \end{array}
  \right),\quad
  %
  b = \left(
    \begin{array}{c}
      \DCo\Co \\
      0           \\
      \DCo\Co \\
      \cdots      \\
      0           \\
      \DCo\Co
    \end{array}
  \right).
\end{equation*}
Тогда (\ref{ch1:eq:lowerRecurrence}) перепишем в виде $ BL = b, L_0 = L_{2m} = 0, $ где $L = (L_1, L_2, \ldots, L_{2m-1})$.

Системы $ Mx = f $ с трехдиагональной матрицей $ M $, имеющей структуру
\[
  M = \left(\begin{array}{cccccccc}
              c_1 & b_1 & 0   & 0   & \cdots & 0       & 0       & 0       \\
              a_2 & c_2 & b_2 & 0   & \cdots & 0       & 0       & 0       \\
              0   & a_3 & c_3 & b_3 & \cdots & 0       & 0       & 0       \\
              \hdotsfor{8}                                                 \\
              0   & 0   & 0   & 0   & \cdots & a_{n-1} & c_{n-1} & b_{n-1} \\
              0   & 0   & 0   & 0   & \cdots & 0       & a_n     & c_n
            \end{array}\right),
\]
можно решать методом прогонки, используя следующие формулы для прогоночных коэффициентов и переменных (см. \cite{samarsky89}):
\begin{gather}
  \label{ch1:eq:tridiagonal-book}
  x_i = \gamma_{i+1} x_{i+1} + \delta_{i+1}, \: i = \overline{1,n-1},
  \quad
  x_n = \frac{f_n - a_n\delta_n}{c_n + a_n\gamma_n}, \\
  % 
  \gamma_{i+1} = -\frac{b_i}{c_i + a_i\gamma_i}, \: i = \overline{2,
    n-1}, \quad
  \gamma_2 = -\frac{b_1}{c_1}, \\
  % 
  \delta_{i+1} = \frac{f_i - a_i\delta_i}{c_i + a_i\gamma_i}, \: i =
  \overline{2, n-1}, \quad \delta_2 = \frac{f_1}{c_1}.
\end{gather}

\begin{proposition}
  \label{ch1:prop:tridiagonal:coefficients}
  Прогоночные коэффициенты для матрицы $B$ даются следующими формулами\textup{:}
  \begin{multline*}
    \gamma_{2k} = \frac{\Co+k-1}{k}, \,
    \gamma_{2k+1} = \frac{k}{k+\Co}, \\
    \delta_{2k} = \frac{\DCo(k-1+2\Co)}{2}, \, \delta_{2k+1} =
    \frac{k\Co(k-1+2\Co)}{2(k+\Co)}, \quad k = \overline{1,m-1}.
  \end{multline*}
\end{proposition}
Данное утверждение доказывается по индукции.

Из \eqref{ch1:eq:lowerRecurrence} следует, что
$L_{2k-1} = \gamma_{2k}\gamma_{2k+1}L_{2k+1} + \gamma_{2k}\delta_{2k+1} + \delta_{2k}, \, k = \overline{1, m-1}$.
Подстановкой $\upperBound{(k+\Co)/m}$ вместо $L_{2k+1}$ это равенство обращается в тождество.
Тем самым доказано
\begin{proposition}
  \label{ch1:prop:lower:recurrence-solution}
  Решение системы {\normalfont(\ref{ch1:eq:lowerRecurrence})} дается
  следующими формулами\textup{:}
  \begin{gather}
    \label{ch1:eq:recurrence-solution:odd}
    L_{2k+1} = ((m - k - \Co)(k + \Co) + \DCo\Co)/2, \quad k = \overline{0, m-1},\\
    \label{ch1:eq:recurrence-solution:even}
    L_{2k} = k (m-k)/2, \quad k = \overline{0, m}.
  \end{gather}
\end{proposition}

Итак, мы определили функцию $\lowerBound{p}$ при $p \in P$.
Для $p \in [0, 1] \setminus P$ стратегия инсайдера основана на применении выпуклой комбинации стратегий для крайних точек интервала, в котором находится $p$.

Обозначим через $\lambda\fOdd[k] + (1-\lambda)\fEven[k+1]$ распределение, при котором первый игрок рандомизирует выбор ставок $k, k+1, k+2$ с параметрами
\begin{align*}
  q_k = \lambda\DCo, &\quad p(H|k) = \pEven,\\
  q_{k+1} = \Co, &\quad p(H|k+1) = \lambda \pEven[k+1] + (1-\lambda) \pOdd,\\
  q_{k+2} = (1-\lambda)\DCo, &\quad p(H|k+2) = \pOdd[k+1].
\end{align*}

Через $\lambda\fEven + (1-\lambda)\fOdd$ обозначим распределение, при котором первый игрок рандомизирует выбор ставок $k$ и $k+1$ с параметрами
\begin{gather*}
  q_k = \lambda\Co + (1-\lambda)(1-\Co), \\
  p(H|k) = \frac{\lambda\Co}{q_k}\pOdd[k-1] + \frac{(1-\lambda)(1-\Co)}{q_k} \pEven,\\
  q_{k+1} = \lambda(1-\Co) + (1-\lambda)\Co, \\
  p(H|k+1) = \frac{\lambda(1-\Co)}{q_{k+1}}\pOdd[k] + \frac{(1-\lambda)\Co}{q_{k+1}}\pEven[k+1].
\end{gather*}

Доказательство следующего утверждения аналогично доказательству утверждения~\ref{ch1:prop:stage-payoff}.
\begin{proposition}
  \label{ch1:prop:first:combination:step}
  При $\lambda \in (0, 1), \, \Co \geq 1/2, \, k = \overline{0, m-1}$ для значения одношагового выигрыша первого игрока верны оценки
  \begin{align*}
    \min_{j \in J}
    \firstPlayerPayoff{1}{%
    \lambda \pEven + (1-\lambda) \pOdd}{%
    \lambda \fEven + (1-\lambda) \fOdd}{%
    j}
    &\geq \DCo \Co (1-\lambda), \\
    % 
    \min_{j \in J}
    \firstPlayerPayoff{1}{%
    \lambda \pOdd + (1-\lambda) \pEven[k+1]}{%
    \lambda \fOdd + (1-\lambda) \fEven[k+1]}{%
    j}
    &\geq \DCo \Co \lambda.
  \end{align*}
\end{proposition}

\begin{proposition}
  \label{ch1:prop:first:combination:game}
  При $\lambda \in (0, 1), \, \Co \geq 1/2, \, k = \overline{0, m-1}$, для гарантированного выигрыша первого игрока в игре $\infiniteGame{p}$ справедливы равенства
  \begin{align*}
    \lowerBound{\lambda \pEven + (1-\lambda) \pOdd}      
    &= 
      \lambda \lowerBound{\pEven} + (1-\lambda) \lowerBound{\pOdd}, \\
    \lowerBound{\lambda \pOdd + (1-\lambda) \pEven[k+1]} 
    &= \lambda \lowerBound{\pOdd} + (1-\lambda) \lowerBound{\pEven}.
  \end{align*}
\end{proposition}
\begin{proof}
  Пусть $p = \lambda \pOdd + (1-\lambda) \pEven[k+1]$, где $k = \overline{0, m - 2}, \, \lambda \in (0, 1)$.
  Тогда по аналогии с \eqref{ch1:eq:lowerBound:recurrence:function} выписывается следующая рекуррентная формула:
  \begin{equation*}
    \lowerBound{p} = \DCo \Co \lambda + \lambda \DCo
    \lowerBound{\pEven} + (1-\lambda) \DCo \lowerBound{\pOdd[k+1]} +
    \Co \lowerBound{(1-\lambda) \pOdd + \lambda \pEven[k+1]}.
  \end{equation*}
  
  Так как $(1-\lambda)\pOdd + \lambda \pEven[k+1] \in (\pOdd, \pEven[k+1])$, то для $\lowerBound{(1-\lambda)\pOdd + \lambda \pEven[k+1]}$ справедливо аналогичное представление.
  Приведя подобные члены, получим

  \begin{equation}
    \label{ch1:eq:first:combination:game:2}
    \begin{aligned}
      \lowerBound{p} 
      &= 
      \frac{1}{1-\Co^2}
      \left(
        \DCo\Co\lambda + 
        \DCo\lambda\lowerBound{\pEven} + 
        (1-\lambda)\DCo\lowerBound{\pOdd[k+1]} + 
      \right.\\
      % 
      &\left. 
        + \Co \left( 
          \DCo\Co(1-\lambda) +
          (1-\lambda)\DCo\lowerBound{\pEven} +
          \lambda\DCo\lowerBound{\pOdd[k+1]} 
        \right)
      \right) = \\
      % 
      &=
      \left( (k + 1)(m - k - 1) + \DCo\lambda(2k - m + 2\Co + 1)
      \right)/2 = \\
      &=
      \lambda\lowerBound{\pOdd} + (1-\lambda)\lowerBound{\pEven[k+1]}.
    \end{aligned}
  \end{equation}
  
  Пусть $p = \lambda\pEven + (1-\lambda)\pOdd$, где $k = \overline{1, m - 1}, \, \lambda \in (0, 1)$.
  Заметим, что $p(H|k) \in ( \pOdd[k-1], \pEven )$, а $p(H|k+1) \in ( \pOdd, \pEven[k+1] )$.
  Тогда с помощью \eqref{ch1:eq:first:combination:game:2} получим
  \begin{multline*}
    \lowerBound{p} =
    \lambda \Co \lowerBound{\pOdd[k-1]} + 
    (1-\lambda)(1-\Co)\lowerBound{\pEven} + \lambda(1-\Co)\lowerBound{\pOdd} + \\
    + (1-\lambda)\Co\lowerBound{\pEven[k+1]} 
    = \lambda \lowerBound{\pEven} + (1-\lambda) \lowerBound{\pOdd}.
  \end{multline*}
  
  При $p \in ( 0, \pOdd[1] )$ и $p \in ( \pOdd[m-1], 1 )$ доказательство проводится аналогично.
\end{proof}

Заметим, что при $\Co < 1/2$ полученные результаты также имеют место, а стратегию $\fOpt$ можно получить, рассмотрев игру $\symmGameExpression[n]{1-p}$.

Таким образом, мы определили стратегию $\fOpt$ и максимальный гарантированный выигрыш первого игрока $\lowerBound{p}$ для любых $p \in [0, 1], \, \Co \in (0, 1)$.
Отсюда вытекает справедливость следующей леммы.

\begin{lemma}
  \label{ch1:lemma:first:lower}
  При использовании первым игроком стратегии $\fOpt$ в игре $\infiniteGame{p}$\textup{,} его выигрыш ограничен снизу функцией $\lowerBound{p}$\textup{,} т.е.
  \[
    \min_{\tau \in \Tau} \infiniteFirstPlayerPayoff{p}{\fOpt}{\tau} \geq
    \lowerBound{p}.
  \]
\end{lemma}

\section{Значение игры и динамика апостериорных вероятностей}\label{ch1:game-value}

\begin{theorem}
  Игра $\infiniteGame{p}$ имеет значение $\infiniteGameValue{p} = \upperBound{p} = \lowerBound{p}$.
  При этом $\fOpt$ -- оптимальная стратегия первого игрока\textup{,} а $\tau^*$ -- оптимальная стратегия второго игрока.
\end{theorem}
Доказательство данной теоремы непосредственно следует из лемм \ref{ch1:lemma:upperBound} и \ref{ch1:lemma:first:lower} и по форме повторяет доказательство аналогичной теоремы в \cite{domansky07}.

\begin{proposition}
  \label{ch1:prop:value-comparison}
  При любом значении $p \in [0,1]$, $\Co \in (0,1)$ и $m \geq 3$ справедливо неравенство
  \begin{equation*}
    V^\Co_m(p) \geq V^1_m(p) = V^0_m(p),
  \end{equation*}
  причем равенство достигается только при $p = k/m, k = \overline{0,m}$.
\end{proposition}
\begin{proof}
  Из (\ref{ch1:eq:recurrence-solution:even}) следует, что нам достаточно показать, что 
  \[
    V^\beta_m((k+\Co)/m) > V^1_m((k+\Co)/m).
  \]
  В силу того, что $(k+\Co)/m = \DCo k/m + \Co (k+1)/m$, получаем
  \begin{gather*}
    V^\Co_m((k+\beta)/m) - \DCo V^1_m(k/m) - \Co V^1_m((k+1)/m) = 2\DCo > 0.
  \end{gather*}
  Отсюда следует справедливость данного утверждения.
\end{proof}

\begin{figure}[b]
  \centering
  \begin{tikzpicture}[yscale=1.5,xscale=8]
    \draw[thick,->,>=stealth'] (-0.1,0) -- (1.1,0) node[right] {$p$};
    \draw[thick] (0,-0.1) -- (0,0.1);
    \node[anchor=north east] at (0,0) {$0$};
    \draw[thick] (1,-0.1) -- (1,0.1);
    \node[anchor=north west] at (1,0) {$1$};

    \draw[thick] plot file {plots/ch1-v0.5.dat};
    \draw[very thick,dashed] plot file {plots/ch1-v1.dat};
    
    \node at (0.86, 2.6) {$V^{1/2}_m(p)$};
    \node at (0.55, 2.6) {$V^1_ m(p)$};
  \end{tikzpicture}
  \caption{Графики функции $V^\Co_m(p)$ при значениях $\Co = 1/2$ и $\Co = 1$}
  \label{ch1:fig:value-comparison}
\end{figure}

Таким образом, из всех рассматриваемых механизмов торгов, те механизмы, которые предписывают продавать акцию по наибольшей или наименьшей предложенной цене, гарантируют инсайдеру наименьший возможный выигрыш.

Рассмотрим динамику апостериорных вероятностей, возникающую при применении игроками оптимальных стратегий.

Пусть $p \in P$. Обозначим через $p^t$ апостериорную вероятность состояния $H$ после $t$-го шага игры, причем $p^0$ соответствует исходной априорной вероятности.
Тогда из замечания~\ref{ch1:remark:posterior-probs} и рекурсивной структуры игры $\infiniteGame{p}$ следует, что последовательность $(p^0, p^1, p^2, \ldots, p^t, \ldots)$ представляет собой однородную марковскую цепь с $2m$ состояний и $2m \times 2m$-матрицей переходных вероятностей
\begin{equation}
  \label{ch1:eq:posterior-chain}
  \Pi = 
  \left(
    \begin{array}{ccccccccc}
      1    & 0   & 0   & 0    & \ldots & 0   & 0    & 0    & 0   \\
      \DCo & 0   & \Co & 0    & \ldots & 0   & 0    & 0    & 0   \\
      0    & \Co & 0   & \DCo & \ldots & 0   & 0    & 0    & 0   \\
      \hdotsfor{9}                                               \\
      0    & 0   & 0   &      & \ldots & \Co & 0    & \DCo & 0   \\
      0    & 0   & 0   &      & \ldots & 0   & \DCo & 0    & \Co \\
      0    & 0   & 0   &      & \ldots & 0   & 0    & 0    & 1
    \end{array}
 \right).
\end{equation}

Занумеруем состояния данной марковской цепи следующим образом:
\begin{gather*}
  p_{2k} = \frac{k}{m}, \quad k = \overline{0, m}, \quad
  p_{2k+1} = \frac{k+\Co}{m}, \quad k = \overline{0, m-1}.
\end{gather*}

Из \eqref{ch1:eq:posterior-chain} видно, что состояния $p_0$ и $p_{2m}$ являются поглощающими.
Они соответствуют моменту игры, в который происходит полное раскрытие приватной информации первого игрока, т.е. моменту, когда игроку~2 становится доподлинно известно истинное состояние $s$.
Случайная величина
\begin{equation*}
  \xi = \min \left\{ 0 \leq t: p^t \in \{p_0, p_{2m}\} \right\}
\end{equation*}
соответствует моменту поглощения. Величина
\begin{equation*}
  \tau(p_k) = \E \{ \xi\ |\ p^0 = p_k \}
\end{equation*}
определяет ожидаемую продолжительность игры, при условии, что априорная вероятность равна $p_i$.

Обозначим через $\pi^l_i,\ \pi^r_i,\ i \in \overline{1, 2m-1}$ вероятности перехода из состояния $p_i$ в состояния $p_{i-1}$ и $p_{i+1}$ соответственно.

\begin{figure}[tb]
  \centering
  \input{figures/ch1-posterior-markov}
  \caption[Последовательность апостериорных вероятностей]{Марковская цепь,
    соответствующая последовательности апостериорных вероятностей}
  \label{ch1:fig:posterior-markov}
\end{figure}

\begin{proposition}
  \label{ch1:prop:game-duration}
  Игра $\infiniteGame{p_k}$ в среднем заканчивается за конечное количество шагов.
  Ее ожидаемая продолжительность выражается формулами
  \begin{equation*} 
    \tau(p_{2k+1}) = \frac{(m-k-\Co)(k+\Co)}{\Co \DCo},\quad
    \tau(p_{2k}) = \frac{k(m-k)}{\Co \DCo}.
  \end{equation*}
\end{proposition}
\begin{proof}
  Известно, что ожидаемое время до поглощения для марковских цепей имеющих структуру, изображенную на рисунке~\ref{ch1:fig:posterior-markov}, выражается следующим образом (\seename \cite[\S~12]{shiryaev11}):
  \begin{gather}
    \label{ch1:prop:game-duration:eq:1}
    \tau(p_j) =
    \sum_{i=0}^{j-1} \rho_i \cdot
    \frac{\sum_{i=0}^{2m-1} R_i}{\sum_{i=0}^{2m-1} \rho_i} -
    \sum_{i=0}^{j-1} R_i,
  \end{gather}
  где
  \begin{gather*}
  \rho_0 = 1, \quad
    \rho_j = \frac{\pi^l_1 \ldots \pi^l_j}{\pi^r_1 \ldots \pi^r_j}, \quad j \geq 1,\\
    R_0 = 0, \quad
    R_1 = \frac{1}{\pi^r_1}, \quad
    R_j = \frac{1}{\pi^r_j}\left( 
      1 + 
      \frac{\pi^l_j}{\pi^r_{j-1}} + 
      \ldots + \frac{\pi^l_j \ldots \pi^l_2}{\pi^r_{j-1} \ldots \pi^r_1}
    \right), \quad j \geq 2.
  \end{gather*}
  Несложно видеть, что для коэффициентов $\rho_j$, $R_j$ выполняется
  \begin{gather*}
    \rho_{2k+1} = \frac{\DCo}{\Co},\quad k = \overline{0, m-1},\quad
    \rho_{2k} = 1,\quad k = \overline{1, m-1},\\
    R_k = \frac{k}{\pi^r_k},\quad k = \overline{1, 2m-1}.
  \end{gather*}
  Отсюда получаем
  \begin{equation}
    \label{ch1:prop:game-duration:eq:2}
    \begin{gathered}
      \sum_{i=0}^{2k-1} \rho_i = k + k \frac{\DCo}{\Co} = \frac{k}{\Co},\\
      \sum_{i=0}^{2k-1} R_i = \frac{k^2}{\Co} + \frac{k(k-1)}{\DCo} = \frac{k(k-\Co)}{\Co\DCo}.
    \end{gathered}
  \end{equation}
  Из \eqref{ch1:prop:game-duration:eq:1} и \eqref{ch1:prop:game-duration:eq:2} находим
  \begin{gather}
    \label{ch1:prop:game-duration:eq3}
    \tau(p_{2k}) =
    \frac{k}{\Co} \frac{m-\Co}{\DCo} - \frac{k(k-\Co)}{\Co\DCo} =
    \frac{k(m-k)}{\Co\DCo}.
  \end{gather}

  Заметим, что имеет место следующее равенство:
  \begin{equation}
    \label{ch1:prop:game-duration:eq4}
    \tau(p_{2k+1}) = 1 + \DCo \tau(p_{2k}) + \Co \tau(p_{2(k+1)}).
  \end{equation}
  Справедливость формулы для $\tau(p_{2k+1})$ проверяется подстановкой~\eqref{ch1:prop:game-duration:eq3} в выражение~\eqref{ch1:prop:game-duration:eq4}.
\end{proof}

В силу того, что первый игрок получает положительные выплаты размера $\Co\DCo$ только в состояниях $p_i$ с нечетными номерами, то его выигрыш за игру равен среднему количеству посещенных нечетных состояний, умноженных на одношаговую выплату. В частности при $p = p_{2k+1}$ и первое, и последнее состояние дают положительный выигрыш. Отсюда получаем
\begin{equation*}
  \frac{\tau(p_{2k+1}) + 1}{2} \cdot \Co\DCo = \frac{(m-k-\Co)(k+\Co) + \Co\DCo}{2}.
\end{equation*}
Аналогично при $p = p_{2k}$ имеем
\begin{equation*}
  \frac{\tau(p_{2k})}{2} \cdot \Co\DCo = \frac{k(m-k)}{2}.
\end{equation*}
Данные результаты согласуется с формулами (\ref{ch1:eq:recurrence-solution:odd},~\ref{ch1:eq:recurrence-solution:even}).

Нужно отметить, что в сравнении со случайным блужданием апостериорных вероятностей, порождаемым оптимальной стратегией инсайдера из \cite{domansky07}, случайное блуждание, рассмотренное выше, имеет более сложный характер: в дополнение к точками $k/m$ оно включает точки $(k+\Co)/m$, кроме того оно больше не является симметричным, кроме случая $\Co = 1/2$.

}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../dissertation"
%%% End:
