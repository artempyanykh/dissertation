\chapter{Теоретико-игровая модель биржевых торгов с дискретными ставками для
  рынка с двумя состояниями} \label{chapt1}

\todo{Привести краткий обзор--схему данной главы. Написать какие результаты и
  где были опубликованы.}

\section{Основные понятия}\label{ch1:intro}
Далее последует описание повторяющейся игры с неполной информацией в смысле
Аумана"--~Машлера, т.е. такие игры, в которых множество состояний конечно, как и
множества возможных действий игроков (см. монографию \cite{aumann95}).
Теоретико-игровые постановки задач из глав~\ref{chapt2} и~\ref{chapt3} будут
отличаться от данного классического описания, о чем будет сказано отдельно.

Рассмотрим антагонистическую игру двух лиц, которая повторяется $n$ раз, где $n
\leq \infty$. Будем считать, что игрок~1 знает функцию выигрыша в данной игре, в
то время как игрок~2 такой информацией не обладает. Однако второй игрок знает,
что настоящая функция выигрыша является одной из $\kappa$ возможных альтернатив.
Каждой такой альтернативе игрок~2 приписывает некоторую вероятность того, что
данная функция выигрыша является истинной функцией выигрыша в рассматриваемой
игре. Таким образом, априорные убеждения игрока~2 задаются вероятностным
вектором %
$
  \po = (p^0_1, p^0_2, \ldots, p^0_\kappa),\ \text{где } \sum_{i=1}^\kappa p^0_i = 1.
$

С данными функциями выигрыша можно связать игры $G_1, G_2, \ldots, G_\kappa$. В
дальнейшем мы будем считать, что информационная неопределенность игрока~2
заключается именно в том, что он не знает какая из игр $G_1, G_2, \ldots,
G_\kappa$ разыгрывается.

На каждом шаге игры первый игрок может совершать действия из множества $I$,
второй игрок --- действия из множества $J$, при этом мы считаем, что множества
действий одного игрока известно другому. Кроме того, положим, что игрок~2 знает,
что первый обладает точной информацией о том, какая именно игра разыгрывается, а
игрок~1 знает априорные убеждения второго.

\begin{figure}[!ht]
  \centering
  \input{figures/ch1-game-structure}
  \caption{Структура повторяющейся игры}
  \label{fig:ch1:game_structure}
\end{figure}

Игры $G_1, G_2, \ldots, G_\kappa$ будем называть \emph{одношаговыми играми}. Все
одношаговые игры описываются матрицами размера $|I| \times |J|$, где элементы
матрицы задают выплаты игроку~1. Мы предполагаем, что оба игрока точно знают
платежные матрицы игр $G_1, G_2, \ldots, G_\kappa$. На каждом шаге игры первый
игрок выбирает номер строки, и одновременно с ним второй игрок выбирает номер
столбца. В конце каждого хода действия игроков оглашаются, и элемент из матрицы,
отвечающей настоящей игре, прибавляется к выигрышу игрока 1 и вычитается из
выигрыша игрока 2. Таким образом, игрок 1 знает свой выигрыш на каждом этапе
игры, в то время как игрок 2 может лишь рассчитать свой ожидаемый выигрыш. В
завершение, мы считаем, что данное описание известно обоим игрокам.

Данная игра с неполной информацией сводится к игре с полной информацией
следующим образом. Обозначим через $S = \{1, 2, \ldots, \kappa\}$ множество
возможных альтернатив или \emph{состояний природы}. Перед началом игры ходом
случая в соответствии с вероятностным распределением $\po$ выбирается состояние
$s \in S$. Далее на протяжении $n$ шагов разыгрывается игра $G_s$. Игрок 1
информирован о результате хода случая, игрок 2 "--- нет. В остальном правила
данной игры совпадают с описанными выше.

Обозначим %
$h_t = \left((i_1, j_1), (i_2, j_2), \ldots, (i_t, j_t)\right)$ %
историю ходов игроков к шагу $t = \overline{1, n}$. Также обозначим через $H_t$
множество всех историй, которые могли реализоваться к шагу $t$. 

Стратегией игрока~1 в такой игре является последовательность ходов %
$\sigma = (\sigma_1, \sigma_2, \ldots, \sigma_n)$, где %
$\sigma_t = (\sigma^1_t, \sigma^2_t, \ldots, \sigma^\kappa_t)$, и %
$\sigma^s_t: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая
от предыдущих ходов, которую игрок~1 использует если ходом случая реализовалось
состояние $s$.

Аналогичным образом, определим стратегиею игрока~2 как последовательность
ходов %
$\tau = (\tau_1, \tau_2, \ldots, \tau_n)$, где %
$\tau_t: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от
предыдущих ходов. Как видно, ход второго игрока на каждом шаге игры зависит
только от предыдущих ходов, и не зависит от состояния, в силу того, что второй
игрок не информирован о результате хода случая.

Обозначим описанную таким образом игру через $G_n(\po)$. Предположим, что эта
игра имеет значение, и стратегии $\sigma^*,\ \tau^*$ являются
оптимальными\footnote{Точные определения значения игры и оптимальных стратегий
  будут даны позднее.}. Тогда стратегия $\tau^*$ является оптимальной и в
изначальной игре с неполной информацией, как и стратегия $\sigma^{*s}$,
полученная из $\sigma^*$ отбрасыванием на каждом шаге всех компонент кроме
$s$-ой. Справедливо и обратное. Если существуют такие %
$(\sigma^{*1}, \tau^*), (\sigma^{*2}, \tau^*), \ldots, (\sigma^{*\kappa},
\tau^*)$, %
что пара $(\sigma^{*s}, \tau)$ является оптимальной в оригинальной игре с
неполной информацией при условии, что на самом деле разыгрывается $G_s$, то
стратегия $\sigma^*$, полученная из %
$(\sigma^{*1}, \sigma^{*2}, \ldots, \sigma^{*\kappa})$, и стратегия $\tau^*$
являются оптимальными в игре $G_n(\po)$.

Таким образом, для того, чтобы найти решение исходной игры с неполной
информацией, достаточно проанализировать игру $G_n(\po)$. Отметим также, что,
как показано в~\cite{aumann95}, достаточно рассматривать только стратегии,
которые зависят только от предыдущих ходов игрока~1 и не зависят от ходов
игрока~2.

\section{Описание модели}\label{ch1:model}
Рассмотрим упрощенную модель финансового рынка, на котором два игрока ведут
торговлю однотипными акциями на протяжении $n \leqslant \infty$ шагов, следуя
работе~\cite{domansky07}.

Перед началом торгов случайный ход определяет цену акции на весь период торгов,
которая может быть либо $m \in \N$ с вероятностью $p$, либо $0$ с вероятностью
$1-p$. Таким образом определенный ход случая является упрощенным аналогом
некоторого шокового события на финансовом рынке. Такого, например, как
публикация отчетов о доходах некоторой компании. Выбранная цена сообщается
первому игроку и не сообщается второму, при этом второй игрок знает, что первый
"--- инсайдер.

% На каждом шаге торгов игроки делают целочисленные ставки. Игрок, предложивший
% б\'{о}льшую ставку покупает у другого акцию по цене, равной выпуклой комбинации
% предложенных ставок с коэффициентом $\beta \in [0, 1]$; если ставки равны, то
% сделка на текущем шаге не состоится.

Рассмотрим $t$-й шаг торгов, где $t = \overline{1,n}$. На данном шаге первый
игрок выбирает ставку %
$i_t \in I = \{0, 1, \ldots, m\}$, а второй --- ставку %
$j_t \in J = \{0, 1, \ldots, m\}$. Игрок предложивший б\'{о}льшую ставку покупает у
другого акцию по цене равной
\[
  \Co \max(i_t, j_t) + \DCo \min(i_t, j_t),\ \text{где } %
  \Co \in [0, 1],\ \DCo = 1 - \Co.
\]
Если ставки равны, то сделка на $t$-м шаге не состоится. Коэффициент $\Co$ можно
интерпретировать как \emph{переговорную силу продавца} "--- чем ближе значение
к $1$, тем большую сумму получит продавец акции в результате сделки.

% Другой отличительной чертой модели с произвольным значением $\Co$, является тот
% факт, что ставка игрока равная $m$ больше не является доминируемой

% Выигрыш первого игрока в повторяющейся игре
% равен $\sum\limits_{t=1}^n a_{i_t j_t}^{s,\Co}$. Второму игроку этот выигрыш
% становится известным только после окончания игры. На промежуточных шагах он не
% имеет точной информации о величинах $a_{i_t, j_t}^{s,\Co}$.

Будем считать, что игроки обладают неограниченными запасами рисковых и
безрисковых активов, т.е. торги не могут прекратиться по причине того, что у
одного из игроков закончатся деньги или акции. Цель игроков состоит в
максимизации стоимости итогового портфеля, состоящего из некоторого числа
купленных акций и суммы денег, полученных в результате торгов. Таким образом, не
ограничивая общности, можно положить, что в начальный момент времени оба игрока
имеют нулевые портфели.

Фактически, в работах~\cite{domansky07, demeyer05}, а также в
работах~\cite{domansky11, domansky13, domansky14}, посвященных обобщению
дискретной модели, коэффициент $\Co = 1$. Мотивацией к рассмотрению дискретной
модели служит тот факт, что на реальных рынках расчеты ведутся пропорционально
минимальной денежной единице. При $\Co = 1$ все ставки будут целочисленны, как и
финальные выплаты игрокам. При рассмотрении модели с произвольным значением
$\Co$ цена сделки перестает быть целочисленной, однако интерпретацию
дискретности модели в этой постановке можно оставить неизменной, решив проблему
нецелой финальной выплаты размера $a$ с помощью случайного механизма, который
выберет либо выплату размера $[a]$, либо выплату размера $[a] + 1$. Ожидаемый
выигрыш при этом останется неизменным, но свойство дискретности сохранится.

\section{Формальная постановка задачи}

Определим формально повторяющуюся игру с неполной информацией, отвечающую
данному выше описанию. 

Пусть множество состояний рынка $S = \{L, H\}$. Перед началом игры случай
выбирает $s \in S $ с вероятностями $p(H) = p$ и $p(L) = 1 - p$. После этого на
протяжении $n \leq \infty$ шагов игроки играют в игру с матрицей $A^{s,\Co}$,
где
\begin{equation*}
  A^{L,\Co}(i, j) = \begin{cases}
    \DCo i + \Co j, &\, i < j, \\
    0, &\, i = j, \\
    -\Co i - \DCo j, &\, i > j,
  \end{cases}
  \qquad
  A^{H,\Co}(i, j) = \begin{cases}
    \DCo i + \Co j - m, &\, i < j, \\
    0, &\, i = j, \\
    m - \Co i - \DCo j, &\, i > j.
  \end{cases}
\end{equation*}


Стратегией первого игрока в данной игре является последовательность ходов %
$\sigma = (\sigma_1, \sigma_2, \ldots, \sigma_t, \ldots)$, где %
$\sigma_t: S \times I^{t-1} \rightarrow \Delta(I)$. Таким образом, на каждом
шаге торгов игрок~1 рандомизирует выбор ставки в зависимости от состояния и
предыдущих ставок. Как и в работе~\cite{domansky07}, мы ограничимся
рассмотрением только тех стратегий $\sigma$, которые гарантируют первому игроку
на каждом шаге игры неотрицательный выигрыш. Множество таких стратегий первого
игрока обозначим через $\Sigma$.

Аналогично стратегией второго игрока назовем последовательность ходов $\tau =
(\tau_1, \tau_2, \ldots, \tau_t, \ldots),$ где $\tau_t: I^{t-1} \rightarrow
\Delta(J)$. Не имея информации о настоящем состоянии, второй игрок при выборе
ставки опирается только на историю ставок инсайдера. Множество стратегий второго
игрока обозначим через $\Tau$.

Обозначим $\Pi[p, \sigma, \tau]$ вероятностное распределение на $(S, I, J)$
порожденное ходом случая и смешанными стратегиями $\sigma$ и $\tau$ игроков.
Также обозначим $\E_{p,\sigma,\tau}$ математическое ожидание по мере $\Pi[p,
\sigma, \tau]$.

При применении первым игроком смешанной стратегии $\sigma$, а вторым игроком
"--- смешанной стратегии $\tau$, ожидаемый выигрыш первого игрока
\begin{equation}
  \label{eq:firstPlayerPayoff}
  K^{m,\Co}_n(p, \sigma, \tau) = \E_{p,\sigma,\tau} \sum_{t=1}^n
  \left(
    pA^{H,\Co}(i_t^H, j_t) + (1 - p)A^{L,\Co}(i_t^L, j_t)
  \right).
\end{equation}
\begin{remark}
  В игре с произвольным значением $\beta$, в отличие от случая $\beta = 1$,
  стратегии использующие ставку $m$ не являются доминируемыми.
\end{remark}
Полученную игру обозначим через $G^{m,\Co}_n(p)$. Ее верхнее и нижнее
значения даются формулами
\begin{equation*}
  \underline{V}^{m,\Co}_n(p) = \sup_{\sigma \in \Sigma} \inf_{\tau \in \Tau}
  K^{m,\Co}_n(p, \sigma, \tau), \quad
  \overbar{V}^{m,\Co}_n(p) = \inf_{\tau \in \Tau} \sup_{\sigma \in \Sigma}
  K^{m,\Co}_n(p, \sigma, \tau).
\end{equation*}
Если верхнее и нижнее значения совпадают, то игра имеет значение, которое мы
обозначим $V^{m,Co}_n(p)$.

\begin{remark}
  Существование значения игры $G^{m,\Co}_n(p)$ при $n < \infty$ следует из
  общей теории. Для игры $G^{m,\Co}_\infty(p)$ ответ на этот вопрос будет
  получен далее.
\end{remark}

Заметим, что имеют место следующие равенства:
\begin{equation*}
  A^{L,\Co}(i, j) = A^{H,\DCo}(m-i, m-j), \quad
  A^{H,\Co}(i, j) = A^{L,\DCo}(m-i, m-j).
\end{equation*}
Определим симметричные по отношению к $\sigma$ и $\tau$ стратегии игроков
$\symm{\sigma}$ и $\symm{\tau}$ следующим образом. Для $t$-го шага
$\symm{\sigma_t} = (\symm{\sigma^H_t}, \symm{\sigma^L})$, где
$\symm{\sigma^s_t}=(\sigma^s_{t,m},\ldots,\sigma^s_{t,0}) \in \Delta(I)$, и
$\symm{\tau_t} = (\tau_{t,m},\ldots,\tau_{t,0}) \in \Delta(J)$. Легко видеть,
что выигрыши игроков в играх $G^{m,\Co}_n(p)$ и $\symmGameExpression[n]{1-p}$
при использовании симметричных стратегий совпадают.

В дальнейшем мы будем опускать верхний индекс $\Co$ там, где это не вызывает неоднозначности.

\section{Оценка сверху выигрыша первого игрока.}
Следуя \cite{domansky07}, рассмотрим чистую стратегию второго игрока $\tau^k, \,
k \in J$:
\[
  \tau^k_1 = k, \quad \tau^k_t(i_{t-1}, j_{t-1}) = \begin{cases}
    j_{t-1} - 1, & \, i_{t-1} < j_{t-1}, \\
    j_{t-1},     & \, i_{t-1} = j_{t-1}, \\
    j_{t-1} + 1, & \, i_{t-1} > j_{t-1}.
  \end{cases}
\]
По сути эта стратегия представляет собой стратегию подражания инсайдеру.
Доказательство следующего утверждения по форме повторяет доказательство
утверждения 4.3 из \cite{domansky07} и приводится в целях иллюстрации.

\begin{proposition}
  \label{proposition:secondPlayerStrategyPayoffs}
  При применении стратегии $\tau^k$ в игре $\generalGame{n}{p}$ второй игрок
  гарантирует себе проигрыш не более
  \[
    h_n^L(\tau^k) = \sum_{t=0}^{n-1}(k - t - \DCo)^+, \quad h_n^H(\tau^k) =
    \sum_{t=0}^{n-1}(m - k - t - \Co)^+,
  \]
  в состояниях L и H соответственно.
\end{proposition}
\begin{proof}
  Проведем доказательство по индукции для $h^L_n(\tau^k)$. При $n=1$ справедливо
  \[
    h^L_1(\tau^k) = \max_{i \in I} A^L(i, k) = \max(0, k - \DCo) = (k - \DCo)^+.
  \]
  Пусть формула верна при $n \leq N$. Для $n=N+1$ оптимальный первый ход
  инсайдера использует ставку $\max(0, k - 1)$, что соответствует либо продаже
  акции по наибольшей цене в случае $k > 0$, либо отсутствию сделки. Для случая
  $k > 0$ имеем
  \begin{gather*}
    h^L_{N+1}(\tau^k) = \DCo (k-1) + \Co k + h^L_N(\tau^{k-1}) =
    k - \DCo + \sum_{t=0}^{N-1}(k - 1 - t - \DCo)^+ = \\
    = k - \DCo + \sum_{t=1}^N(k-t-\DCo)^+ = \sum_{t=0}^N(k-t-\DCo)^+.
  \end{gather*}
  В случае $k = 0$ получаем
  \begin{gather*}
    h^L_{N+1}(\tau^k) = 0 + h^L_N(\tau^k) = \sum_{t=0}^{N-1}(k-t-\DCo)^+ = \sum_{t=0}^N(k-t-\DCo)^+.
  \end{gather*}
  Для $h^H_n(\tau^k)$ утверждение доказывается аналогично.
\end{proof}

Последовательности $\{h_n^L(\tau^k)\}$ и $\{h_n^H(\tau^k)\}$ не убывают и
ограничены сверху по $n$. Кроме того %
$h^s_m(\tau^k) = h^s_{m+1}(\tau^k) = \ldots = h^s_{m+i}(\tau^k),\ i \in \N$.
Введем следующую функцию:
\begin{multline*}
  \upperBound{p} 
  = \min_{j \in J} \lim_{n \rightarrow \infty}\left(
    ph_n^H(\tau^j) + (1-p)h_n^L(\tau^j)
  \right) = \\
  %
  = \min_{j \in J} \left[ p (m - j)(m - j + \DCo - \Co) + (1 - p)j(j + \Co
    - \DCo) \right] / 2 = \\
  = \min_{j \in J} \left[ j^2 + j(2\Co - 1 - 2 m p) + m p (1 + m - 2\Co) \right].
\end{multline*}

\begin{figure}[b]
  \centering
  \input{figures/ch1-omega-x-p}
  \caption{Функция $\omega(x,p)$ при $p \in \{(k-\DCo)/m, (k+\Co)/m\}$}
  \label{fig:ch1:omega(x,p)}
\end{figure}

Функция $\omega(x, p) = x^2 + x(2\Co - 1 - 2mp)$ достигает минимума по $x$ при
$x = m p - \Co + 1/2$. Поэтому при $p \in \left( (k-\DCo)/m, (k+\Co)/m) \right]$
минимум функции $j^2 + j(2\Co - 1 - 2 m p)$ по $j \in J$ достигается при $j = k$
(см. рис~\ref{fig:ch1:omega(x,p)}).

Таким образом, $\upperBound{p}$ является кусочно-линейной функцией, состоящей из
$m~+~1$ линейных сегментов, и полностью определяется своими значениями в точках
\begin{gather*}
  \upperBound{(k+\Co)/m} = \left( (m - (k + \Co))(k + \Co) + \DCo\Co
  \right) / 2, \enskip
  k = \overline{0, m - 1},\\
  \upperBound{0} = \upperBound{1} = 0.
\end{gather*}

Пусть второй игрок при $p \in \left( (k-\DCo)/m, (k+\Co)/m) \right]$
применяет $\tau^k, \, k = \overline{0, m}$. Обозначим эту стратегию через
$\tau^*$. Тогда справедлива следующая
\begin{lemma}
  \label{lemma:upperBound}
  При использовании вторым игроком стратегии $\tau^*$ в игре
  $\infiniteGame{p}$\textup{,} выигрыш первого игрока ограничен сверху функцией
  $\upperBound{p}$, т.е.
  \[
    \max_{\sigma \in \Sigma} \infiniteFirstPlayerPayoff{p}{\sigma}{\tau^*} \leq
    \upperBound{p}.
  \]
\end{lemma}

\section{Оценка снизу выигрыша первого игрока}
Перейдем к описанию стратегии первого игрока, гарантирующей ему выигрыш не менее
$\upperBound{p}$ в игре $\infiniteGame{p}$.

Пусть на первом шаге игры первый игрок применяет %
$\fGeneral{k} = \left(\fGeneral{H}, \fGeneral{L}\right)$, где %
$\fGeneral{H} = \left(\fGeneral[1,k]{H}, \fGeneral[1,k+1]{H}\right)$,
$\fGeneral{L} = \left(\fGeneral[1,k]{L}, \fGeneral[1,k+1]{L}\right)$ и
$\fGeneral[1,i]{s}$ -- вероятность сделать ставку $i$ в состоянии $s \in S$.
Применяя $\fGeneral{k}$, инсайдер делает ставки $k$ и $k+1$ с некоторыми
заданными вероятностями.

Определим следующие параметры: полные вероятности использования действий $k$ и
$k+1$, равные $q_k$ и $q_{k+1}$ соответственно, а также апостериорные
вероятности $p(s|i)$ состояния $s$ при условии, что на предыдущем шаге первый
игрок сделал ставку $i$. Тогда вероятности $\fGeneral[1,i]{s}$ можно найти по
формуле Байеса
\[
  \fGeneral[1,i]{s}~=~p(s|i)q_i/p(s), \: i = k, k + 1.
\]

\begin{proposition}
  При использовании $\fGeneral{k}$ первый игрок гарантирует себе на первом шаге
  выигрыш
  \begin{equation}
    \label{eq:lowerPayoffGeneral}
    \firstPlayerPayoff{1}{p}{\fGeneral{k}}{j} =
    \begin{cases}
      mp - \Co k - \DCo j - \Co q_{k+1},      & \, j < k,     \\
      \left(m p(H|k+1) - k - \Co \right) q_{k+1}, & \, j = k,     \\
      \left(k + \Co - m p(H|k) \right) q_k,       & \, j = k + 1, \\
      \DCo k + \Co j - mp + \DCo q_{k+1}, & \, j > k + 1.
    \end{cases}
  \end{equation}
\end{proposition}
\begin{proof}
  Пусть $j < k$. Тогда из \eqref{eq:firstPlayerPayoff} и определения
  $\fGeneral{k}$ получаем
  \begin{align*}
    \firstPlayerPayoff{1}{p}{\fGeneral{k}}{j} &=
    p \left( 
      \fGeneral[1,k]{H} (m - \Co k - \DCo j) +
      \fGeneral[1,k+1]{H} (m - \Co (k+1) - \DCo j)
    \right) + \\
    &+ (1-p) \left( 
      \fGeneral[1,k]{L} (- \Co k - \DCo j) +
      \fGeneral[1,k+1]{L} (- \Co (k+1) - \DCo j)
    \right) = \\
    &=
    m p (\fGeneral[1,k]{H} + \fGeneral[1,k+1]{H}) -
    \left(
      p (\fGeneral[1,k]{H} + \fGeneral[1,k+1]{H}) +
      (1-p) (\fGeneral[1,k]{L} + \fGeneral[1,k+1]{L})
    \right) \times \\ 
    &\times (\Co k + \DCo j) -
    (p \fGeneral[1,k+1]{H} + (1-p) \fGeneral[1,k+1]{L}) \Co = \\
    &= mp - \Co k - \DCo j - \Co q_{k+1}.
  \end{align*}
  При $j = k$ имеет место равенство
  \begin{align*}
    \firstPlayerPayoff{1}{p}{\fGeneral{k}}{j} 
    &=
      p \fGeneral[1,k+1]{H} (m - \Co (k+1) - \DCo k) +
      (1-p) \fGeneral[1,k+1]{L} (- \Co (k+1) - \DCo k) = \\
    &= m p \fGeneral[1,k+1]{H} - 
      (p \fGeneral[1,k+1]{H} + (1-p) \fGeneral[1,k+1]{L}) (\Co (k+1) + \DCo k) =\\
    &= m p(H|k+1) q_{k+1} - q_{k+1} (\Co (k+1) + \DCo k) = \\
    &= (m p(H|k+1) - k - \Co) q_{k+1}.
  \end{align*}
  Случаи $j = k + 1$ и $j > k + 1$ разбираются аналогично.
\end{proof}

Построим оптимальную стратегию инсайдера. Рассмотрим на $[0,1]$ множество $P$
точек вида

\[
\pEven[i] = i/m, \, i = \overline{0, m}, \quad \pOdd[i] = (i + \Co)/m, \, i =
\overline{0, m - 1}.
\]

Для $p = \pEven$ определим $\fEven$ как действие $\fGeneral{k}$ с параметрами
\begin{equation*}
  p(H|k) = \pOdd[k-1], \quad p(H|k + 1) = \pOdd[k], \quad q_k = \Co, \quad q_{k+1} = \DCo.
\end{equation*}
Дополнительно определим $\fEven[0]$ как действие, состоящее в применении ставки
$0$ с вероятностью $1$, а $\fEven[m]$ -- как действие, состоящее в применении
ставки $m$ с вероятностью $1$. Аналогично для $p = \pOdd$ определим $\fOdd$ как
действие $\fGeneral{k}$ с параметрами
\begin{equation*}
  p(H|k) = \pEven[k], \quad p(H|k + 1) = \pEven[k+1], \quad q_k = \DCo, \quad q_{k+1} = \Co.
\end{equation*}

\begin{proposition}
  При $p \in P$ для значения $\firstPlayerPayoff{1}{p}{\sigma}{j}$ выигрыша
  первого игрока верны оценки
  \begin{equation}
    \label{eq:lowerBound:inequalities}
    \min_{j \in J}
    \firstPlayerPayoff{1}{\pEven}{\fEven}{j} \geq 0,
    \quad
    \min_{j \in J}
    \firstPlayerPayoff{1}{\pOdd}{\fOdd}{j} \geq \DCo\Co.
  \end{equation}
\end{proposition}
\begin{proof}
  Подставив полные вероятности действий и апостериорные вероятности состояний в
  \eqref{eq:firstPlayerPayoff}, получим для $p = \pOdd[k]$
  \begin{equation*}
    \firstPlayerPayoff{1}{\pOdd}{\fOdd}{j} = \begin{cases}
      k + \Co - \Co k - \DCo j - \Co^2 < \Co \DCo,\ & j < k,\\
      (k + 1 - k - \Co) \Co = \Co \DCo,\ & j = k,\\
      (k + \Co - k) \DCo = \Co \DCo,\ & j = k+1,\\
      \DCo k + \Co j - k - \Co + \Co \DCo > \Co \DCo,\ & j > k+1.
    \end{cases}
  \end{equation*}
  Справедливость неравенства %
  $\min_{j \in J} \firstPlayerPayoff{1}{\pEven}{\fEven}{j} \geq 0$ %
  устанавливается аналогично.
\end{proof}

Заметим, что если $p \in P$, то при применении инсайдером на первом шаге игры
$\fEven$ и $\fOdd$, значения апостериорных вероятностей также принадлежат $P$.
Таким образом, можно продолжить применение $\fEven$ и $\fOdd$ на последующих
шагах игры, тем самым определив стратегию $\fOpt$ в игре $\generalGame{n}{p}$,
при $p \in P, \, n \in \mathbb{N}$.

Пусть $\lowerBound[n]{p}$ при $p \in P$ --- гарантированный выигрыш первого
игрока в игре $\generalGame{n}{p}$ при применении стратегии $\fOpt$. В силу
неравенств (\ref{eq:lowerBound:inequalities}) и рекурсивной структуры игры
$\generalGame{n}{p}$ (см. \cite{domansky07}) для $\lowerBound[n]{p}$ справедливы
формулы
\begin{equation}
  \begin{gathered}
    \label{eq:lowerBound:recurrence:function}
    \lowerBound[n]{(k + \Co)/m} = \DCo\Co + \DCo\lowerBound[n-1]{k/m} +
    \Co\lowerBound[n-1]{(k + 1)/m}, \: k = \overline{0, m-1}, \\
    % 
    \lowerBound[n]{k/m} = \Co\lowerBound[n-1]{(k - 1 + \Co)/m} +
    \DCo\lowerBound[n-1]{(k + \Co)/m}, \: k = \overline{1, m-1}, \\
    % 
    \lowerBound[n]{0} = \lowerBound[n]{1} = 0.
  \end{gathered}
\end{equation}

Так как $\lowerBound[n]{p}$ не убывает по $n$ и ограничена сверху, то устремив
$n$ к бесконечности, получим нижнюю оценку $\lowerBound{p}$ выигрыша первого
игрока в игре $\infiniteGame{p}, \, p \in P$.

Введем следующие обозначения:
\[
  L_{2k} = \lowerBound{k/m}, \, k = \overline{0,m}, \enskip%
  L_{2k+1} = \lowerBound{(k+\Co)/m)}, \, k = \overline{0,m-1}.
\]
Тогда справедливы формулы
\begin{equation}
  \label{eq:lowerRecurrence}
  \begin{gathered}
    L_{2k+1} = \DCo\Co + \DCo L_{2k} + \Co L_{2(k+1)}, \enskip k = \overline{0, m-1},\\
    L_{2k} = \Co L_{2k-1} + \DCo L_{2k+1}, \enskip k = \overline{1, m-1},\\
    L_0 = L_{2m} = 0.
  \end{gathered}
\end{equation}

Введем $(2m-1)\times(2m-1)$-матрицу $B$ и $(2m-1)$-вектор-столбец $b$:
\begin{equation*}
  B =
  \left(
    \begin{array}{cccccccc}
      1      & -\Co  & 0       & 0      & \cdots & 0      & 0       & 0       \\
      -\Co & 1       & -\DCo & 0      & \cdots & 0      & 0       & 0       \\
      0      & -\DCo & 1       & -\Co & \cdots & 0      & 0       & 0       \\
      \hdotsfor{8}                                                              \\
      0      & 0       & 0       & 0      & \cdots & -\Co & 1       & -\DCo \\
      0      & 0       & 0       & 0      & \cdots & 0      & -\DCo & 1 
    \end{array}
  \right),\quad
  %
  b = \left(
    \begin{array}{c}
      \DCo\Co \\
      0           \\
      \DCo\Co \\
      \cdots      \\
      0           \\
      \DCo\Co
    \end{array}
  \right).
\end{equation*}
Тогда (\ref{eq:lowerRecurrence}) перепишем в виде $ BL = b, L_0 = L_{2m} = 0, $
где $L = (L_1, L_2, \ldots, L_{2m-1})$.

Системы $ Mx = f $ с трехдиагональной матрицей $ M $, имеющей структуру
\[
  M = \left(\begin{array}{ccccccc}
              c_1 & b_1 & 0   & \cdots & 0       & 0       & 0       \\
              a_2 & c_2 & b_2 & \cdots & 0       & 0       & 0       \\
              \hdotsfor{7}                                           \\
              0   & 0   & 0   & \cdots & a_{n-1} & c_{n-1} & b_{n-1} \\
              0 & 0 & 0 & \cdots & 0 & a_n & c_n
            \end{array}\right),
\]
можно решать методом прогонки, используя следующие формулы для
прогоночных коэффициентов и переменных (см. \cite{samarsky89}):
\begin{gather*}
  x_i = \gamma_{i+1} x_{i+1} + \delta_{i+1}, \: i = \overline{1,n-1},
  \quad
  x_n = \frac{f_n - a_n\delta_n}{c_n + a_n\gamma_n}, \\
  % 
  \gamma_{i+1} = -\frac{b_i}{c_i + a_i\gamma_i}, \: i = \overline{2,
    n-1}, \quad
  \gamma_2 = -\frac{b_1}{c_1}, \\
  % 
  \delta_{i+1} = \frac{f_i - a_i\delta_i}{c_i + a_i\gamma_i}, \: i =
  \overline{2, n-1}, \quad \delta_2 = \frac{f_1}{c_1}.
\end{gather*}

\begin{proposition}
  \label{proposition:tridiagonal:coefficients}
  Прогоночные коэффициенты для матрицы $B$ даются следующими
  формулами\textup{:}
  \begin{multline*}
    \gamma_{2k} = \frac{\Co+k-1}{k}, \,
    \gamma_{2k+1} = \frac{k}{k+\Co}, \\
    \delta_{2k} = \frac{\DCo(k-1+2\Co)}{2}, \, \delta_{2k+1} =
    \frac{k\Co(k-1+2\Co)}{2(k+\Co)}, \quad k = \overline{1,m-1}.
  \end{multline*}
\end{proposition}
Данное утверждение доказывается по индукции.

Из (\ref{eq:lowerRecurrence}) следует, что $L_{2k-1} =
\gamma_{2k}\gamma_{2k+1}L_{2k+1} + \gamma_{2k}\delta_{2k+1} +
\delta_{2k}, \, k = \overline{1, m-1}$. Подстановкой
$\upperBound{(k+\Co)/m}$ вместо $L_{2k+1}$ это равенство обращается в
тождество. Тем самым доказано

\begin{proposition}
  \label{proposition:lower:recurrence-solution}
  Решение системы {\normalfont(\ref{eq:lowerRecurrence})} дается
  следующими формулами\textup{:}
  \begin{gather*}
    L_{2k+1} = ((m - (k + \Co))(k + \Co) + \DCo\Co)/2, \, k = \overline{0, m-1},\\
    L_{2k} = k (m-k)/2, \, k = \overline{0,m}.
  \end{gather*}
\end{proposition}

Итак, мы определили функцию $\lowerBound{p}$ при $p \in P$. Для %
$p \in [0, 1] \setminus P$ стратегия инсайдера основана на применении выпуклой
комбинации стратегий для крайних точек интервала, в котором находится $p$.

Обозначим через $\lambda\fOdd[k] + (1-\lambda)\fEven[k+1]$ распределение, при
котором первый игрок рандомизирует выбор ставок $k, k+1, k+2$ с параметрами
\begin{gather*}
  q_k = \lambda\DCo, \, q_{k+1} = \Co, \, q_{k+2} = (1-\lambda)\DCo,\\
  p(H|k) = \pEven, \, p(H|k+1) = \lambda \pEven[k+1] + (1-\lambda)
  \pOdd, \, p(H|k+2) = \pOdd[k+1].
\end{gather*}

Через $\lambda\fEven + (1-\lambda)\fOdd$ обозначим распределение, при котором
первый игрок рандомизирует выбор ставок $k$ и $k+1$ с параметрами
  \begin{gather*}
    q_k = \lambda\Co + (1-\lambda)(1-\Co), \: p(H|k) =
    \frac{\lambda\Co}{q_k}\pOdd[k-1] +
    \frac{(1-\lambda)(1-\Co)}{q_k} \pEven,\\
    q_{k+1} = \lambda(1-\Co) + (1-\lambda)\Co, \: p(H|k+1) =
    \frac{\lambda(1-\Co)}{q_{k+1}}\pOdd[k] +
    \frac{(1-\lambda)\Co}{q_{k+1}}\pEven[k+1].
  \end{gather*}

Справедливость следующего утверждение следует из линейности
$\firstPlayerPayoff{1}{p}{\sigma}{j}$ по $\sigma$ и равенства
(\ref{eq:lowerPayoffGeneral}).

\begin{proposition}
  \label{proposition:first:combination:step}
  При $\lambda \in (0, 1), \, \Co \geq 1/2, \, k = \overline{0, m-1}$ для
  значения одношагового выигрыша первого игрока верны оценки
  \begin{align*}
    \min_{j \in J}
    \firstPlayerPayoff{1}{%
    \lambda \pEven + (1-\lambda) \pOdd}{%
    \lambda \fEven + (1-\lambda) \fOdd}{%
    j}
    &\geq \DCo \Co (1-\lambda), \\
    % 
    \min_{j \in J}
    \firstPlayerPayoff{1}{%
    \lambda \pOdd + (1-\lambda) \pEven[k+1]}{%
    \lambda \fOdd + (1-\lambda) \fEven[k+1]}{%
    j}
    &\geq \DCo \Co \lambda.
  \end{align*}
\end{proposition}

\begin{proposition}
  \label{proposition:first:combination:game}
  При $\lambda \in (0, 1), \, \Co \geq 1/2, \, k = \overline{0, m-1}$,
  для гарантированного выигрыша первого игрока в игре $\infiniteGame{p}$
  справедливы равенства
  \begin{align*}
    \lowerBound{\lambda \pEven + (1-\lambda) \pOdd}      
    &= 
      \lambda \lowerBound{\pEven} + (1-\lambda) \lowerBound{\pOdd}, \\
    \lowerBound{\lambda \pOdd + (1-\lambda) \pEven[k+1]} 
    &= \lambda \lowerBound{\pOdd} + (1-\lambda) \lowerBound{\pEven}.
  \end{align*}
\end{proposition}
\begin{proof}
  Пусть $p = \lambda \pOdd + (1-\lambda) \pEven[k+1]$, где %
  $k = \overline{0, m - 2}, \, \lambda \in (0, 1)$. Тогда по аналогии с
  \eqref{eq:lowerBound:recurrence:function} выписывается следующая рекуррентная
  формула:
  \[
    \lowerBound{p} = \DCo \Co \lambda + \lambda \DCo
    \lowerBound{\pEven} + (1-\lambda) \DCo \lowerBound{\pOdd[k+1]} +
    \Co \lowerBound{(1-\lambda) \pOdd + \lambda \pEven[k+1]}.
  \]
  Так как %
  $(1-\lambda)\pOdd + \lambda \pEven[k+1] \in (\pOdd, \pEven[k+1])$, то для
  $\lowerBound{(1-\lambda)\pOdd + \lambda \pEven[k+1]}$ справедливо аналогичное
  представление. Приведя подобные члены, получим
  \begin{multline}
    \label{eq:first:combination:game:2}
    \lowerBound{p} = \frac{1}{1-\Co^2}
    \left(
      \DCo\Co\lambda + 
      \DCo\lambda\lowerBound{\pEven} + 
      (1-\lambda)\DCo\lowerBound{\pOdd[k+1]} + 
    \right.\\
    % 
    \left. 
      + \Co \left( 
        \DCo\Co(1-\lambda) +
        (1-\lambda)\DCo\lowerBound{\pEven} +
        \lambda\DCo\lowerBound{\pOdd[k+1]} 
      \right)
    \right) = \\
    % 
    = \left( (k + 1)(m - k - 1) + \DCo\lambda(2k - m + 2\Co + 1)
    \right)/2 = \\
    = \lambda\lowerBound{\pOdd} + (1-\lambda)\lowerBound{\pEven[k+1]}.
  \end{multline}
  
  Пусть $p = \lambda\pEven + (1-\lambda)\pOdd$, где %
  $k = \overline{1, m - 1}, \, \lambda \in (0, 1)$. Заметим, что %
  $p(H|k) \in ( \pOdd[k-1], \pEven )$, а %
  $p(H|k+1) \in ( \pOdd, \pEven[k+1] )$. Тогда с помощью
  \eqref{eq:first:combination:game:2} получим
  \begin{multline*}
    \lowerBound{p} =
    \lambda \Co \lowerBound{\pOdd[k-1]} + 
    (1-\lambda)(1-\Co)\lowerBound{\pEven} + \lambda(1-\Co)\lowerBound{\pOdd} + \\
    + (1-\lambda)\Co\lowerBound{\pEven[k+1]} 
    = \lambda \lowerBound{\pEven} + (1-\lambda) \lowerBound{\pOdd}.
  \end{multline*}
  
  При $p \in ( 0, \pOdd[1] )$ и $p \in ( \pOdd[m-1], 1 )$ доказательство
  проводится аналогично.
\end{proof}

Заметим, что при $\Co < 1/2$ полученные результаты также имеют место, а
стратегию $\fOpt$ можно получить, рассмотрев игру $\symmGameExpression[n]{1-p}$.
Таким образом, мы определили стратегию $\fOpt$ и максимальный гарантированный
выигрыш первого игрока $\lowerBound{p}$ для любых %
$p \in [0, 1], \, \Co \in [0, 1]$. Отсюда вытекает справедливость следующей
леммы.

\begin{lemma}
  \label{lemma:first:lower}
  При использовании первым игроком стратегии $\fOpt$ в игре
  $\infiniteGame{p}$\textup{,} его выигрыш ограничен снизу функцией
  $\lowerBound{p}$\textup{,} т.е.
  \[
    \min_{\tau \in \Tau} \infiniteFirstPlayerPayoff{p}{\fOpt}{\tau} \geq
    \lowerBound{p}.
  \]
\end{lemma}

% Отметим, что приведенная стратегия инсайдера для $p \in [0, 1] \setminus
% P$ принципиально отличается от его стратегии в \cite{pyanykh14}, которая
% оптимальна только при $\Co = 1/2$.

\section{Значение игры}

Доказательство следующей теоремы следуем непосредственно из лемм
\ref{lemma:upperBound} и \ref{lemma:first:lower} и по форме повторяет
доказательство аналогичной теоремы в \cite{domansky07}.
\begin{theorem}
  Игра $\infiniteGame{p}$ имеет значение $\infiniteGameValue{p} = \upperBound{p}
  = \lowerBound{p}$. При этом $\fOpt$ -- оптимальная стратегия первого
  игрока\textup{,} а $\tau^*$ -- оптимальная стратегия второго игрока.
\end{theorem}

\todo{
  \begin{enumerate}
  \item Доказательство для утверждения о прогоночных коэффициентах.
  \item Доказательство для утверждения об одношаговом выигрыше для промежуточных точек.
  \item Секция про случайное блуждание апостериорных вероятностей
    (продолжительность, чем похоже, чем отличается).
  \item Заключение: сравнение стратегий игроков, сравнение выигрышей при
    различных значениях $\Co$. Сказать что в $p = k/m$ все функции выигрышей
    пересекаются.
  \item Рисунок, иллюстрирующий эволюцию апостериорных вероятностей для
    стратегий игроков.
  \item Все ссылки должны быть под \texttt{ch1:} пространством имен.
  \end{enumerate}
}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../dissertation"
%%% End:
