
\section*{Общая характеристика работы}

\newcommand{\emphasis}[1]{\textbf{{#1}}}
\newcommand{\actuality}{\emphasis{\actualityTXT}}
\newcommand{\progress}{\emphasis{\progressTXT}}
\newcommand{\aim}{\emphasis{\aimTXT}}
\newcommand{\tasks}{\emphasis{\tasksTXT}}
\newcommand{\researchsubject}{\emphasis{\researchsubjectTXT}}
\newcommand{\novelty}{\emphasis{\noveltyTXT}}
\newcommand{\influence}{\emphasis{\influenceTXT}}
\newcommand{\methods}{\emphasis{\methodsTXT}}
\newcommand{\defpositions}{\emphasis{\defpositionsTXT}}
\newcommand{\reliability}{\emphasis{\reliabilityTXT}}
\newcommand{\probation}{\emphasis{\probationTXT}}
\newcommand{\contribution}{\emphasis{\contributionTXT}}
\newcommand{\publications}{\emphasis{\publicationsTXT}}

\input{common/characteristic} % Характеристика работы по структуре во введении и в автореферате не отличается (ГОСТ Р 7.0.11, пункты 5.3.1 и 9.2.1), потому её загружаем из одного и того же внешнего файла, предварительно задав форму выделения некоторым параметрам

%Диссертационная работа была выполнена при поддержке грантов ...

\emphasis{Объем и структура работы.}
Диссертация состоит из~введения, трех глав и заключения.
Полный объем диссертации составляет \textbf{96}~страниц текста с~\textbf{8}~рисунками и~\textbf{2}~таблицами.
Список литературы содержит \textbf{59}~наименований.

\textbf{Благодарности.} Автор выражает глубокую признательность своему научному руководителю, кандидату физико-математических наук, доценту Владимиру Викторовичу Морозову за ценные замечания, поддержку и неоценимую помощь в подготовке диссертации.

%\newpage
\section*{Содержание работы}
Во \emphasis{введении} обосновывается актуальность исследований, проводимых в рамках данной диссертационной работы, приводится обзор научной литературы по изучаемой проблеме, формулируется цель, ставятся задачи работы, сформулированы научная новизна, теоретическая и практическая значимость представляемой работы, а также результаты, выносимые на защиту.

% * Chapter 1
\emphasis{Первая глава} посвящена исследованию теоретико-игровой модели биржевых торгов с дискретными ставками и двумя состояниями.

% ** Основные понятия и введение в тему
В \emphasis{разделе 1.1} диссертации дано введение в теорию повторяющихся игр с неполной информацией, определены основные термины и понятия.

Рассмотрим антагонистическую игру двух лиц, которая повторяется $n$ раз, где $n\leq \infty$.
Будем считать, что первый игрок знает функцию выигрыша в данной игре, в то время как второй игрок такой информацией не обладает.
Однако второй игрок знает, что настоящая функция выигрыша является одной из $\kappa$ возможных альтернатив.
Каждой такой альтернативе второй игрок приписывает некоторую вероятность того, что данная функция выигрыша является истинной функцией выигрыша в рассматриваемой
игре.
Таким образом, априорные убеждения второго игрока задаются вероятностным вектором
$
  \pd = (\pc{1}, \pc{2}, \ldots, \pc{\kappa}),\ \sum_{i=1}^\kappa \pc{i} = 1.
$

С данными функциями выигрыша можно связать игры $G_1, G_2, \ldots, G_\kappa$.
В дальнейшем мы будем считать, что информационная неопределенность второго игрока заключается именно в незнании того, какая из игр разыгрывается.

На каждом шаге игры первый игрок может совершать действия из множества $I$, второй игрок --- действия из множества $J$, при этом мы считаем, что множества действий одного игрока известно другому.
Кроме того, положим, что второй игрок знает, что первый обладает точной информацией о том, какая именно игра разыгрывается, а первый игрок знает априорные убеждения второго.

Игры $G_1, G_2, \ldots, G_\kappa$ будем называть \emph{одношаговыми играми}.
Все одношаговые игры описываются матрицами размера $|I| \times |J|$, где элементы матрицы задают выплаты первому игроку.
Мы предполагаем, что оба игрока точно знают платежные матрицы игр $G_1, G_2, \ldots, G_\kappa$.
На каждом шаге игры первый игрок выбирает номер строки, и одновременно с ним второй игрок выбирает номер столбца.
В конце каждого хода действия игроков оглашаются, и элемент из матрицы, отвечающей настоящей игре, прибавляется к выигрышу первого игрока и вычитается из выигрыша второго.
Таким образом, первый игрок знает свой выигрыш на каждом этапе игры, в то время как второй может лишь рассчитать свой ожидаемый выигрыш.
В завершение, мы считаем, что данное описание известно обоим игрокам.

Данная игра с неполной информацией описывается в виде игры в нормальной форме следующим образом.
Обозначим через $S = \{1, 2, \ldots, \kappa\}$ множество возможных альтернатив или \emph{состояний природы}.
Перед началом игры ходом случая в соответствии с вероятностным распределением $\pd$ выбирается состояние $s \in S$.
Далее на протяжении $n$ шагов разыгрывается игра $G_s$.
Первый игрок информирован о результате хода случая, второй игрок "--- нет.
В остальном правила данной игры совпадают с описанными выше.

Пусть $h_t = \left((i_1, j_1), (i_2, j_2), \ldots, (i_t, j_t)\right)$ "--- история ставок игроков после завершения шага $t$.
Множество все таких $h_t$ обозначим через $H_t$. 

Обозначим через $\Delta(X)$ совокупность всех вероятностных распределений на множестве $X$.

Стратегией первого игрока в такой игре является последовательность ходов (отображений) $\sigmar = (\sigmas{1}, \sigmas{2}, \ldots, \sigmas{n})$, где $\sigmas{t} = (\sigmas[1]{t}, \sigmas[2]{t}, \ldots, \sigmas[\kappa]{t})$, и $\sigmas[s]{t}: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от предыдущих ходов, которую первый игрок использует, если ходом случая реализовалось состояние $s$.

Аналогичным образом определим стратегию второго игрока как последовательность ходов (отображений) $\taur = (\taus{1}, \taus{2}, \ldots, \taus{n})$, где $\taus{t}: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от предыдущих ходов.
Как видно, ход второго игрока на каждом шаге игры зависит только от предыдущих ходов, и не зависит от состояния, в силу того, что второй игрок не информирован о результате хода случая.

Отметим, что, как показано в книге Мертенса, Сорена и Замира~\cite{mertens15}, на шаге $t$ обоим игрокам достаточно принимать в расчет лишь последовательность $(i_1, i_2, \ldots, i_{t-1})$ действий первого игрока на предыдущих ходах.
Это связано с тем, что информация, получаемая вторым игроком относительно состояния $s$, может передаваться лишь посредством действий первого игрока.

Также нужно отметить, что в данной работе рассмотрены игры, в которых выигрыш равен суммарным выплатам, в отличие от постановки из монографии Аумана, Машлера, в которой рассматривались игры с усредненными выплатами.

% ** Описание дискретной модели
В \emphasis{разделе 1.2} приводится описание дискретной модели биржевых торгов.
Следуя работе В.~К.~Доманского (\seename~ссылку на стр.~\pageref{domansky07ref}), рассматривается упрощенная модель финансового рынка, на котором два игрока ведут торговлю однотипными акциями на протяжении $n \leqslant \infty$ шагов.
%
Перед началом торгов случайный ход определяет цену акции на весь период торгов, которая может быть либо $m \in \N$ с вероятностью $p$, либо $0$ с вероятностью $1-p$.
Таким образом определенный ход случая является упрощенным аналогом некоторого шокового события на финансовом рынке (такого, как, например, публикация отчетов о доходах некоторой компании).
Выбранная цена сообщается первому игроку и не сообщается второму, при этом второй игрок знает, что первый "--- инсайдер.

Рассмотрим $t$-й шаг торгов, где $t = \overline{1,n}$.
На данном шаге первый игрок выбирает ставку $i_t \in I = \{0, 1, \ldots, m\}$, а второй --- ставку $j_t \in J = \{0, 1, \ldots, m\}$.
Игрок, предложивший б\'{о}льшую ставку, покупает у другого акцию по цене равной
$
  \Co \max(i_t, j_t) + \DCo \min(i_t, j_t),\ \text{где } %
  \Co \in (0, 1),\ \DCo = 1 - \Co.
$
Если ставки равны, то сделка на $t$-м шаге не состоится.
Коэффициент $\Co$ можно интерпретировать как \emph{переговорную силу продавца}: чем ближе значение к $1$, тем большую сумму получит продавец акции в результате сделки.

Считаем, что игроки обладают неограниченными запасами рисковых и безрисковых активов, т.е. торги не могут прекратиться по причине того, что у одного из игроков закончатся деньги или акции.
Цель игроков состоит в максимизации стоимости итогового портфеля, состоящего из некоторого числа купленных акций и суммы денег, полученных в результате торгов.
Таким образом, не ограничивая общности, можно положить, что в начальный момент времени оба игрока имеют нулевые портфели.

% ** Определение игры G^m_n(p)

В \emphasis{разделе 1.3} формально определяется повторяющаяся игра с неполной информацией, отвечающая данному выше описанию.

Пусть множество состояний рынка $S = \{L, H\}$.
Перед началом игры случай выбирает $s \in S $ с вероятностями $P(s=H) = p$ и $P(s=L) = 1 - p$.
После этого на протяжении $n \leq \infty$ шагов игроки участвуют в игре с матрицей $A^{s,\Co}$, где элементы матрицы заданы следующим образом:
\begin{equation*}
  \as[L](i, j) = \begin{cases}
    \DCo i + \Co j, &\, i < j, \\
    0, &\, i = j, \\
    -\Co i - \DCo j, &\, i > j,
  \end{cases}
  \qquad
  \as[H](i, j) = \begin{cases}
    \DCo i + \Co j - m, &\, i < j, \\
    0, &\, i = j, \\
    m - \Co i - \DCo j, &\, i > j.
  \end{cases}
\end{equation*}

Как и в работе В.~К.~Доманского, мы ограничимся рассмотрением только тех стратегий $\sigmar$ первого игрока, которые гарантируют ему на каждом шаге игры неотрицательный выигрыш.
Множество таких стратегий обозначим через $\Sigma$.
Множество стратегий второго игрока обозначим через $\Tau$.

Обозначим через $\E_{(p,\sigmar,\taur)}$ математическое ожидание по мере, индуцированной на $S \times I^n \times J^n$ ходом случая и смешанными стратегиями $\sigmar$ и $\taur$ игроков.
%%%%%%%%%
При применении первым игроком смешанной стратегии $\sigmar$, а вторым игроком смешанной стратегии $\taur$, ожидаемый выигрыш первого игрока
\begin{equation}
  \label{ch1:eq:firstPlayerPayoff}
  \K*{n}(p, \sigmar, \taur) = \E_{(p,\sigmar,\taur)} \sum_{t=1}^n
  \left(
    p \as[H](i_t^H, j_t) + (1 - p)\as[L](i_t^L, j_t)
  \right).
\end{equation}

Полученную игру обозначим через $\theG*{n}(p)$.
Ее верхнее и нижнее значения даются формулами
\begin{equation*}
  \LowV*{n}(p) = \max_{\sigmar \in \Sigma} \inf_{\taur \in \Tau}
  \K*{n}(p, \sigmar, \taur), \quad
  \HighV*{n}(p) = \min_{\taur \in \Tau} \sup_{\sigmar \in \Sigma}
  \K*{n}(p, \sigmar, \taur).
\end{equation*}
Если верхнее и нижнее значения совпадают, то игра имеет значение, которое мы обозначим $\V*{n}(p)$.

В \emphasis{разделе 1.4} рассматривается следующая чистая стратегия второго игрока $\tau^k,\ k \in J$, введенная В.~К.~Доманским в базовой работе:
\[
  \tau^k_1 = k, \quad \tau^k_t(i_{t-1}, j_{t-1}) = \begin{cases}
    j_{t-1} - 1, & \, i_{t-1} < j_{t-1}, \\
    j_{t-1},     & \, i_{t-1} = j_{t-1}, \\
    j_{t-1} + 1, & \, i_{t-1} > j_{t-1}.
  \end{cases}
\]
Пусть стратегия второго игрока $\taur^*$ состоит в применении $\tau^k$ при $p \in \left( (k-\DCo)/m, (k+\Co)/m) \right]\, k = \overline{0, m}$.
Справедлива следующая
\begin{theorem}
  Зафиксируем вероятность $p \in [0,1]$.
  Тогда при использовании вторым игроком стратегии $\taur^*$ в игре $\theG*{\infty}(p)$\textup{,} выигрыш первого игрока ограничен сверху величиной $\H*{\infty}(p)$, т.е.
  \[ 
    \max_{\sigmar \in \Sigma} \K*{\infty}(p, \sigmar, \taur^*) \leq \H*{\infty}(p).
  \]

  $\H*{\infty}(p)$ является вогнутой кусочно-линейной функцией, график которой состоит из $m+1$ линейных сегментов и полностью определяется своими значениями в следующих точках\textup{:}
  \begin{gather*}
    \H*{\infty}(k+\Co)/m) = \frac{1}{2} \left( (m - (k + \Co))(k + \Co) + \DCo\Co \right),\enskip
    k = \overline{0, m - 1},\\
    \H*{\infty}(0) = \H*{\infty}(1) = 0.
  \end{gather*}
\end{theorem}

В \emphasis{разделе 1.5} описана стратегия первого игрока, гарантирующая ему выигрыш не менее $\H*{\infty}(p)$ в игре $\theG*{\infty}(p)$.

Стратегию $\sigma$ первого игрока в $n$-шаговой игре можно представить как $(\sigmas{1}, \sigmara{i},\ i \in I)$, где $\sigmas{1}$ "--- ход первого игрока на первом шаге игры, а $\sigmara{i}$ "--- стратегия в игре продолжительности $n-1$, зависящая от ставки $i$ на первом шаге.
Аналогично, стратегию второго игрока можно представить как $(\taus{1}, \taura{i},\ i \in I)$.
Тогда для функции выигрыша справедливо следующее представление
\begin{equation}
  \label{ch1:eq:recursive-structure}
  \K*{n}(p,\sigmar,\taur) = 
  \K*{1}(p,\sigmas{1},\taus{1}) + \sum_{i \in I} \qc{i} \K*{n-1}(\pac{H}{i},\sigmara{i},\taura{i}).
\end{equation}
Отсюда получаем, что, определив одношаговую стратегию инсайдера для любого значения $p \in [0,1]$, можно рекурсивно продолжить ее применение на последующих шагах игры, тем самым определив стратегию в игре произвольной продолжительности.

Пусть на первом шаге игры первый игрок выбирает ход %
$\sigmas{1} = (\sigmas[H]{1}, \sigmas[L]{1})$, где %
$\sigmasc[s]{i}$ -- вероятность сделать ставку $i$ в состоянии $s \in S$.
%
Будем использовать эквивалентный способ задания хода.
Для этого определим следующие параметры: полные вероятности $\qc{i}$ использования действий $i$, а также апостериорные вероятности $\pac{s}{i}$ состояния $s$ при условии, что на предыдущем шаге первый игрок сделал ставку $i$.
Тогда вероятности $\sigmasc[s]{i}$ можно найти по формуле Байеса
$
  \sigmasc[s]{i} = \pac{s}{i}\qc{i}/\pc{s}.
$

Построим оптимальную стратегию инсайдера, определив его ход для всех значений вероятности $p$.
При $p$ равном $0$ или $1$ первый игрок применяет ставки $0$ и $m$ соответственно с вероятностью $1$.
При $p = k/m,\ k = \overline{1, m-1}$ первый игрок рандомизирует выбор ставок $k$ и $k+1$ с параметрами
\begin{equation*}
  \qc{k} = \Co,\ \pac{H}{k} = (k-1+\Co)/m,\
  \qc{k+1} = \DCo,\ \pac{H}{k + 1} = (k+\Co)/m.
\end{equation*}
При $p = (k+\Co)/m,\ k = \overline{0, m-1}$ он рандомизирует выбор ставок $k$ и $k+1$ с параметрами
\begin{equation*}
  \qc{k} = \DCo,\ \pac{H}{k} = k/m,\
  \qc{k+1} = \Co,\ \pac{H}{k+1} = (k+1)/m.
\end{equation*}
При $p = \lambda (k+\beta)/m + (1-\lambda) (k+1)/m,\ \lambda \in (0, 1)$ первый игрок рандомизирует выбор ставок $k, k+1, k+2$ с параметрами
\begin{align*}
  \qc{k} = \lambda\DCo, &\quad \pac{H}{k} = k/m,\\
  \qc{k+1} = \Co, &\quad \pac{H}{k+1} = \lambda (k+1)/m + (1-\lambda) (k+\Co)/m,\\
  \qc{k+2} = (1-\lambda)\DCo, &\quad \pac{H}{k+2} = (k+1+\Co)/m.
\end{align*}
Наконец, при $p = \lambda k/m + (1-\lambda) (k+\Co)/m,\ \lambda \in (0, 1)$ первый игрок рандомизирует выбор ставок $k$ и $k+1$ с параметрами
\begin{gather*}
  \qc{k} = \lambda\Co + (1-\lambda)(1-\Co),\enskip
  \pac{H}{k} = \frac{\lambda\Co}{\qc{k}} \frac{k-1+\Co}{m} + \frac{(1-\lambda)(1-\Co)}{\qc{k}} \frac{k}{m},\\
  \qc{k+1} = \lambda(1-\Co) + (1-\lambda)\Co,\enskip
  \pac{H}{k+1} = \frac{\lambda(1-\Co)}{\qc{k+1}} \frac{k+\Co}{m} + \frac{(1-\lambda)\Co}{\qc{k+1}} \frac{k+1}{m}.
\end{gather*}

Пусть при $\Co \in (0,1)$ стратегия $\sigma^*$ состоит в применении инсайдером описанных выше одношаговых стратегий для соответствующих значений апостериорной вероятности. 
При $\Co = 1$ стратегий инсайдера найдена в работе В.~К.~Доманского~(\seename~ссылку на стр.~\pageref{domansky07ref}).
При $\Co = 0$ стратегия может быть получена из соображений симметрии. 
Таким образом, стратегия $\sigma^*$ определена для всех значения $\Co \in [0,1]$.

Обозначим гарантированный выигрыш первого игрока в игре $\theG*{n}(p)$ при применении стратегии $\sigmar$ через
$
  \L*{n}(p, \sigmar) = \min_{\taur \in \Tau} \K*{n}(p,\sigmar,\taur).
$
В работе показано, что функции $\L*{\infty}(p, \sigmar^*)$ и $\H*{\infty}(p)$ совпадают при всех значениях $p \in [0,1],\ \Co \in [0,1]$.

Теоремы о значении игры $\theG*{\infty}(p)$ даны в \emphasis{разделе 1.6}.
\begin{theorem}
  Игра $\theG*{\infty}(p)$ имеет значение $\V*{\infty}(p) = \H*{\infty}(p) = \L*{\infty}(p)$.
  При этом $\sigmar^*$ -- оптимальная стратегия первого игрока\textup{,} а $\taur^*$ -- оптимальная стратегия второго игрока.
\end{theorem}

\begin{theorem}
  При любом значении $p \in [0,1]$, $\Co \in (0,1)$ и $m \geq 3$ справедливо неравенство
  \begin{equation*}
    \V*[\Co]{\infty}(p) \geq \V*[1]{\infty}(p) = \V*[0]{\infty}(p),
  \end{equation*}
  причем равенство достигается только при $p = k/m, k = \overline{0,m}$.
\end{theorem}

\emphasis{Раздел 1.7} посвящен анализу случайных блужданий апостериорных вероятностей $p^t$ состояния $H$, возникающих при применении игроками оптимальных стратегий $\sigmar^*$ и $\taur^*$.
Случайная величина
$
  \xi \eqdef \min \left\{ t \geq 0: p^t \in \{0, 1\} \right\}
$
соответствует моменту поглощения.
Пусть $\tau(p)$ --- средняя продолжительность игры при условии, что априорная вероятность равна $p$.

\begin{theorem}
  Если $p \in \{k_1/m, (k_2+\Co)/m,\ k_1 = \overline{0,m},\ k_2 = \overline{0,m-1}\},$ то ожидаемая продолжительность игры $\theG*{\infty}(p)$ выражается формулами
  \begin{equation*} 
    \tau\left( (k+\beta)/m \right) = \frac{(m-k-\Co)(k+\Co)}{\Co \DCo},\quad
    \tau\left( k/m \right) = \frac{k(m-k)}{\Co \DCo}.
  \end{equation*}
\end{theorem}

% * Вторая глава
\emphasis{Вторая глава} посвящена исследованию дискретной модели рынка со счетным множеством состояний.
В \emphasis{разделе 2.1} дается формальное описание соответствующей повторяющейся игры.

Пусть множество состояний $S = \Z_+$.
Перед началом игры случай выбирает состояние рынка $\s \in S$ в соответствии с вероятностным распределением $\pd = (\pc{s}, \; s \in S)$, имеющим конечную дисперсию состояния $\D \pd < \infty$.
Множество всех таких распределений обозначим $\MM$.

На каждом шаге игры $t = \overline{1,n}, \; n \leqslant \infty$, игроки делают ставки $i_t \in I, \, j_t \in J$, где $I = J = \Z_+$.
Выплата первому игроку в состоянии $s$ равна
\begin{equation*}
  \as(i_t, j_t) =
  \begin{cases}
    (1-\beta) i_t + \beta j_t - s, &\; i_t < j_t, \\
    0, &\; i_t = j_t, \\
    s - \beta i_t - (1-\beta)j_t, &\; i_t > j_t.
  \end{cases}
\end{equation*}
Ожидаемый выигрыш первого игрока обозначим при использовании игроками стратегий $\sigmar$ и $\taur$ равен
$
  \K{n}(\p, \sigmar, \taur) =
  \E_{(\p, \sigmar, \taur)} \sum_{t=1}^n \as(i_t, j_t).
$
Заданную таким образом игру обозначим $\theG{n}(\p)$.

В \emphasis{разделе 2.2} получена оценка сверху выигрыша первого игрока.

Следующие множества распределений зададим ограничениями на математическое ожидание состояния:
\begin{gather*}
  \Theta(x) = \left\{ \p \in \MM: \E \p = x \right\},\
  \Lambda(x, y) = \left\{ \p \in \MM: x < \E \p \leqslant y \right\}.
\end{gather*}

Пусть $\taur^*$ --- стратегия второго игрока, состоящая в применении $\tau^k$ при $\p \in \Lambda(k-1+\beta,k+\beta)$.
Отметим, что при заданном распределении $\p$ выбор $k$ зависит от значения $\beta$.

\begin{theorem}
  \label{ch2:upper-bound:theorem}
  При использовании вторым игроком стратегии $\taur^*$ выигрыш первого игрока в игре
  $\theG{\infty}(\p)$ ограничен сверху величиной
  \begin{equation*}
    \H{\infty}(\p) = \inf_{k \in J} \sum_{s \in S} \pc{s}  h^s_\infty(\taur^k).
  \end{equation*}
  Функция $\H{\infty}(\p)$ является кусочно-линейной вогнутой с областями линейности $\Lambda(k - 1 + \beta, k + \beta)$ и областями недифференцируемости $\Theta(k+\beta)$ при $k \in S$.
  Для распределений $\p$ с $\E \p = k - 1 + \beta + \eta, \; \eta \in (0, 1]$, ее значение равно
  \begin{equation}
    \label{ch2:upper-bound:eq:H(p)}
    \H{\infty}(\p) = \left( \D \p + \beta(1-\beta) - \eta(1-\eta) \right)/2.
  \end{equation}
\end{theorem}

В \emphasis{разделе 2.3} построена стратегия первого игрока, гарантирующая ему выигрыш не менее $\H{\infty}(\p)$.

Обозначим $\L{n}(\p, \sigmar)$ гарантированный выигрыш первого игрока, использующего стратегию $\sigmar$ в игре $\theG{n}(\p)$, т.е.
$
  \L{n}(\p, \sigmar) = \inf_{\taur \in \Tau} \K{n}(\p, \sigmar, \taur).
$

Обозначим $e^s$ вырожденное вероятностное распределение с носителем в точке $s$.
Пусть $\pd^x(l, r) \in \Theta(x)$ --- распределение с носителем $\{l, r\},\ l<r$.
При этом распределении вероятности реализации состояний $l$ и $r$ равны $(r-x)/(r-l)$ и $(x-l)/(r-l)$ соответственно, а дисперсия
$\D \pd^x(l, r) = (x - l)(r - x)$.

Способ построения оптимальной стратегии первого игрока основан на следующем представлении распределений $\pd = (\pc{s},\ s \in S) \in \Theta(x)$ в виде выпуклой комбинации распределений с двухточечными носителями:
\begin{gather}
  \label{ch2:lower-bound:eq:prob-decomp-sum}
  \pd = \begin{cases}
    \displaystyle
    \pc{x} e^x + \sum_{r=x+1}^\infty \sum_{l=0}^{x-1} \alpha_{l,r}(\pd) \pd^x(l, r),\ & x \in S,\\
    \displaystyle
    \sum_{r=\floor{x+1}}^\infty \sum_{l=0}^{\ceil{x-1}} \alpha_{l,r}(\pd) \pd^x(l, r),\ & x \notin S,\\
  \end{cases}\\
  \alpha_{l,r}(\pd) = (r-l) \pc{l} \pc{r} / \sum_{t=0}^{\ceil{x-1}} \pc{t} (x-t). \nonumber
\end{gather}
\begin{lemma}
  \label{ch2:lower-bound:lemma:convex-combination}
  Пусть $\pd_1, \pd_2 \in \MM$, $\sigmar^1, \sigmar^2 \in \Sigma$ --- стратегии первого игрока.
  Тогда для $\pd = \lambda \pd_1 + (1-\lambda) \pd_2,\ \lambda \in [0, 1],$ найдется такая стратегия $\sigmar^c \in \Sigma$, что
  \[
    \L{n}(\pd, \sigmar^c) \geqslant
    \lambda \L{n}(\pd_1, \sigmar^1) + (1-\lambda) \L{n}(\pd_2, \sigmar^2).
  \]
\end{lemma}

В диссертации показано, что для доказательства совпадения верхней и нижней оценок выигрыша в игре $\theG{\infty}(\pd)$ можно ограничиться рассмотрением только распределений %
$\pd = \pd^{k+\beta}(l, r) \in \Theta(k + \beta), \; k \in S,\ l = \overline{0, k},\ r = \overline{k+1, \infty}$.

Обозначим $\sigmak$ ход первого игрока, состоящий в выборе ставки из множества $\{k, k+1\}$.
Ход $\sigmak$ определяется заданием полных вероятностей действий $\qc{k}, \qc{k+1}$ и апостериорных распределений $\pad{k}, \pad{k+1}$, причем $\qc{k} + \qc{k+1} = 1$.

Определим стратегию $\sigmar^*$ первого игрока в игре $\theG{\infty}(\p)$.
Введем множество распределений
$
  P(l,r) = \left\{
    \pd^{k_1}(l, r), \, \pd^{k_2+\beta}(l, r), \, k_1 = \overline{l,r}, k_2 = \overline{l,r-1}
  \right\}.
$
При $\p \in P(l,r)$ первый ход $\sigmas[*]{1}$ стратегии $\sigmar^*$ определяется следующим образом.
Если $\p = \p^l(l,r)$ или $\p = \p^r(l,r)$, то первый игрок использует ставки $l$ и $r$, соответственно, с вероятностью 1.
В противном случае он использует $\sigmak$ с параметрами из таблицы~\ref{ch2:tab:insider-strategy}.

\begin{table}[htb]
  \centering
  \renewcommand{\arraystretch}{1.5}
  \captionsetup{width=12cm}
  \caption{Параметры хода $\sigmas[*]{1}$ при $\p \in P(l, r)$}
  \label{ch2:tab:insider-strategy}
  \begin{tabular}{|P{2cm}||P{2cm}|P{2cm}|P{2cm}|P{2cm}|}
    \hline
    \hline
    $\pd$         & $\qc{k}$ & $\qc{k+1}$ & $\p^{k}$ & $\pc{k+1}$ \\ \hline
    $\pd^k(l, r)$ & $\beta$  & $1-\beta$  & $\pd^{k-1+\beta}(l, r)$ & $\pd^{k+\beta}(l, r)$ \\ \hline
    $\pd^{k+\beta}(l, r)$                                                   & $1-\beta$ & $\beta$ & $\pd^k(l, r)$ & $\pd^{k+1}(l, r)$     \\
    \hline
    \hline
    \multicolumn{1}{c}{}
    \vspace{-2.5em}
  \end{tabular}
\end{table}

На последующих шагах игры ход $\sigmas[*]{1}$ применяется рекурсивно для соответствующих значений апостериорных вероятностей.
В результате определили стратегию $\sigmar^*$ для распределения $\p \in P(l,r)$.

Для произвольного распределения $\pd \in \Theta(k),\ k \in S$, стратегию $\sigmar^*$ определим следующим образом.
Если реализуется состояние $s = k$, то гарантированный выигрыш первого игрока не превышает $0$ и он прекращает игру.
Таким образом, первый игрок, следуя стратегии $\sigmar^*$, прекращает игру с вероятностью $p^k$.
В противном случае игрок использует конструкцию леммы~\ref{ch2:lower-bound:lemma:convex-combination} для построения стратегии, соответствующей выпуклой комбинации распределений $\pd^k(l, r)$ в разложении $\p$.
Первый ход такой стратегии использует две ставки $k$ и $k+1$ с полными вероятностями $(1-\pc{k})\beta$ и $(1-\pc{k})(1-\beta)$ соответственно.
Апостериорные вероятностные распределения являются выпуклыми комбинациями соответствующих апостериорных двухточечных распределений и даются следующими формулами:
\begin{gather*}
  \pad{k} = \frac{1}{1-\pc{k}} \sum_{r=k+1}^\infty \sum_{l=0}^{k-1} \alpha_{l,r}(\pd) \pd^{k-1+\beta}(l, r), \\
  \pad{k+1} = \frac{1}{1-\pc{k}} \sum_{r=k+1}^\infty \sum_{l=0}^{k-1} \alpha_{l,r}(\pd) \pd^{k+\beta}(l, r).
\end{gather*}
Аналогичные рассуждения справедливы и для распределений $\pd \in \Theta(k+\beta) \cup \Lambda(k, k+\beta),\ k \in S$.

В \emphasis{разделе 2.4} дана теорема о значении игры $\theG{\infty}(\pd)$.
\begin{theorem}
  \label{ch2:solution:theorem}
  При любом распределении $\pd \in \MM$ игра $\theG{\infty}(\pd)$ имеет значение
  $
    \V{\infty}(\pd) = \H{\infty}(\pd) = \L{\infty}(\pd),
  $
  а $\sigmar^*$ и $\taur^*$ "--- оптимальные стратегии игроков.
\end{theorem}

В \emphasis{разделе 2.5} приведена вторая оптимальная стратегия инсайдера $\xi^*$.
Введем множество распределений %
\begin{equation*}
  P'(l,r) =
  \{\pd^l(l, r), \pd^r(l, r)\}
  \cup
  \left\{
    \pd^{k+\beta}(l, r), \, k = \overline{l, r-1}
  \right\}.
\end{equation*}
При $\p \in P'(l,r)$ первый ход $\xi^*_1$ стратегии $\xiv^*$ определяется следующим образом.
Если $\pd = \pd^l(l,r)$ или $\pd = \pd^r(l,r)$, то первый игрок использует ставки $l$ и $r$ соответственно с вероятностью 1.
В противном случае он использует $\sigmak$ с параметрами из таблицы~\ref{ch2:tab:insider-strategy2}.
\begin{table}[htb]
  \centering
  \renewcommand{\arraystretch}{1.5}
  \captionsetup{width=12cm}
  \caption{Параметры хода $\xi^*_1$ при $\pd \in P'(l, r)$}
  \label{ch2:tab:insider-strategy2}
  \begin{tabular}{|P{2cm}||P{2cm}|P{2cm}|P{2cm}|P{2cm}|}
    \hline
    \hline
    $\pd$                   & $\qc{k}$ & $\qc{k+1}$                 & $\pad{k}$                & $\pad{k+1}$                                      \\
    \hline
    $\pd^{l+\beta}(l, r)$           & $\frac{1}{1+\beta}$       & $\frac{\beta}{1+\beta}$ & $\pd^l(l, r)$           & $\pd^{l+1+\beta}(l, r)$ \\
    \hline
    $\pd^{r-1+\beta}(l, r)$         & $\frac{1-\beta}{2-\beta}$ & $\frac{1}{2-\beta}$     & $\pd^{r-2+\beta}(l, r)$ & $\pd^r(l, r)$           \\
    \hline
    $\pd^{k+\beta}(l, r)$   & $\frac{1}{2}$             & $\frac{1}{2}$           & $\pd^{k-1+\beta}(l, r)$ & $\pd^{k+1+\beta}(l, r)$  \\
    \hline
    \hline
    \multicolumn{1}{c}{}
    \vspace{-2.5em}
  \end{tabular}
\end{table}

Для остальных распределений $\pd$ стратегия $\xi^*$ определяется аналогично тому, как это было сделано для стратегии $\sigmar^*$.

Из таблицы~\ref{ch2:tab:insider-strategy2} видно, что при $\p \in P'(l, r)$ использование первым игроком стратегии $\xi^*$ порождает случайное блуждание последовательности апостериорных вероятностей существенно отличное от случайного блуждания, порождаемого при использовании $\sigmar^*$.
Данное случайное блуждание симметрично с вероятностями перехода в соседние состояния равными $1/2$, симметрия нарушается только в крайних и соседних к ним состояниях.

% * Третья глава
\emphasis{Третья глава} посвящена исследованию теоретико-игровой модели биржевых торгов с непрерывными ставками и двумя состояниями. 

В \emphasis{разделе 3.1} дано описание соответствующей модели.
Как и в главе~1, множество возможных состояний рынка $S = \{H, L\}$.
На каждом шаге торгов первый игрок делает ставку из множества $I = [0, 1]$, второй игрок "--- ставку из множества $J = [0, 1]$.

Обозначим через $\Port{t} = (\Port{t}^R, \Port{t}^N)$ портфель первого игрока на $t$-м шаге торгов, где $\Port{t}^R$ и $\Port{t}^N$ "--- количество единиц рискового и безрискового активов соответственно.
Если на $t$-м шаге игроки делают ставки $x \in I,\ y \in J$, то портфель 
$
\Port{t} = \Port{t-1} + \vartheta(x, y),
$
где
\begin{equation}\label{ch3:eq:trans-mech}
  \vartheta(x, y) = \Ind{x > y} (1, -(\Co x + \DCo y)) +
  \Ind{x < y} (-1, \DCo x + \Co y).
\end{equation}
Таким образом, одна акция продается по цене, равной выпуклой комбинации предложенных ставок с заданным коэффициентом $\Co$.
Стоимость портфеля при этом равна
$
  V(\Port{t}) \eqdef \Ind{s = H} \, \Port{t}^R + \Port{t}^N.
$
Цель игроков состоит в максимизации прибыли, полученной от торгов.
Прибыль первого игрока после завершения сделок будет равна $V(\Port{n})$, а второго $-V(\Port{n})$.

В \emphasis{разделе 3.2} рассмотрены теоретико-игровые постановки основной задачи и двойственной к ней в смысле Де~Мейера, которые мы будем называть прямой и двойственной играми соответственно.
Как отмечено в работе Де~Мейера и Салей~(\seename~ссылку на стр.~\pageref{demeyer02ref}), прямая (двойственная) игра больше подходит для построения оптимальной стратегии первого (второго) игрока.

В \emphasis{подразделе 3.2.1} дается определение прямой игры.
Стратегии $\sigma,\ \tau$ игроков, а также множества стратегий $\Sigma_n, \Tau_n$ в $n$-шаговой игре определяются аналогично тому, как это было сделано в главе~1.
Пара стратегий $(\sigma, \tau)$ вместе с ходом случая индуцирует на $S \times H_n$ вероятностное распределение $\Pi[p, \sigma, \tau]$.
Тогда выигрыш первого игрока равен
$
  g^\Co_n(p, \sigma, \tau) = \E_{( p, \sigma, \tau )} V(\Port{n}).
$
Выигрыш второго игрока при этом равен $-g^\Co_n(p, \sigma, \tau)$.
Полученную игру обозначим через $G^\Co_n(p)$, а ее нижнее и верхнее значения --- через $\LV[\Co]{n}(p)$ и $\HV[\Co]{n}(p)$ соответственно.
В том случае, когда $\LV[\Co]{n}(p) = \HV[\Co]{n}(p) = V^\Co_n(p)$, игра имеет значение $V^\Co_n(p)$.
Положим при этом, что $V^\Co_0(p) \equiv 0$.
В дальнейшем верхний индекс $\Co$ мы будем часто опускать.

Рассмотрим стратегию $\sigma$ первого игрока как пару $(\sigma_1, \tilde{\sigma})$, где $\sigma_1$ -- ход игрока на первом шаге игры, а $\tilde{\sigma}$ -- стратегия в игре продолжительности $n$, зависящая от ставок $(x, y)$ на первом шаге.
Аналогично, стратегию $\tau$ второго игрока можно представить как пару $(\tau_1, \tilde{\tau})$.
Случайные величины ставок, имеющих распределения $\sigma_1$ и $\tau_1$, обозначим через $X$ и $Y$ соответственно.

Пара $(\sigma_1, \tau_1)$ вместе с ходом случая индуцирует вероятностное распределение $\Pi[p, \sigma_1, \tau_1]$ на $S \times I \times J$.
Обозначим через
$
  p(x) = \Pi[p, \sigma_1](s = H\ |\ X = x)
$
апостериорную вероятность состояния $H$ при условии, что первый игрок сделал ставку $x$.
Отметим, что апостериорная вероятность не зависит от ставки второго игрока $y$, так как она не зависит от $s$.
Тогда для значения выигрыша первого игрока справедливо представление
\begin{align*}
  g_{n+1}(p, \sigma, \tau) 
  &= 
    g_1(p, \sigma_1, \tau_1) +
    \E_{( p, \sigma_1, \tau_1 )}
    g_n(p(X), \tilde{\sigma}(X, Y), \tilde{\tau}(X, Y)).
\end{align*}

Отсюда видно, что определив одношаговую стратегию для любого значения $p \in [0, 1]$, можно рекурсивно продолжить ее применение на последующих шагах игры.
В силу того, что игра с $p \in \{0, 1\}$ имеет тривиальное решение, дальнейшие построения будут проведены для значений $p \in (0, 1)$.

В \emphasis{подразделе 3.2.2} определяется двойственная игра следующим образом.
Перед началом игры первый игрок выбирает текущее состояние $s \in S$.
Второй игрок не осведомлен о выборе первого.
Если $s = H$, то первый вынужден заплатить второму штраф $z$ в конце игры.
В остальном правила двойственной игры $G^*_n(z)$ аналогичны правилам игры $G_n(p)$.

Стратегией первого игрока в двойственной игре является пара $\dualFPS$, где $p \in [0, 1]$, $\sigma \in \Sigma_n$.
Множество стратегий второго игрока совпадает с $\Tau_n$.

Выигрыш второго игрока, который он стремится максимизировать, определяется как
$
  \dualg = z p - g_n(p, \sigma, \tau).
$
Верхнее и нижнее значения игры обозначим через $\HW{n}(z)$ и $\LW{n}(z)$ соответственно.
В том случае, когда $\HW{n}(z) = \LW{n}(z) = W_n(z)$, игра имеет значение $W_n(z)$.
При этом $W_0(z) = \min(z, 0)$.

В \emphasis{разделе 3.3} получено решение одношаговой игры $G^\Co_1(p)$.
Найденные в диссертации оптимальные стратегии игроков зависят от $\Co$.
В то же время значение игры $V^\Co_1(p) = p(1-p)$ от $\Co$ не зависит.

В \emphasis{разделе 3.4} найдены оценки выигрыша первого и второго игроков в прямой и двойственной играх.

Пусть $a(v)$ "--- вогнутая функция, определенная на прямой, причем $a$ может принимать значение $-\infty$.
Функцией, сопряженной к $a$ в смысле Фенхеля, называется
\begin{equation*}
  a^*(u) = \inf_{v \in \R} \left( u v - a(v) \right).
\end{equation*}

Непрерывная дифференцируемость функций $\LV{n}(p)$, $\LV[*]{n}(z)$ и $\LW{n}(z)$ доказана в разделе~3.5.

Получению оценки нижнего значения игры $G_n(p)$ посвящен \emphasis{подраздел 3.4.1}.
Как показано в базовой работе Де~Мейера и Салей, одношаговую стратегию $\sigma_1$ первого игрока в игре $G_n(p)$, можно параметризовать функциями $f$ и $Q$, удовлетворяющими следующим свойствам:
\begin{subequations}
  \begin{flalign}
    \label{ch3:eq:parametr-prop:f-incr}
    &\bullet\quad f: [0, 1] \rightarrow [0, 1],\ \forall u_1, u_2 \in [0, 1]: u_1 < u_2 \implies f(u_1) \leqslant f(u_2); &\\
    \label{ch3:eq:parametr-prop:int-q=p}
    &\bullet\quad \int_0^1 Q(u) \di u = p;\ Q(u) \geqslant 0,\ u \in [0, 1];&\\
    \label{ch3:eq:parametr-prop:f-Q-eq}
    &\bullet\quad \forall u_1, u_2 \in [0, 1]: f(u_1) = f(u_2) \implies Q(u_1) = Q(u_2).&
  \end{flalign}
\end{subequations}
Пусть $\mu = \Pi[p, \sigma_1]$.
Так как для любого $B \in \Borel(I)$ выполнено
\begin{equation*}
  \mu(X \in B \; | \; s = H) = \int_0^1 \Ind{f(u) \in B} \frac{Q(u)}{p} \di u,
\end{equation*}
то восстановить $\sigma_1$ по $(f, Q)$ можно следующим образом.
Если ходом случая было выбрано состояние $H$, то инсайдер выбирает $u \in [0, 1]$ как реализацию случайной величины с плотностью вероятности $Q(u)/p$ и делает ставку $x = f(u)$.
Аналогично, в состоянии $L$ он выбирает $u$ как реализацию случайной величины с плотностью вероятности $(1 - Q(u))/(1 - p)$ и делает ставку $x = f(u)$.

Следуя схеме из работы Де~Мейера и Салей, в диссертации найдены следующие функции: 
\begin{equation}
  \label{ch3:eq:f}
  f(u) = (u - \DCo)^{-2} \int_{\DCo}^u 2(v-\DCo) Q(v) \di v,\footnotemark
  \footnotetext{
    При $u = \DCo$ функция $f(u)$ доопределяется по правилу Лопиталя как $Q(\DCo)$.
  }
\end{equation}%
\begin{equation}
  \label{ch3:eq:Q(u)}
  Q(u) = \LV[*\prime]{n}(1+\lambda-2u),
\end{equation}
где $\lambda$ находится из уравнения
$
  \int_0^1 \LV[*\prime]{n}(1+\lambda-2u) \di u = p.
$
\begin{lemma}
  \label{ch3:lem:f-Q-is-strategy}
  Функции $f$ и $Q$\textnormal{,} определенные в~\eqref{ch3:eq:f} и \eqref{ch3:eq:Q(u)}\textnormal{,} принимают значения в $[0, 1]$ и удовлетворяют условиям~\eqref{ch3:eq:parametr-prop:f-incr} "--- \eqref{ch3:eq:parametr-prop:f-Q-eq}\textnormal{,} т.е. параметризуют некоторую стратегию $\sigma_1$ первого игрока.
\end{lemma}

Показано, что определенные выше $f$ и $Q$ параметризуют стратегию первого игрока, выравнивающую его выигрыш при применении вторым игроком ставки $y \in [f(0), f(1)]$ и дающую выигрыш не меньше при $y \in [0, 1] \setminus [f(0), f(1)]$.

\begin{theorem}\label{ch3:thm:V-bound}
  При любом $p \in [0, 1]$ для нижнего значения игры $G_{n+1}(p)$ справедлива оценка $\LV{n+1}(p) \geqslant K^*(p)$, где
  \begin{equation*}
    K(\lambda) = \int_0^1 \LV[*]{n}(1+\lambda-2u) \di u.
  \end{equation*}
\end{theorem}

В \emphasis{подразделе 3.4.2} получена оценка для нижнего значения игры $G^*_n(z)$.
Аналогично тому, как это было сделано для первого игрока, параметризуем $\tau_1$ при помощи неубывающей функции $h: [0, 1] \rightarrow [0, 1]$.

Пусть
\begin{equation}\label{ch3:eq:h(u)}
  h(u) = 2(u - \DCo)^{-2} \int_\DCo^u (v - \DCo) \LW[\prime]{n}(z - 2v + 1) \di v.\footnotemark
  \footnotetext{При $u = \DCo$ функция $h(u)$ доопределяется по правилу Лопиталя как $\LW[\prime]{n}(z - 2\DCo + 1)$.}
\end{equation}

\begin{lemma}\label{ch3:lem:h(u)-props}
  Функция $h,$ определенная в~\eqref{ch3:eq:h(u)}$,$ обладает следующими свойствами$:$
  \begin{itemize}
  \item[$\bullet$] 
    $h: [0, 1] \rightarrow [0, 1],\ \forall u_1, u_2 \in [0, 1]: u_1 < u_2 \implies h(u_1) \leq h(u_2);$ 
  \item[$\bullet$] 
  $h(u_1) = h(u_2) \implies h(u_1) = \LW[\prime]{n}(z - 2u_1 + 1) = \LW[\prime]{n}(z - 2u_2 + 1)$.
  \end{itemize}
  В частности$,$ функция $h$ может служить параметризацией некоторого распределения $\tau_1$.
\end{lemma}

В диссертации показано, что стратегия второго игрока $\tau_1$, соответствующая $h$, выравнивает его выигрыш при применении первым игроком ставки $x \in [h(0), h(1)]$ и дает не меньший выигрыш при $x \in [0, 1] \setminus [h(0), h(1)]$.

\begin{theorem}\label{ch3:thm:W-bound}
  Для нижнего значения игры $G_{n+1}^*(z)$ справедлива оценка
  \begin{equation*}
    \LW{n+1}(z) \geqslant \int_0^1 \LW{n}(z - 2v + 1) \di v.
  \end{equation*}
\end{theorem}

В \emphasis{разделе 3.5} даны утверждения о значении прямой и двойственной игр, о динамике игрового взаимодействия между игроками, а также приведен алгоритм численного построения оптимальных стратегий игроков в $n$-шаговой игре.

Поскольку выражения для нижних оценок в теоремах~\ref{ch3:thm:V-bound} и~\ref{ch3:thm:W-bound} совпадают с аналогичными выражениями в работе Де~Мейера, Салей, справедливы все двойственные соотношения между $\LV{n}(p)$ и $\LW{n}(z)$, а также утверждения относительно оптимальности стратегий.

\begin{theorem}
  Для всех $z \in \mathbb{R}$ выполнено
  \begin{equation}\label{ch3:eq:duality-relationships}
    \LV[*]{n}(z) = \HW{n}(z) = \HV[*]{n}(z) = \LW{n}(z).
  \end{equation}
  Таким образом, игры $G_n(p)$ и $G_n^*(z)$ имеют значения $V_n(p)$ и $W_n(z)$ соответственно.
  Кроме того,
  \begin{equation}\label{ch3:eq:W-recursive}
    W_{n+1}(z) = \int_0^1 W_n(z - 2u + 1) \di u.
  \end{equation}
\end{theorem}

\begin{theorem}\label{ch3:thm:optimal-strategies}
  Стратегии $\sigma^0$ и $\tau^0$ являются оптимальными в игре $G_n(p)$ тогда и только тогда, когда стратегии $(p, \sigma^0),$ $\tau^0$ являются оптимальными при $z = V_n'(p)$ в игре $G_n^*(z)$.
\end{theorem}

\begin{corollary}
  \label{ch3:cor:value-indep-beta}
  Значения игр $G^\Co_n(p)$ и $G^{\Co*}_n(z)$ не зависят от коэффициента $\Co$.
\end{corollary}

Динамика игрового взаимодействия также совпадает с таковой в работе Де~Мейера, Салей.

\noindent
\textbf{Алгоритм построения оптимальных стратегий в игре $\mathbf{G_n(p)}$}.
В силу рекурсивной структуры игры $G_n(p)$ достаточно описать способ получения оптимальных действий игроков на первом шаге игры при заданном значении $p$.
\begin{enumerate}
\item
  Находим $\lambda$ как решение уравнения 
  $
    p = W'_n(\lambda).
  $
  Производная $W'_n(\cdot)$ является кусочно-полиномиальной функцией $n$-го порядка.
  Следовательно, ее корни могут быть найдены численно с любой заданной точностью.
\item
  Согласно~\eqref{ch3:eq:Q(u)} и~\eqref{ch3:eq:duality-relationships} находим функцию 
  $
    Q(u) = W'_{n-1}(\lambda + 1 - 2u).
  $
  В силу сказанного выше функция $Q(u)$ является кусочно-полиномиальной порядка $n-1$.
\item
  Выбираем $u_1$ как реализацию случайной величины $U_1$, распределенной на $[0, 1]$ с плотностью вероятности $Q(u)/p$ в состоянии $H$ и $\left(1 - Q(u)\right)/(1-p)$ в состоянии $L$.
\item
  Согласно~\eqref{ch3:eq:f} находим 
  $
    x = f(u_1) = (u_1 - \DCo)^{-2} \int_\DCo^{u_1} 2 (v - \DCo) Q(v) \di v.
  $
  Так как для расчета оптимальной ставки $x$ необходимо знать значение $f(u)$ лишь в одной точке $u$, оно может быть эффективно найдено численно.
\item
  Находим $u_2$ как реализацию случайной величины $U_2$, распределенной равномерно на $[0, 1]$
\item
  Из~\eqref{ch3:eq:h(u)} и теоремы~\ref{ch3:thm:optimal-strategies} следует, что выражения для $h$ и $f$ совпадают.
  Таким образом, оптимальная ставка второго игрока $y = h(u_2) = f(u_2)$.
\item
  Если $n = 1$, игра заканчивается после объявления ставок. В противном случае игроки переходят к игре $G_{n-1}(p^1)$, где $p^1 = Q(u_1)$.
\end{enumerate}

В \emphasis{разделе 3.6} даны примеры аналитического нахождения оптимальных $f$ и $Q$ в одношаговой и двухшаговой играх.

Перспективы дальнейших исследований включают рассмотрение моделей более приближенных к условиям реального рынка.

% % * Conclusion
% В \emphasis{заключении} приведены основные результаты работы, которые заключаются в следующем:
% \input{common/concl}

%\newpage
% При использовании пакета \verb!biblatex! список публикаций автора по теме
% диссертации формируется в разделе <<\publications>>\ файла
% \verb!../common/characteristic.tex!  при помощи команды \verb!\nocite! 

\ifdefmacro{\microtypesetup}{\microtypesetup{protrusion=false}}{} % не рекомендуется применять пакет микротипографики к автоматически генерируемому списку литературы
\ifnumequal{\value{bibliosel}}{0}{% Встроенная реализация с загрузкой файла через движок bibtex8
  \renewcommand{\refname}{\large \authorbibtitle}
  \nocite{*}
  \insertbiblioauthor                          % Подключаем Bib-базы
  %\insertbiblioother   % !!! bibtex не умеет работать с несколькими библиографиями !!!
}{% Реализация пакетом biblatex через движок biber
  \insertbiblioauthor                          % Подключаем Bib-базы
  % \insertbiblioother
}
\ifdefmacro{\microtypesetup}{\microtypesetup{protrusion=true}}{}


%%% Local variables:
%%% mode: latex
%%% TeX-master: "../synopsis"
%%% End:
