
\section*{Общая характеристика работы}

\newcommand{\emphasis}[1]{\textbf{{#1}}}
\newcommand{\actuality}{\emphasis{\actualityTXT}}
\newcommand{\progress}{\emphasis{\progressTXT}}
\newcommand{\aim}{\emphasis{\aimTXT}}
\newcommand{\tasks}{\emphasis{\tasksTXT}}
\newcommand{\researchsubject}{\emphasis{\researchsubjectTXT}}
\newcommand{\novelty}{\emphasis{\noveltyTXT}}
\newcommand{\influence}{\emphasis{\influenceTXT}}
\newcommand{\methods}{\emphasis{\methodsTXT}}
\newcommand{\defpositions}{\emphasis{\defpositionsTXT}}
\newcommand{\reliability}{\emphasis{\reliabilityTXT}}
\newcommand{\probation}{\emphasis{\probationTXT}}
\newcommand{\contribution}{\emphasis{\contributionTXT}}
\newcommand{\publications}{\emphasis{\publicationsTXT}}

\input{common/characteristic} % Характеристика работы по структуре во введении и в автореферате не отличается (ГОСТ Р 7.0.11, пункты 5.3.1 и 9.2.1), потому её загружаем из одного и того же внешнего файла, предварительно задав форму выделения некоторым параметрам

%Диссертационная работа была выполнена при поддержке грантов ...

\emphasis{Объем и структура работы.}
Диссертация состоит из~введения, трех глав и заключения.
Полный объем диссертации составляет \todo{\textbf{ХХХ}}~страниц текста с~\todo{\textbf{ХХ}}~рисунками и~\todo{XXX}~таблицами.
Список литературы содержит \todo{\textbf{ХХX}}~наименование.

%\newpage
\section*{Содержание работы}
Во \emphasis{введении} обосновывается актуальность исследований, проводимых в рамках данной диссертационной работы, приводится обзор научной литературы по изучаемой проблеме, формулируется цель, ставятся задачи работы, сформулированы научная новизна, теоретическая и практическая значимость представляемой работы, а также результаты, выносимые на защиту.

% * Chapter 1
\emphasis{Первая глава} посвящена исследованию теоретико-игровой модели биржевых торгов с дискретными ставками и двумя состояниями.

% ** Основные понятия и введение в тему
В \emphasis{разделе 1.1} диссертации дано введение в теорию повторяющихся игр с неполной информацией, определены основные термины и понятия.

Рассмотрим антагонистическую игру двух лиц, которая повторяется $n$ раз, где $n\leq \infty$.
Будем считать, что первый игрок знает функцию выигрыша в данной игре, в то время как второй игрок такой информацией не обладает.
Однако второй игрок знает, что настоящая функция выигрыша является одной из $\kappa$ возможных альтернатив.
Каждой такой альтернативе второй игрок приписывает некоторую вероятность того, что данная функция выигрыша является истинной функцией выигрыша в рассматриваемой
игре.
Таким образом, априорные убеждения второго игрока задаются вероятностным вектором
\[
  \pd = (\pc{1}, \pc{2}, \ldots, \pc{\kappa}),\quad \sum_{i=1}^\kappa \pc{i} = 1.
\]

С данными функциями выигрыша можно связать игры $G_1, G_2, \ldots, G_\kappa$.
В дальнейшем мы будем считать, что информационная неопределенность второго игрока заключается именно в том, что он не знает какая из игр $G_1, G_2, \ldots, G_\kappa$ разыгрывается.

На каждом шаге игры первый игрок может совершать действия из множества $I$, второй игрок --- действия из множества $J$, при этом мы считаем, что множества действий одного игрока известно другому.
Кроме того, положим, что второй игрок знает, что первый обладает точной информацией о том, какая именно игра разыгрывается, а первый игрок знает априорные убеждения второго.

Игры $G_1, G_2, \ldots, G_\kappa$ будем называть \emph{одношаговыми играми}.
Все одношаговые игры описываются матрицами размера $|I| \times |J|$, где элементы матрицы задают выплаты первому игроку.
Мы предполагаем, что оба игрока точно знают платежные матрицы игр $G_1, G_2, \ldots, G_\kappa$.
На каждом шаге игры первый игрок выбирает номер строки, и одновременно с ним второй игрок выбирает номер столбца.
В конце каждого хода действия игроков оглашаются, и элемент из матрицы, отвечающей настоящей игре, прибавляется к выигрышу первого игрока и вычитается из выигрыша второго.
Таким образом, первый игрок знает свой выигрыш на каждом этапе игры, в то время как второй может лишь рассчитать свой ожидаемый выигрыш.
В завершение, мы считаем, что данное описание известно обоим игрокам.

Данная игра с неполной информацией описывается в виде игры в нормальной форме следующим образом.
Обозначим через $S = \{1, 2, \ldots, \kappa\}$ множество возможных альтернатив или \emph{состояний природы}.
Перед началом игры ходом случая в соответствии с вероятностным распределением $\pd$ выбирается состояние $s \in S$.
Далее на протяжении $n$ шагов разыгрывается игра $G_s$.
Первый игрок информирован о результате хода случая, второй игрок "--- нет.
В остальном правила данной игры совпадают с описанными выше.

Пусть $h_t = \left((i_1, j_1), (i_2, j_2), \ldots, (i_t, j_t)\right)$ "--- история ставок игроков после завершения шага $t$.
Множество все таких $h_t$ обозначим через $H_t$. 

Обозначим через $\Delta(X)$ совокупность всех вероятностных распределений на множестве $X$.

Стратегией первого игрока в такой игре является последовательность ходов (отображений) $\sigmar = (\sigmas{1}, \sigmas{2}, \ldots, \sigmas{n})$, где $\sigmas{t} = (\sigmas[1]{t}, \sigmas[2]{t}, \ldots, \sigmas[\kappa]{t})$, и $\sigmas[s]{t}: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от предыдущих ходов, которую первый игрок использует если ходом случая реализовалось состояние $s$.

Аналогичным образом определим стратегию второго игрока как последовательность ходов (отображений) $\taur = (\taus{1}, \taus{2}, \ldots, \taus{n})$, где $\taus{t}: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от предыдущих ходов.
Как видно, ход второго игрока на каждом шаге игры зависит только от предыдущих ходов, и не зависит от состояния, в силу того, что второй игрок не информирован о результате хода случая.

Отметим, что, как показано в монографии Аумана, Машлера~\cite{aumann95}, достаточно рассматривать только стратегии, которые зависят лишь от предыдущих ходов первого игрока и не зависят от ходов второго.
%
Также нужно отметить, что в данной работе рассмотрены игры, в которых выигрыш равен суммарным выплатам, в отличие от постановки из \cite{aumann95}, в которых рассматривались игры с усредненными выплатами.

% ** Описание дискретной модели
В \emphasis{разделе 1.2} приводится описание дискретной модели биржевых торгов.
Следуя работе~\cite{domansky07}, рассматривается упрощенная модель финансового рынка, на котором два игрока ведут торговлю однотипными акциями на протяжении $n \leqslant \infty$ шагов.

Перед началом торгов случайный ход определяет цену акции на весь период торгов, которая может быть либо $m \in \N$ с вероятностью $p$, либо $0$ с вероятностью $1-p$.
Таким образом определенный ход случая является упрощенным аналогом некоторого шокового события на финансовом рынке (такого, как, например, публикация отчетов о доходах некоторой компании).
Выбранная цена сообщается первому игроку и не сообщается второму, при этом второй игрок знает, что первый "--- инсайдер.

Рассмотрим $t$-й шаг торгов, где $t = \overline{1,n}$.
На данном шаге первый игрок выбирает ставку $i_t \in I = \{0, 1, \ldots, m\}$, а второй --- ставку $j_t \in J = \{0, 1, \ldots, m\}$.
Игрок, предложивший б\'{о}льшую ставку, покупает у другого акцию по цене равной
\[
  \Co \max(i_t, j_t) + \DCo \min(i_t, j_t),\ \text{где } %
  \Co \in (0, 1),\ \DCo = 1 - \Co.
\]
Если ставки равны, то сделка на $t$-м шаге не состоится.
Коэффициент $\Co$ можно интерпретировать как \emph{переговорную силу продавца}: чем ближе значение к $1$, тем большую сумму получит продавец акции в результате сделки.

Считаем, что игроки обладают неограниченными запасами рисковых и безрисковых активов, т.е. торги не могут прекратиться по причине того, что у одного из игроков закончатся деньги или акции.
Цель игроков состоит в максимизации стоимости итогового портфеля, состоящего из некоторого числа купленных акций и суммы денег, полученных в результате торгов.
Таким образом, не ограничивая общности, можно положить, что в начальный момент времени оба игрока имеют нулевые портфели.

% ** Определение игры G^m_n(p)

В \emphasis{разделе 1.3} формально определяется повторяющаяся игра с неполной информацией, отвечающая данному выше описанию.

Пусть множество состояний рынка $S = \{L, H\}$.
Перед началом игры случай выбирает $s \in S $ с вероятностями $P(s=H) = p$ и $P(s=L) = 1 - p$.
После этого на протяжении $n \leq \infty$ шагов игроки участвуют в игре с матрицей $A^{s,\Co}$, где элементы матрица заданы следующим образом:
\begin{equation*}
  \as[L](i, j) = \begin{cases}
    \DCo i + \Co j, &\, i < j, \\
    0, &\, i = j, \\
    -\Co i - \DCo j, &\, i > j,
  \end{cases}
  \qquad
  \as[H](i, j) = \begin{cases}
    \DCo i + \Co j - m, &\, i < j, \\
    0, &\, i = j, \\
    m - \Co i - \DCo j, &\, i > j.
  \end{cases}
\end{equation*}

На шаге $t$ обоим игрокам достаточно принимать в расчет лишь последовательность $(i_1, i_2, \ldots, i_{t-1})$ действий первого игрока на предыдущих ходах.
Это связано с тем, что информация, получаемая вторым игроком относительно состояния $s$, может передаваться лишь посредством действий первого игрока.

Стратегией первого игрока в данной игре является последовательность ходов (отображений) 
$\sigmar = (\sigmas{1}, \sigmas{2}, \ldots, \sigmas{t}, \ldots)$, где 
$\sigmas{t}: S \times I^{t-1} \rightarrow \Delta(I)$.
Таким образом, на каждом шаге торгов первый игрок рандомизирует выбор ставки в зависимости от состояния и предыдущих ставок.
Как и в работе~\cite{domansky07}, мы ограничимся рассмотрением только тех стратегий $\sigmar$, которые гарантируют первому игроку на каждом шаге игры неотрицательный выигрыш.
Множество таких стратегий первого игрока обозначим через $\Sigma$.

Аналогично стратегией второго игрока назовем последовательность ходов (отображений) 
$\taur = (\taus{1}, \taus{2}, \ldots, \taus{t}, \ldots),$ где 
$\taus{t}: I^{t-1} \rightarrow \Delta(J)$.
Не имея информации о настоящем состоянии, второй игрок при выборе ставки опирается только на историю ставок инсайдера.
Множество стратегий второго игрока обозначим через $\Tau$.

Обозначим через $\E_{(p,\sigmar,\taur)}$ математическое ожидание по мере, индуцированной на $S \times I^n \times J^n$ ходом случая и смешанными стратегиями $\sigmar$ и $\taur$ игроков.
%%%%%%%%%
При применении первым игроком смешанной стратегии $\sigmar$, а вторым игроком "--- смешанной стратегии $\taur$, ожидаемый выигрыш первого игрока
\begin{equation}
  \label{ch1:eq:firstPlayerPayoff}
  \K*{n}(p, \sigmar, \taur) = \E_{(p,\sigmar,\taur)} \sum_{t=1}^n
  \left(
    p \as[H](i_t^H, j_t) + (1 - p)\as[L](i_t^L, j_t)
  \right).
\end{equation}

Полученную игру обозначим через $\theG*{n}(p)$.
Ее верхнее и нижнее значения даются формулами
\begin{equation*}
  \LowV*{n}(p) = \max_{\sigmar \in \Sigma} \inf_{\taur \in \Tau}
  \K*{n}(p, \sigmar, \taur), \quad
  \HighV*{n}(p) = \min_{\taur \in \Tau} \sup_{\sigmar \in \Sigma}
  \K*{n}(p, \sigmar, \taur).
\end{equation*}
Если верхнее и нижнее значения совпадают, то игра имеет значение, которое мы обозначим $\V*{n}(p)$.

Заметим, что имеют место следующие равенства:
\begin{equation}
  \label{ch1:eq:payoff-symmetry}
  \as[L][\Co](i, j) = \as[H][\DCo](m-i, m-j), \quad
  \as[H][\Co](i, j) = \as[L][\DCo](m-i, m-j).
\end{equation}
Из них следует следующее
\begin{remark}
  \label{ch1:rem:symm-payoffs}
  Определим для заданных стратегий $\sigmar,\ \taur$ стратегии $\overline{\sigmar}$ и $\overline{\taur}$ таким образом, что для $t$-го шага
  $\overline{\sigmas{t}} = (\overline{\sigmas[H]{t}}, \overline{\sigmas[L]{t}})$, где
  $\overline{\sigmas[s]{t}}=(\sigmasc[s][t]{m},\ldots,\sigmasc[s][t]{0}) \in \Delta(I)$, и
  $\overline{\taus{t}} = (\tausc[t]{m},\ldots,\tausc[t]{0}) \in \Delta(J)$.
  Из равенств (\ref{ch1:eq:payoff-symmetry}) следует, что выигрыши игроков в играх $\theG*[\Co]{n}(p)$ и $\theG*[\DCo]{n}(1-p)$ при использовании соответственно стратегий $\sigmar,\ \taur$ и $\overline{\sigmar},\ \overline{\taur}$ совпадают.
\end{remark}

В \emphasis{разделе 1.4} рассматривается следующая чистая стратегия второго игрока $\tau^k,\ k \in J$, введенная В.~К.~Доманским в работе~\cite{domansky07}:
\[
  \tau^k_1 = k, \quad \tau^k_t(i_{t-1}, j_{t-1}) = \begin{cases}
    j_{t-1} - 1, & \, i_{t-1} < j_{t-1}, \\
    j_{t-1},     & \, i_{t-1} = j_{t-1}, \\
    j_{t-1} + 1, & \, i_{t-1} > j_{t-1}.
  \end{cases}
\]
Пусть стратегия второго игрока $\taur^*$ состоит в применении $\tau^k$ при $p \in \left( (k-\DCo)/m, (k+\Co)/m) \right]\, k = \overline{0, m}$.
Справедлива следующая
\begin{theorem}
  Зафиксируем вероятность $p \in [0,1]$.
  Тогда при использовании вторым игроком стратегии $\taur^*$ в игре $\theG*{\infty}(p)$\textup{,} выигрыш первого игрока ограничен сверху величиной $\H*{\infty}(p)$, т.е.
  \[
    \max_{\sigmar \in \Sigma} \K*{\infty}(p, \sigmar, \taur^*) \leq \H*{\infty}(p).
  \]
  где $\H*{\infty}(p)$ является вогнутой кусочно-линейной функцией, график которой состоит из $m+1$ линейных сегментов и полностью определяется своими значениями в следующих точках:
  \begin{gather*}
    \H*{\infty}(k+\Co)/m) = \frac{1}{2} \left( (m - (k + \Co))(k + \Co) + \DCo\Co \right),\enskip
    k = \overline{0, m - 1},\\
    \H*{\infty}(0) = \H*{\infty}(1) = 0.
  \end{gather*}
\end{theorem}

В \emphasis{разделе 1.5} описана стратегия первого игрока, гарантирующая ему выигрыш не менее $\H*{\infty}(p)$ в игре $\theG*{\infty}(p)$.

Пусть на первом шаге игры первый игрок выбирает ход %
$\sigma^k_1 = (\sigma^H_1, \sigma^L_1)$, где %
$\sigma^H_1 = (\sigma^H_{1,k}, \sigma^H_{1,k+1})$,
$\sigma^L_1 = (\sigma^L_{1,k}, \sigma^L_{1,k+1})$ и
$\sigma^s_{1,i}$ -- вероятность сделать ставку $i$ в состоянии $s \in S$.
Применяя $\sigma^k_1$, инсайдер делает ставки $k$ и $k+1$ с некоторыми заданными вероятностями.

В дальнейшем будем использовать эквивалентный способ задания хода.
Для этого определим следующие параметры: полные вероятности использования действий $k$ и $k+1$, равные $\qc{k}$ и $\qc{k+1}$ соответственно, а также апостериорные вероятности $\pac{s}{i}$ состояния $s$ при условии, что на предыдущем шаге первый игрок сделал ставку $i$.
Тогда вероятности $\sigma^s_{1,i}$ можно найти по формуле Байеса
\[
  \sigma^s_{1,i} = \pac{s}{i}\qc{i}/\pc{s}, \: i = k, k + 1.
\]

Построим оптимальную стратегию инсайдера.
% Рассмотрим на $[0,1]$ множество $P$ точек вида
% \[
% \pEven[k] = k/m, \, k = \overline{0, m}, \quad \pOdd[k] = (k + \Co)/m, \, k = \overline{0, m - 1}.
% \]

Для $p = k/m,\ k = \overline{1, m-1}$ определим $\phi^0_k$ как распределение $\sigma^k_1$ с параметрами
\begin{align*}
  \qc{k} = \Co,& \quad \pac{H}{k} = (k-1+\Co)/m,\\
  \qc{k+1} = \DCo,& \quad \pac{H}{k + 1} = (k+\Co)/m.
\end{align*}
% Покомпонентно оно записывается как
% \begin{gather*}
%   \sigma^H_{1,k} = \frac{(k-\DCo)\Co}{k},\quad 
%   \sigma^H_{1,k+1} = \frac{(k+\Co)\DCo}{k},\\
%   \sigma^L_{1,k} = \frac{(m - k + \DCo)\Co}{m - k},\quad 
%   \sigma^L_{1,k+1} = \frac{(m - k - \Co)\DCo}{m - k}.
% \end{gather*}
Дополнительно определим $\phi^0_0$ как распределение, состоящее в применении ставки $0$ с вероятностью $1$, а $\phi^0_m$ -- как распределение, состоящее в применении ставки $m$ с вероятностью $1$.

Аналогично для $p = (k+\Co)/m,\ k = \overline{0, m-1}$ определим $\phi^\Co_k$ как распределение $\sigma^k_1$ с параметрами
\begin{align*}
  \qc{k} = \DCo,& \quad \pac{H}{k} = k/\Co,\\
  \qc{k+1} = \Co,& \quad \pac{H}{k+1} = (k+1)/\Co.
\end{align*}

Для $p = \lambda (k+\beta)/m + (1-\lambda) (k+1)/m,\ \lambda \in (0, 1)$ обозначим через $\lambda \phi^\Co_k + (1-\lambda)\phi^\Co_{k+1}$ распределение, при котором первый игрок рандомизирует выбор ставок $k, k+1, k+2$ с параметрами
\begin{align*}
  \qc{k} = \lambda\DCo, &\quad \pac{H}{k} = k/m,\\
  \qc{k+1} = \Co, &\quad \pac{H}{k+1} = \lambda (k+1)/m + (1-\lambda) (k+\Co)/m,\\
  \qc{k+2} = (1-\lambda)\DCo, &\quad \pac{H}{k+2} = (k+1+\Co)/m.
\end{align*}

Для $p = \lambda k/m + (1-\lambda) (k+\Co)/m,\ \lambda \in (0, 1)$ через $\lambda \phi^0_k + (1-\lambda)\phi^\Co_k$ обозначим распределение, при котором первый игрок рандомизирует выбор ставок $k$ и $k+1$ с параметрами
\begin{gather*}
  \qc{k} = \lambda\Co + (1-\lambda)(1-\Co),\enskip
  \pac{H}{k} = \frac{\lambda\Co}{q_k} \frac{k-1+\Co}{m} + \frac{(1-\lambda)(1-\Co)}{q_k} \frac{k}{m},\\
  \qc{k+1} = \lambda(1-\Co) + (1-\lambda)\Co,\enskip
  \pac{H}{k+1} = \frac{\lambda(1-\Co)}{q_{k+1}} \frac{k+\Co}{m} + \frac{(1-\lambda)\Co}{q_{k+1}} \frac{k+1}{m}.
\end{gather*}

Следуя \cite{domansky07}, опишем рекурсивную структуру игры $\theG*{n}(p)$.
Стратегию $\sigma$ первого игрока в $n$-шаговой игре можно представить как $(\sigmas{1}, \sigmara{i},\ i \in I)$, где $\sigmas{1}$ "--- ход первого игрока на первом шаге игры, а $\sigmara{i}$ "--- стратегия в игре продолжительности $n-1$, зависящая от ставки $i$ на первом шаге.
Аналогично стратегию второго игрока можно представить как $(\taus{1}, \taura{i},\ i \in I)$.
Тогда для функции выигрыша справедливо следующее представление
\begin{equation}
  \label{ch1:eq:recursive-structure}
  \K*{n}(p,\sigmar,\taur) = 
  \K*{1}(p,\sigmas{1},\taus{1}) + \sum_{i \in I} \qc{i} \K*{n-1}(\pac{H}{i},\sigmara{i},\taura{i}).
\end{equation}

Отсюда получаем, что, определив одношаговую стратегию инсайдера для любого значения $p \in [0,1]$, можно рекурсивно продолжить ее применение на последующих шагах игры, тем самым определив стратегию в игре произвольной продолжительности.

Пусть при $\Co \in (0,1)$ стратегия $\sigma^*$ состоит в применении инсайдером описанных выше одношаговых стратегий для соответствующих значений апостериорной вероятности. 
Стратегия инсайдера при $\Co = 1$ найдена в~\cite{domansky07}.
При $\Co = 0$ стратегия может быть получена конструкцией замечания~\ref{ch1:rem:symm-payoffs}.
Таким образом, стратегия $\sigma^*$ определена для всех значения $\Co \in [0,1]$.

Обозначим гарантированный выигрыш первого игрока в игре $\theG*{n}(p)$ при применении стратегии $\sigmar$ через
\begin{equation*}
  \L*{n}(p, \sigmar) = \min_{\taur \in \Tau} \K*{n}(p,\sigmar,\taur).
\end{equation*}
В работе показано, что функции $\L*{\infty}(p, \sigmar^*)$ и $\H*{\infty}(p)$ совпадают при всех значениях $p \in [0,1],\ \Co \in [0,1]$.

В \emphasis{разделе 1.6} даны теоремы о значении игры $\theG*{\infty}(p)$.
\begin{theorem}
  Игра $\theG*{\infty}(p)$ имеет значение $\V*{\infty}(p) = \H*{\infty}(p) = \L*{\infty}(p)$.
  При этом $\sigmar^*$ -- оптимальная стратегия первого игрока\textup{,} а $\taur^*$ -- оптимальная стратегия второго игрока.
\end{theorem}

\begin{theorem}
  При любом значении $p \in [0,1]$, $\Co \in (0,1)$ и $m \geq 3$ справедливо неравенство
  \begin{equation*}
    \V*[\Co]{\infty}(p) \geq \V*[1]{\infty}(p) = \V*[0]{\infty}(p),
  \end{equation*}
  причем равенство достигается только при $p = k/m, k = \overline{0,m}$.
\end{theorem}

\emphasis{Раздел 1.7} посвящен анализу случайных блужданий апостериорных вероятностей, возникающих при применении игроками оптимальных стратегий $\sigmar^*$ и $\taur^*$.

Случайная величина
\begin{equation*}
  \xi \eqdef \min \left\{ t \geq 0: p^t \in \{p_0, p_{2m}\} \right\}
\end{equation*}
соответствует моменту поглощения. Величина
\begin{equation*}
  \tau(p_k) \eqdef \E \{ \xi\ |\ p = p_k \}
\end{equation*}
определяет ожидаемую продолжительность игры, при условии, что априорная вероятность равна $p_k$.

\begin{theorem}
  Игра $\theG*{\infty}(p),\ p \in \{k_1/m, (k_2+\Co)/m,\ k_1 = \overline{0,m},\ k_2 = \overline{0,m-1}\},$ в среднем заканчивается за конечное количество шагов.
  Ее ожидаемая продолжительность выражается формулами
  \begin{equation*} 
    \tau\left( (k+\beta)/m \right) = \frac{(m-k-\Co)(k+\Co)}{\Co \DCo},\quad
    \tau\left( k/m \right) = \frac{k(m-k)}{\Co \DCo}.
  \end{equation*}
\end{theorem}

% * Вторая глава
\emphasis{Вторая глава} посвящена исследованию дискретной модели рынка со счетным множеством состояний.
В \emphasis{разделе 2.1} дается формальное описание соответствующей повторяющейся игры.

Пусть множество состояний $S = \Z_+$.
Перед началом игры случай выбирает состояние рынка $\s \in S$ в соответствии с вероятностным распределением $\p = (p^s, \; s \in S)$, имеющим конечную дисперсию состояния $\D \p < \infty$.
Множество всех таких распределений обозначим $\MM$.

На каждом шаге игры $t = \overline{1,n}, \; n \leqslant \infty$, игроки делают ставки $i_t \in I, \, j_t \in J$, где $I = J = \Z_+$.
В силу того, что игрок, предложивший б\'{о}льшую ставку, покупает акцию у другого по цене, равной выпуклой комбинации предложенных ставок, выплата первому игроку в состоянии $s$ равна
\begin{equation*}
  \as(i_t, j_t) =
  \begin{cases}
    (1-\beta) i_t + \beta j_t - s, &\; i_t < j_t, \\
    0, &\; i_t = j_t, \\
    s - \beta i_t - (1-\beta)j_t, &\; i_t > j_t.
  \end{cases}
\end{equation*}

При использовании игроками стратегий $\sigmav$ и $\tauv$ ожидаемый выигрыш первого игрока равен
\begin{equation*}
  \K{n}(\p, \sigmav, \tauv) =
  \E_{(\p, \sigmav, \tauv)} \sum_{t=1}^n \as(i_t, j_t),
\end{equation*}
где математическое ожидание берется по мере, индуцированной $\p$, $\sigmav$ и $\tauv$ на множестве $S \times I^n \times J^n$.
Заданную таким образом игру обозначим $\theG{n}(\p)$.

Если для некоторых стратегий $\sigmar^* \in \Sigma,$ $\taur^* \in \Tau$ выполняются равенства
\begin{equation*}
  \inf_{\taur \in \Tau} \K{n}(\p, \sigmar^*, \taur) =
  \K{n}(\p, \sigmar^*, \taur^*) =
  \sup_{\sigmar \in \Sigma} \K{n}(\p, \sigmar, \taur^*) \eqdef
  \V{n}(\p),
\end{equation*}
то говорят, что игра $\theG{n}(\p)$ имеет значение $\V{n}(\p)$, а стратегии $\sigmar^*$ и $\taur^*$
называются оптимальными.

Нижнее и верхнее значения игры $\theG(\p)$ обозначим соответственно
\begin{equation*}
  \LowV{n}(\p) =
    \sup_{\sigmar \in \Sigma}
    \inf_{\taur \in \Tau}
    \K{n}(\p, \sigmav, \tauv), \quad
  \HighV{n}(\p) =
    \inf_{\taur \in \Tau}
    \sup_{\sigmar \in \Sigma}
    \K(\p, \sigmra, \taur).
\end{equation*}
Данные функции являются вогнутыми на $\MM$.

В \emphasis{разделе 2.2} получена оценка сверху выигрыша первого игрока.

Следующие множества распределений зададим ограничениями на математическое ожидание состояния:
\begin{gather*}
  \Theta(x) = \left\{ \p \in \MM: \E \p = x \right\}, \\
  \Lambda(x, y) = \left\{ \p \in \MM: x < \E \p \leqslant y \right\}.
\end{gather*}

Пусть $\taur^*$ --- стратегия второго игрока, состоящая в применении $\tau^k$ при $\p \in \Lambda(k-1+\beta,k+\beta)$.
Отметим, что при заданном распределении $\p$ выбор $k$ зависит от значения $\beta$.

\begin{theorem}
  \label{ch2:upper-bound:theorem}
  При использовании вторым игроком стратегии $\taur^*$, выигрыш первого игрока в игре
  $\theG{\infty}(\p)$ ограничен сверху функцией
  \begin{equation*}
    \H{\infty}(\p) = \inf_{k \in J} \sum_{s \in S} \pc{s}  h^s_\infty(\taur^k).
  \end{equation*}
  Функция $\H{\infty}(\p)$ является кусочно-линейной вогнутой с областями линейности $\Lambda(k - 1 + \beta, k + \beta)$ и областями недифференцируемости $\Theta(k+\beta)$ при $k \in S$.
  Для распределений $\p$ с $\E \p = k - 1 + \beta + \eta, \; \eta \in (0, 1]$, ее значение равно
  \begin{equation}
    \label{ch2:upper-bound:eq:H(p)}
    \H{\infty}(\p) = \left( \D \p + \beta(1-\beta) - \eta(1-\eta) \right)/2.
  \end{equation}
\end{theorem}

В \emphasis{разделе 2.3} построена стратегия первого игрока, гарантирующая ему выигрыш не менее $\H{\infty}(\p)$.

Задав одношаговую стратегию $\sigmas{1}$ первого игрока при помощи полных вероятностей $\qc{i}$ сделать ставку $i$ и апостериорных вероятностей $\pac{s}{i}$ для $i \in I$, получим следующее выражение его одношагового выигрыша:
\begin{equation}
  \label{ch2:lower-bound:eq:K1(q,pi)}
  \K{1}(\p, \sigmas{1}, j) = \sum_{i \in I} \sum_{s \in S} \qc{i} \pac{s}{i} \as(i, j).
\end{equation}

Обозначим $\L{n}(\p, \sigmav)$ гарантированный выигрыш первого игрока, использующего стратегию $\sigmar$ в игре $\theG{n}(\p)$, т.е.
\[
  \L{n}(\p, \sigmar) = \inf_{\taur \in \Tau} \K{n}(\p, \sigmar, \taur).
\]
\begin{lemma}
  \label{ch2:lower-bound:lemma:convex-combination}
  Пусть $\p_1, \p_2 \in \MM$, $\sigmar^1, \sigmar^2 \in \Sigma$ --- стратегии первого игрока.
  Тогда для $\p = \lambda \p_1 + (1-\lambda) \p_2,\ \lambda \in [0, 1],$ найдется такая стратегия $\sigmar^c \in \Sigma$, что
  \[
    \L{n}(\p, \sigmar^c) \geqslant
    \lambda \L{n}(\p_1, \sigmar^1) + (1-\lambda) \L{n}(\p_2, \sigmar^2).
  \]
\end{lemma}

Обозначим $e^s$ вырожденное вероятностное распределение с носителем в точке $s$.
Пусть $\pd^x(l, r) \in \Theta(x)$ --- распределение с носителем $\{l, r\},\ l<r$.
При этом распределении вероятности реализации состояний $l$ и $r$ равны $(r-x)/(r-l)$ и $(x-l)/(r-l)$ соответственно, а дисперсия
\[
  \D \pd^x(l, r) = (x - l)(r - x).
\]
Любое распределение $\pd = (\pc{s},\ s \in S) \in \Theta(x)$ может быть представлено в виде выпуклой комбинации распределений с двухточечными носителями следующим образом:
\begin{gather}
  \label{ch2:lower-bound:eq:prob-decomp-sum}
  \pd = \begin{cases}
    \displaystyle
    \pc{x} e^x + \sum_{r=x+1}^\infty \sum_{l=0}^{x-1} \alpha_{l,r}(\pd) \pd^x(l, r),\ & x \in S,\\
    \displaystyle
    \sum_{r=\floor{x+1}}^\infty \sum_{l=0}^{\ceil{x-1}} \alpha_{l,r}(\pd) \pd^x(l, r),\ & x \notin S,\\
  \end{cases}\\
  \alpha_{l,r}(\pd) = (r-l) \pc{l} \pc{r} / \sum_{t=0}^{\ceil{x-1}} \pc{t} (x-t). \nonumber
\end{gather}

Обозначим через $\LL$ банахово пространство последовательностей $(l^s,\ s \in S)$ с нормой $\norm{l} = \sum_{s = 0}^\infty s^2 |l^s|$.
Множества $\MM$ и $\Theta(x)$ являются выпуклыми замкнутыми подмножествами пространства $\LL$.

\begin{lemma}
  \label{ch2:lower-bound:lemma:decomp-convergence}
  Для любого распределения $\pd \in \Theta(x)$ ряд в разложении (\ref{ch2:lower-bound:eq:prob-decomp-sum}) сходится к $\pd$ по норме.
\end{lemma}

В силу того, что функционал $\LowV{n}(\p)$ вогнут на $\MM$ и по теореме~\ref{ch2:upper-bound:theorem} ограничен на данном множестве, то он непрерывен на $\MM$.
Отсюда и из леммы~\ref{ch2:lower-bound:lemma:decomp-convergence} следует, что для распределений $\p \in \Theta(x)$ выполнено
\begin{equation*}
  \left\{
  \begin{aligned}
    \LowV{n}(\pd) &\geqslant
      \pc{x} \LowV{n}(e^x) + \sum_{r=x+1}^\infty \sum_{l=0}^{x-1} \alpha_{l,r}(\pd) \LowV{n} \left( \pd^x(l, r) \right),&\ x \in S,\\
    \LowV{n}(\pd) &\geqslant 
      \sum_{r=\floor{x+1}}^\infty \sum_{l=0}^{\ceil{x-1}} \alpha_{l,r}(\pd) \LowV{n} \left( \pd^x(l, r) \right),&\ x \notin S.
  \end{aligned}
  \right.
\end{equation*}

Из данных неравенств, теоремы~\ref{ch2:upper-bound:theorem} и леммы~\ref{ch2:lower-bound:lemma:convex-combination} следует, что для доказательства совпадения верхней и нижней оценок выигрыша в игре $\theG{\infty}(\pd)$ можно ограничиться рассмотрением только распределений %
$\pd = \pd^{k+\beta}(l, r) \in \Theta(k + \beta), \; k \in S,\ l = \overline{0, k},\ r = \overline{k+1, \infty}$.
Для таких распределений мы построим стратегию первого игрока $\sigmar^*$, для которой $\L{\infty}(\pd, \sigmar^*) = \H{\infty}(\pd)$.
Отсюда будет следовать, что $\V{\infty}(\pd) = \H{\infty}(\pd)$, а $\sigmar^*$ и $\taur^*$ --- оптимальные стратегии игроков в игре $\theG{\infty}(\pd)$.

Обозначим $\sigmak$ ход первого игрока, состоящий в выборе ставки из множества $\{k, k+1\}$.
Ход $\sigmak$ определяется заданием полных вероятностей $\qc{k}, \qc{k+1}$ и апостериорных распределений $\pad{k}, \pad{k+1}$, причем $\qc{k} + \qc{k+1} = 1$.

Определим стратегию $\sigmar^*$ первого игрока в игре $\theG{\infty}(\p)$.
Введем множество распределений
\begin{equation*}
  P(l,r) = \left\{
    \pd^{k_1}(l, r), \, \pd^{k_2+\beta}(l, r), \, k_1 = \overline{l,r}, k_2 = \overline{l,r-1}
  \right\}.
\end{equation*}
При $\p \in P(l,r)$ первый ход $\sigmas[*]{1}$ стратегии $\sigmar^*$ определяется следующим образом.
Если $\p = \p^l(l,r)$ или $\p = \p^r(l,r)$, то первый игрок использует ставки $l$ и $r$, соответственно, с вероятностью 1.
В противном случае он использует $\sigmak$ с параметрами из таблицы~\ref{ch2:tab:insider-strategy}.

\begin{table}[htb]
  \centering
  \renewcommand{\arraystretch}{1.5}
  \captionsetup{width=12cm}
  \caption{Параметры хода $\sigmas[*]{1}$ при $\p \in P(l, r)$}
  \label{ch2:tab:insider-strategy}
  \begin{tabular}{|P{2cm}||P{2cm}|P{2cm}|P{2cm}|P{2cm}|}
    \hline
    \hline
    $\pd$         & $\qc{k}$ & $\qc{k+1}$ & $\p^{k}$ & $\pc{k+1}$ \\ \hline
    $\pd^k(l, r)$ & $\beta$  & $1-\beta$  & $\pd^{k-1+\beta}(l, r)$ & $\pd^{k+\beta}(l, r)$ \\ \hline
    $\pd^{k+\beta}(l, r)$                                                   & $1-\beta$ & $\beta$ & $\pd^k(l, r)$ & $\pd^{k+1}(l, r)$     \\
    \hline
    \hline
    \multicolumn{1}{c}{}
    \vspace{-2.5em}
  \end{tabular}
\end{table}

На последующих шагах игры ход $\sigmas[*]{1}$ применяется рекурсивно для соответствующих значений апостериорных вероятностей.
В результате определили стратегию $\sigmar^*$ для распределения $\p \in P(l,r)$.

Для произвольного распределения $\pd \in \Theta(k),\ k \in S$, стратегию $\sigmar^*$ определим следующим образом.
Если реализуется состояние $s = k$, то гарантированный выигрыш первого игрока не превышает $0$ и он прекращает игру.
Таким образом, первый игрок, следуя стратегии $\sigmar^*$, прекращает игру с вероятностью $p^k$.
В противном случае игрок использует конструкцию леммы~\ref{ch2:lower-bound:lemma:convex-combination} для построения стратегии, соответствующей выпуклой комбинации распределений $\pd^k(l, r)$ в разложении $\p$.
Первый ход такой стратегии использует две ставки $k$ и $k+1$ с полными вероятностями $(1-\pc{k})\beta$ и $(1-\pc{k})(1-\beta)$ соответственно.
Апостериорные вероятностные распределения являются выпуклыми комбинациями соответствующих апостериорных двухточечных распределений и даются следующими формулами:
\begin{gather*}
  \pad{k} = \frac{1}{1-\pc{k}} \sum_{r=k+1}^\infty \sum_{l=0}^{k-1} \alpha_{l,r}(\pd) \pd^{k-1+\beta}(l, r), \\
  \pad{k+1} = \frac{1}{1-\pc{k}} \sum_{r=k+1}^\infty \sum_{l=0}^{k-1} \alpha_{l,r}(\pd) \pd^{k+\beta}(l, r).
\end{gather*}
Аналогичные рассуждения справедливы и для распределений $\pd \in \Theta(k+\beta) \cup \Lambda(k, k+\beta),\ k \in S$.

В диссертации показано, что для $\pd \in P(l,r)$ значения $\L{\infty}(\pd, \sigmar^*)$ и $\H{\infty}(\pd)$ совпадают.

В \emphasis{разделе 2.4} дана теорема о значении игры $\theG{\infty}(\pd)$.
\begin{theorem}
  \label{ch2:solution:theorem}
  Игра $\theG{\infty}(\pd)$ имеет значение
  \[
    \V{\infty}(\pd) = \H{\infty}(\pd) = \L{\infty}(\pd),
  \]
  а $\sigmar^*$ и $\taur^*$ --- оптимальные стратегии игроков.
\end{theorem}

В \emphasis{разделе 2.5} приведена вторая оптимальная стратегия инсайдера $\xi^*$.
Введем множество распределений %
\begin{equation*}
  P'(l,r) =
  \{\pd^l(l, r), \pd^r(l, r)\}
  \cup
  \left\{
    \pd^{k+\beta}(l, r), \, k = \overline{l, r-1}
  \right\}.
\end{equation*}
При $\p \in P'(l,r)$ первый ход $\xi^*_1$ стратегии $\xiv^*$ определяется следующим образом.
Если $\pd = \pd^l(l,r)$ или $\pd = \pd^r(l,r)$, то первый игрок использует ставки $l$ и $r$ соответственно с вероятностью 1.
В противном случае он использует $\sigmak$ с параметрами из таблицы~\ref{ch2:tab:insider-strategy2}.
\begin{table}[htb]
  \centering
  \renewcommand{\arraystretch}{1.5}
  \captionsetup{width=12cm}
  \caption{Параметры хода $\xi^*_1$ при $\pd \in P'(l, r)$}
  \label{ch2:tab:insider-strategy2}
  \begin{tabular}{|P{2cm}||P{2cm}|P{2cm}|P{2cm}|P{2cm}|}
    \hline
    \hline
    $\pd$                   & $\qc{k}$ & $\qc{k+1}$                 & $\pad{k}$                & $\pad{k+1}$                                      \\
    \hline
    $\pd^{l+\beta}(l, r)$           & $\frac{1}{1+\beta}$       & $\frac{\beta}{1+\beta}$ & $\pd^l(l, r)$           & $\pd^{l+1+\beta}(l, r)$ \\
    \hline
    $\pd^{r-1+\beta}(l, r)$         & $\frac{1-\beta}{2-\beta}$ & $\frac{1}{2-\beta}$     & $\pd^{r-2+\beta}(l, r)$ & $\pd^r(l, r)$           \\
    \hline
    $\pd^{k+\beta}(l, r)$   & $\frac{1}{2}$             & $\frac{1}{2}$           & $\pd^{k-1+\beta}(l, r)$ & $\pd^{k+1+\beta}(l, r)$  \\
    \hline
    \hline
    \multicolumn{1}{c}{}
    \vspace{-2.5em}
  \end{tabular}
\end{table}

Для остальных распределений $\pd$ стратегия $\xi^*$ определяется аналогично тому, как это было сделано для стратегии $\sigmar^*$.

Использование стратегии $\xi^*$ при $\p \in P'(l, r)$ порождает случайное блуждание последовательности апостериорных вероятностей.
Данное случайное блуждание симметрично с вероятностями перехода в соседние состояния равными $1/2$, симметрия нарушается только в крайних и соседних к ним состояниях.

% * Третья глава
\emphasis{Третья глава} посвящена исследованию 

% % * Conclusion
% В \emphasis{заключении} приведены основные результаты работы, которые заключаются в следующем:
% \input{common/concl}

%\newpage
% При использовании пакета \verb!biblatex! список публикаций автора по теме
% диссертации формируется в разделе <<\publications>>\ файла
% \verb!../common/characteristic.tex!  при помощи команды \verb!\nocite! 

\ifdefmacro{\microtypesetup}{\microtypesetup{protrusion=false}}{} % не рекомендуется применять пакет микротипографики к автоматически генерируемому списку литературы
\ifnumequal{\value{bibliosel}}{0}{% Встроенная реализация с загрузкой файла через движок bibtex8
  \renewcommand{\refname}{\large \authorbibtitle}
  \nocite{*}
  \insertbiblioauthor                          % Подключаем Bib-базы
  %\insertbiblioother   % !!! bibtex не умеет работать с несколькими библиографиями !!!
}{% Реализация пакетом biblatex через движок biber
  \insertbiblioauthor                          % Подключаем Bib-базы
  \insertbiblioother
}
\ifdefmacro{\microtypesetup}{\microtypesetup{protrusion=true}}{}


%%% Local variables:
%%% mode: latex
%%% TeX-master: "../synopsis"
%%% End:
