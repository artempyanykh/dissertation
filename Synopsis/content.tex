
\section*{Общая характеристика работы}

\newcommand{\emphasis}[1]{\underline{\textbf{{#1}}}}
\newcommand{\actuality}{\emphasis{\actualityTXT}}
\newcommand{\progress}{\emphasis{\progressTXT}}
\newcommand{\aim}{\emphasis{\aimTXT}}
\newcommand{\tasks}{\emphasis{\tasksTXT}}
\newcommand{\researchsubject}{\emphasis{\researchsubjectTXT}}
\newcommand{\novelty}{\emphasis{\noveltyTXT}}
\newcommand{\influence}{\emphasis{\influenceTXT}}
\newcommand{\methods}{\emphasis{\methodsTXT}}
\newcommand{\defpositions}{\emphasis{\defpositionsTXT}}
\newcommand{\reliability}{\emphasis{\reliabilityTXT}}
\newcommand{\probation}{\emphasis{\probationTXT}}
\newcommand{\contribution}{\emphasis{\contributionTXT}}
\newcommand{\publications}{\emphasis{\publicationsTXT}}

\input{common/characteristic} % Характеристика работы по структуре во введении и в автореферате не отличается (ГОСТ Р 7.0.11, пункты 5.3.1 и 9.2.1), потому её загружаем из одного и того же внешнего файла, предварительно задав форму выделения некоторым параметрам

%Диссертационная работа была выполнена при поддержке грантов ...

\emphasis{Объем и структура работы.}
Диссертация состоит из~введения, трех глав и заключения.
Полный объем диссертации составляет \todo{\textbf{ХХХ}}~страниц текста с~\todo{\textbf{ХХ}}~рисунками и~\todo{XXX}~таблицами.
Список литературы содержит \todo{\textbf{ХХX}}~наименование.

%\newpage
\section*{Содержание работы}
Во \emphasis{введении} обосновывается актуальность исследований, проводимых в рамках данной диссертационной работы, приводится обзор научной литературы по изучаемой проблеме, формулируется цель, ставятся задачи работы, сформулированы научная новизна, теоретическая и практическая значимость представляемой работы, а также результаты, выносимые на защиту.

% * Chapter 1
\emphasis{Первая глава} посвящена исследованию теоретико-игровой модели биржевых торгов с дискретными ставками и двумя состояниями.

% ** Основные понятия и введение в тему
В \emphasis{разделе 1.1} диссертации дано введение в теорию повторяющихся игр с неполной информацией, определены основные термины и понятия.
Теоретико-игровые постановки задач из глав~2 и~3 будут отличаться от данного классического описания, о чем будет сказано отдельно.

Рассмотрим антагонистическую игру двух лиц, которая повторяется $n$ раз, где $n\leq \infty$.
Будем считать, что первый игрок знает функцию выигрыша в данной игре, в то время как второй игрок такой информацией не обладает.
Однако второй игрок знает, что настоящая функция выигрыша является одной из $\kappa$ возможных альтернатив.
Каждой такой альтернативе второй игрок приписывает некоторую вероятность того, что данная функция выигрыша является истинной функцией выигрыша в рассматриваемой
игре.
Таким образом, априорные убеждения второго игрока задаются вероятностным вектором
$\p = (p(1), p(2), \ldots, p(\kappa)),\ \sum_{i=1}^\kappa p(i) = 1$.
С данными функциями выигрыша можно связать игры $G_1, G_2, \ldots, G_\kappa$.
В дальнейшем мы будем считать, что информационная неопределенность второго игрока заключается именно в том, что он не знает какая из игр $G_1, G_2, \ldots, G_\kappa$ разыгрывается.

На каждом шаге игры первый игрок может совершать действия из множества $I$, второй игрок --- действия из множества $J$, при этом мы считаем, что множества действий одного игрока известно другому.
Кроме того, положим, что второй игрок знает, что первый обладает точной информацией о том, какая именно игра разыгрывается, а первый игрок знает априорные убеждения второго.

Игры $G_1, G_2, \ldots, G_\kappa$ будем называть \emph{одношаговыми играми}.
Все одношаговые игры описываются матрицами размера $|I| \times |J|$, где элементы матрицы задают выплаты первому игроку.
Мы предполагаем, что оба игрока точно знают платежные матрицы игр $G_1, G_2, \ldots, G_\kappa$.
На каждом шаге игры первый игрок выбирает номер строки, и одновременно с ним второй игрок выбирает номер столбца.
В конце каждого хода действия игроков оглашаются, и элемент из матрицы, отвечающей настоящей игре, прибавляется к выигрышу первого игрока и вычитается из выигрыша второго.
Таким образом, первый игрок знает свой выигрыш на каждом этапе игры, в то время как второй может лишь рассчитать свой ожидаемый выигрыш.
В завершение, мы считаем, что данное описание известно обоим игрокам.

Данная игра с неполной информацией описывается в виде игры в нормальной форме следующим образом.
Обозначим через $S = \{1, 2, \ldots, \kappa\}$ множество возможных альтернатив или \emph{состояний природы}.
Перед началом игры ходом случая в соответствии с вероятностным распределением $\p$ выбирается состояние $s \in S$.
Далее на протяжении $n$ шагов разыгрывается игра $G_s$.
Первый игрок информирован о результате хода случая, второй игрок "--- нет.
В остальном правила данной игры совпадают с описанными выше.

Пусть $h_t = \left((i_1, j_1), (i_2, j_2), \ldots, (i_t, j_t)\right)$ "--- история ходов после завершения шага $t$.
Множество все таких $h_t$ обозначим через $H_t$. 

Обозначим через $\Delta(X)$ совокупность всех вероятностных распределений на множестве $X$.

Стратегией первого игрока в такой игре является последовательность ходов (отображений) $\sigma = (\sigma_1, \sigma_2, \ldots, \sigma_n)$, где $\sigma_t = (\sigma^1_t, \sigma^2_t, \ldots, \sigma^\kappa_t)$, и $\sigma^s_t: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от предыдущих ходов, которую первый игрок использует если ходом случая реализовалось состояние $s$.

Аналогичным образом, определим стратегию второго игрока как последовательность ходов (отображений) $\tau = (\tau_1, \tau_2, \ldots, \tau_n)$, где $\tau_t: H_{t-1} \rightarrow \Delta(I)$ "--- смешанная стратегия, зависящая от предыдущих ходов.
Как видно, ход второго игрока на каждом шаге игры зависит только от предыдущих ходов, и не зависит от состояния, в силу того, что второй игрок не информирован о результате хода случая.

Отметим, что, как показано в монографии Аумана, Машлера~\cite{aumann95}, достаточно рассматривать только стратегии, которые зависят лишь от предыдущих ходов первого игрока и не зависят от ходов второго.
%
Также нужно отметить, что в диссертации рассмотрены игры, в которых выигрыш равен суммарным выплатам, в отличие от постановки из \cite{aumann95}, в которых рассматривались игры с усредненными выплатами.

% ** Описание дискретной модели
В \emphasis{разделе 1.2} приводится описание дискретной модели биржевых торгов.
Следуя работе~\cite{domansky07}, рассматривается упрощенная модель финансового рынка, на котором два игрока ведут торговлю однотипными акциями на протяжении $n \leqslant \infty$ шагов.

Перед началом торгов случайный ход определяет цену акции на весь период торгов, которая может быть либо $m \in \N$ с вероятностью $p$, либо $0$ с вероятностью $1-p$.
Таким образом определенный ход случая является упрощенным аналогом некоторого шокового события на финансовом рынке.
Такого, например, как публикация отчетов о доходах некоторой компании.
Выбранная цена сообщается первому игроку и не сообщается второму, при этом второй игрок знает, что первый "--- инсайдер.

Рассмотрим $t$-й шаг торгов, где $t = \overline{1,n}$.
На данном шаге первый игрок выбирает ставку $i_t \in I = \{0, 1, \ldots, m\}$, а второй --- ставку $j_t \in J = \{0, 1, \ldots, m\}$.
Игрок предложивший б\'{о}льшую ставку покупает у другого акцию по цене равной
\[
  \Co \max(i_t, j_t) + \DCo \min(i_t, j_t),
\]
где $\Co \in (0, 1),\ \DCo = 1 - \Co$.
Если ставки равны, то сделка на $t$-м шаге не состоится.
Коэффициент $\Co$ можно интерпретировать как \emph{переговорную силу продавца} "--- чем ближе значение к $1$, тем большую сумму получит продавец акции в результате сделки.

Считаем, что игроки обладают неограниченными запасами рисковых и безрисковых активов, т.е. торги не могут прекратиться по причине того, что у одного из игроков закончатся деньги или акции.
Цель игроков состоит в максимизации стоимости итогового портфеля, состоящего из некоторого числа купленных акций и суммы денег, полученных в результате торгов.
Таким образом, не ограничивая общности, можно положить, что в начальный момент времени оба игрока имеют нулевые портфели.

% ** Определение игры G^m_n(p)

В \emphasis{разделе 1.3} формально определяется повторяющаяся игра с неполной информацией, отвечающая данному выше описанию.

Пусть множество состояний рынка $S = \{L, H\}$. Перед началом игры случай выбирает $s \in S $ с вероятностями $P(s=H) = p$ и $P(s=L) = 1 - p$.
После этого на протяжении $n \leq \infty$ шагов игроки участвуют в игре с матрицей $A^{s,\Co}$, где
\begin{equation*}
  A^{L,\Co}(i, j) = \begin{cases}
    \DCo i + \Co j, &\, i < j, \\
    0, &\, i = j, \\
    -\Co i - \DCo j, &\, i > j,
  \end{cases}
  \qquad
  A^{H,\Co}(i, j) = \begin{cases}
    \DCo i + \Co j - m, &\, i < j, \\
    0, &\, i = j, \\
    m - \Co i - \DCo j, &\, i > j.
  \end{cases}
\end{equation*}

Стратегией первого игрока в данной игре является последовательность ходов (отображений) 
$\sigma = (\sigma_1, \sigma_2, \ldots, \sigma_t, \ldots)$, где 
$\sigma_t: S \times I^{t-1} \rightarrow \Delta(I)$.
Таким образом, на каждом шаге торгов первый игрок рандомизирует выбор ставки в зависимости от состояния и предыдущих ставок.
Как и в работе~\cite{domansky07}, мы ограничимся рассмотрением только тех стратегий $\sigma$, которые гарантируют первому игроку на каждом шаге игры неотрицательный выигрыш.
Множество таких стратегий первого игрока обозначим через $\Sigma$.

Аналогично стратегией второго игрока назовем последовательность ходов (отображений) 
$\tau = (\tau_1, \tau_2, \ldots, \tau_t, \ldots),$ где 
$\tau_t: I^{t-1} \rightarrow \Delta(J)$.
Не имея информации о настоящем состоянии, второй игрок при выборе ставки опирается только на историю ставок инсайдера.
Множество стратегий второго игрока обозначим через $\Tau$.

Обозначим через $\E_{(p,\sigma,\tau)}$ математическое ожидание по мере, индуцированной на $S \times I^n \times J^n$ ходом случая и смешанными стратегиями $\sigma$ и $\tau$ игроков.

При применении первым игроком смешанной стратегии $\sigma$, а вторым игроком "--- смешанной стратегии $\tau$, ожидаемый выигрыш первого игрока равен
\begin{equation*}
  K^{m,\Co}_n(p, \sigma, \tau) = \E_{(p,\sigma,\tau)} \sum_{t=1}^n
  \left(
    pA^{H,\Co}(i_t^H, j_t) + (1 - p)A^{L,\Co}(i_t^L, j_t)
  \right).
\end{equation*}

Полученную игру обозначим через $G^{m,\Co}_n(p)$.
Ее верхнее и нижнее значения даются формулами
\begin{equation*}
  \underline{V}^{m,\Co}_n(p) = \max_{\sigma \in \Sigma} \inf_{\tau \in \Tau}
  K^{m,\Co}_n(p, \sigma, \tau), \quad
  \overbar{V}^{m,\Co}_n(p) = \min_{\tau \in \Tau} \sup_{\sigma \in \Sigma}
  K^{m,\Co}_n(p, \sigma, \tau).
\end{equation*}
Если верхнее и нижнее значения совпадают, то игра имеет значение, которое мы обозначим $V^{m,\Co}_n(p)$.

Заметим, что имеют место следующие равенства:
\begin{equation*}
  A^{L,\Co}(i, j) = A^{H,\DCo}(m-i, m-j), \quad
  A^{H,\Co}(i, j) = A^{L,\DCo}(m-i, m-j).
\end{equation*}

Из них следует следующее
\begin{remark}
  \label{ch1:rem:symm-payoffs}
  Определим для заданных стратегий $\sigma,\ \tau$ стратегии $\overbar{\sigma}$ и $\overbar{\tau}$ таким образом, что для $t$-го шага
  $\overbar{\sigma_t} = (\overbar{\sigma^H_t}, \overbar{\sigma^L_t})$, где
  $\overbar{\sigma^s_t}=(\sigma^s_{t,m},\ldots,\sigma^s_{t,0}) \in \Delta(I)$, и
  $\overbar{\tau_t} = (\tau_{t,m},\ldots,\tau_{t,0}) \in \Delta(J)$.
  Выигрыши игроков в играх $G^{m, \Co}_n(p)$ и $G^{m, \DCo}_n(1-p)$ при использовании соответственно стратегий $\sigma,\ \tau$ и $\overbar{\sigma},\ \overbar{\tau}$ совпадают.
\end{remark}

В дальнейшем мы часто будем опускать верхний индекс $\Co$.

В \emphasis{разделе 1.4} рассматривается следующая чистая стратегия второго игрока $\tau^k,\ k \in J$, введенная В.~К.~Доманским в работе~\cite{domansky07}:
\[
  \tau^k_1 = k, \quad \tau^k_t(i_{t-1}, j_{t-1}) = \begin{cases}
    j_{t-1} - 1, & \, i_{t-1} < j_{t-1}, \\
    j_{t-1},     & \, i_{t-1} = j_{t-1}, \\
    j_{t-1} + 1, & \, i_{t-1} > j_{t-1}.
  \end{cases}
\]
Пусть стратегия второго игрока $\tau^*$ состоит в применении $\tau^k$ при $p \in \left( (k-\DCo)/m, (k+\Co)/m) \right]\, k = \overline{0, m}$.
Справедлива следующая
\begin{theorem}
  Зафиксируем вероятность $p \in [0,1]$.
  Тогда при использовании вторым игроком стратегии $\tau^*$ в игре $G^m_\infty(p)$\textup{,} выигрыш первого игрока ограничен сверху величиной $H^m_\infty(p)$, т.е.
  \[
    \max_{\sigma \in \Sigma} K^m_\infty(p,\sigma,\tau^*) \leqslant H^m_\infty(p),
  \]
  где $H^m_\infty(p)$ является вогнутой кусочно-линейной функцией, график которой состоит из $m+1$ линейных сегментов и полностью определяется своими значениями в следующих точках:
  \begin{gather*}
    H^m_\infty(k+\Co)/m) = \frac{1}{2} \left( (m - (k + \Co))(k + \Co) + \DCo\Co \right),\enskip
    k = \overline{0, m - 1},\\
    H^m_\infty(0) = H^m_\infty(1) = 0.
  \end{gather*}
\end{theorem}

В \emphasis{разделе 1.5} описана стратегия первого игрока, гарантирующая ему выигрыш не менее $H^m_\infty(p)$ в игре $G^m_\infty(p)$.

Пусть на первом шаге игры первый игрок выбирает ход %
$\sigma^k_1 = (\sigma^H_1, \sigma^L_1)$, где %
$\sigma^H_1 = (\sigma^H_{1,k}, \sigma^H_{1,k+1})$,
$\sigma^L_1 = (\sigma^L_{1,k}, \sigma^L_{1,k+1})$ и
$\sigma^s_{1,i}$ -- вероятность сделать ставку $i$ в состоянии $s \in S$.
Применяя $\sigma^k_1$, инсайдер делает ставки $k$ и $k+1$ с некоторыми заданными вероятностями.

В дальнейшем будем использовать эквивалентный способ задания хода.
Для этого определим следующие параметры: полные вероятности использования действий $k$ и $k+1$, равные $q_k$ и $q_{k+1}$ соответственно, а также апостериорные вероятности $p(s|i)$ состояния $s$ при условии, что на предыдущем шаге первый игрок сделал ставку $i$.
Тогда вероятности $\sigma^s_{1,i}$ можно найти по формуле Байеса
\[
  \sigma^s_{1,i} = p(s|i)q_i/p(s), \: i = k, k + 1.
\]

Построим оптимальную стратегию инсайдера.
% Рассмотрим на $[0,1]$ множество $P$ точек вида
% \[
% \pEven[k] = k/m, \, k = \overline{0, m}, \quad \pOdd[k] = (k + \Co)/m, \, k = \overline{0, m - 1}.
% \]

Для $p = k/m,\ k = \overline{1, m-1}$ определим $\phi^0_k$ как распределение $\sigma^k_1$ с параметрами
\begin{align*}
  q_k = \Co,& \quad p(H|k) = (k-1+\Co)/m,\\
  q_{k+1} = \DCo,& \quad p(H|k + 1) = (k+\Co)/m.
\end{align*}
% Покомпонентно оно записывается как
% \begin{gather*}
%   \sigma^H_{1,k} = \frac{(k-\DCo)\Co}{k},\quad 
%   \sigma^H_{1,k+1} = \frac{(k+\Co)\DCo}{k},\\
%   \sigma^L_{1,k} = \frac{(m - k + \DCo)\Co}{m - k},\quad 
%   \sigma^L_{1,k+1} = \frac{(m - k - \Co)\DCo}{m - k}.
% \end{gather*}
Дополнительно определим $\phi^0_0$ как распределение, состоящее в применении ставки $0$ с вероятностью $1$, а $\phi^0_m$ -- как распределение, состоящее в применении ставки $m$ с вероятностью $1$.

Аналогично для $p = (k+\Co)/m,\ k = \overline{0, m-1}$ определим $\phi^\Co_k$ как распределение $\sigma^k_1$ с параметрами
\begin{align*}
  q_k = \DCo,& \quad p(H|k) = k/\Co,\\
  q_{k+1} = \Co,& \quad p(H|k + 1) = (k+1)/\Co.
\end{align*}
% Покомпонентно оно записывается как
% \begin{gather*}
%   \sigma^H_{1,k} = \frac{k\DCo}{k + \Co},\quad 
%   \sigma^H_{1,k+1} = \frac{(k+1)\Co}{k + \Co},\\
%   \sigma^L_{1,k} = \frac{(m - k)\DCo}{m - k - \Co},\quad 
%   \sigma^L_{1,k+1} = \frac{(m - k - 1)\Co}{m - k - \Co}.
% \end{gather*}

Для $p = \lambda (k+\beta)/m + (1-\lambda) (k+1)/m,\ \lambda \in (0, 1)$ обозначим через $\lambda \phi^\Co_k + (1-\lambda)\phi^\Co_{k+1}$ распределение, при котором первый игрок рандомизирует выбор ставок $k, k+1, k+2$ с параметрами
\begin{align*}
  q_k = \lambda\DCo, &\quad p(H|k) = k/m,\\
  q_{k+1} = \Co, &\quad p(H|k+1) = \lambda (k+1)/m + (1-\lambda) (k+\Co)/m,\\
  q_{k+2} = (1-\lambda)\DCo, &\quad p(H|k+2) = (k+1+\Co)/m.
\end{align*}

Для $p = \lambda k/m + (1-\lambda) (k+\Co)/m,\ \lambda \in (0, 1)$ через $\lambda \phi^0_k + (1-\lambda)\phi^\Co_k$ обозначим распределение, при котором первый игрок рандомизирует выбор ставок $k$ и $k+1$ с параметрами
\begin{gather*}
  q_k = \lambda\Co + (1-\lambda)(1-\Co),\enskip
  p(H|k) = \frac{\lambda\Co}{q_k} \frac{k-1+\Co}{m} + \frac{(1-\lambda)(1-\Co)}{q_k} \frac{k}{m},\\
  q_{k+1} = \lambda(1-\Co) + (1-\lambda)\Co,\enskip
  p(H|k+1) = \frac{\lambda(1-\Co)}{q_{k+1}} \frac{k+\Co}{m} + \frac{(1-\lambda)\Co}{q_{k+1}} \frac{k+1}{m}.
\end{gather*}

Следуя \cite{domansky07}, опишем рекурсивную структуру игры $G^m_n(p)$.
Стратегию $\sigma$ первого игрока в $n$-шаговой игре можно представить как $(\sigma_1, \sigma(i),\ i \in I)$, где $\sigma_1$ "--- ход первого игрока на первом шаге игры, а $\sigma(i)$ "--- стратегия в игре продолжительности $n-1$, зависящая от ставки $i$ на первом шаге.
Аналогично стратегию второго игрока можно представить как $(\tau_1, \tau(i),\ i \in I)$.
Тогда для функции выигрыша справедливо следующее представление
\begin{equation}
  \label{ch1:eq:recursive-structure}
  K^m_n(p,\sigma,\tau) = 
  K^m_1(p,\sigma_1,\tau_1) + \sum_{i \in I} q_i K^m_{n-1}(p(H|i),\sigma(i),\tau(i)).
\end{equation}

Отсюда получаем, что, определив одношаговую стратегию инсайдера для любого значения $p \in [0,1]$, можно рекурсивно продолжить ее применение на последующих шагах игры, тем самым определив стратегию в игре произвольной продолжительности.

Пусть при $\Co \in (0,1)$ стратегия $\sigma^*$ состоит в применении инсайдером описанных выше одношаговых стратегий для соответствующих значений апостериорной вероятности. 
Стратегия инсайдера при $\Co = 1$ найдена в~\cite{domansky07}.
При $\Co = 0$ стратегия может быть получена конструкцией замечания~\label{ch1:rem:symm-payoffs}.
Таким образом, стратегия $\sigma^*$ определена для всех значения $\Co \in [0,1]$.

Обозначим гарантированный выигрыш первого игрока в игре $G^m_n(p)$ при применении стратегии $\sigma^*$ через
\begin{equation*}
  L^m_n(p) = \min_{\tau \in \Tau} K^m_n(p,\sigma^*,\tau).
\end{equation*}
В работе показано, что функции $L^{m,\Co}_\infty(p)$ и $H^{m,\Co}_\infty(p)$ совпадают при всех значениях $p \in [0,1],\ \Co \in [0,1]$.

В \emphasis{разделе 1.6} даны теоремы о значении игры $G^m_\infty(p)$.
\begin{theorem}
  Игра $G^m_\infty(p)$ имеет значение $V^m_\infty(p) = H^m_\infty(p) = L^m_\infty(p)$.
  При этом $\sigma^*$ -- оптимальная стратегия первого игрока\textup{,} а $\tau^*$ -- оптимальная стратегия второго игрока.
\end{theorem}

\begin{theorem}
  При любом значении $p \in [0,1]$, $\Co \in (0,1)$ и $m \geq 3$ справедливо неравенство
  \begin{equation*}
    V^{m, \Co}_\infty(p) \geq V^{m,1}_\infty(p) = V^{m,0}_\infty(p),
  \end{equation*}
  причем равенство достигается только при $p = k/m, k = \overline{0,m}$.
\end{theorem}

\emphasis{Раздел 1.7} посвящен анализу случайных блужданий апостериорных вероятностей, возникающих при применении игроками оптимальных стратегий $\sigma^*$ и $\tau^*$.

\begin{theorem}
  Игра $G^m_\infty(p),\ p \in \{k_1/m, (k_2+\Co)/m,\ k_1 = \overline{0,m},\ k_2 = \overline{0,m-1}\},$ в среднем заканчивается за конечное количество шагов.
  Ее ожидаемая продолжительность выражается формулами
  \begin{equation*} 
    \tau(p_{2k+1}) = \frac{(m-k-\Co)(k+\Co)}{\Co \DCo},\quad
    \tau(p_{2k}) = \frac{k(m-k)}{\Co \DCo}.
  \end{equation*}
\end{theorem}

% \begin{table*}
%   \centering
%   \begin{tabular}{|c|c|c|}
%     \hline\hline
%     $i$ & $q_i$ & $p(H|i)$ \\
%     \hline
%     $k$
%         & $\lambda\Co + (1-\lambda)(1-\Co)$
%                 & $\frac{\lambda\Co}{q_k}\frac{k-1+\Co}{m} + \frac{(1-\lambda)(1-\Co)}{q_k} \frac{k}{m}$ \\
%     $k$ &
%           $\frac{\lambda(1-\Co)}{q_{k+1}}$
%                 & $\frac{\lambda(1-\Co)}{q_{k+1}} \frac{k+\Co}{m} + \frac{(1-\lambda)\Co}{q_{k+1}} \frac{k+1}{m}$ \\
%     \hline
%   \end{tabular}
%   \caption{capt}
%   \label{tab:t4}
% \end{table*}

% * Вторая глава
\emphasis{Вторая глава} посвящена исследованию дискретной модели рынка со счетным множеством состояний.
В \emphasis{разделе 2.1} дается формальное описание соответствующей повторяющейся игры.

Пусть множество состояний $S = \Z_+$.
Перед началом игры случай выбирает состояние рынка $\s \in S$ в соответствии с вероятностным распределением $\p = (p^s, \; s \in S)$, имеющим конечную дисперсию состояния $\D \p < \infty$.
Множество всех таких распределений обозначим $\MM$.

На каждом шаге игры $t = \overline{1,n}, \; n \leqslant \infty$, игроки делают ставки $i_t \in I, \, j_t \in J$, где $I = J = \Z_+$.
В силу того, что игрок, предложивший б\'{о}льшую ставку, покупает акцию у другого по цене, равной выпуклой комбинации предложенных ставок, выплата первому игроку в состоянии $s$ равна
\begin{equation*}
  \as(i_t, j_t) =
  \begin{cases}
    (1-\beta) i_t + \beta j_t - s, &\; i_t < j_t, \\
    0, &\; i_t = j_t, \\
    s - \beta i_t - (1-\beta)j_t, &\; i_t > j_t.
  \end{cases}
\end{equation*}

На шаге $t$ обоим игрокам достаточно принимать в расчет лишь последовательность $(i_1, i_2, \ldots, i_{t-1})$ действий первого игрока на предыдущих ходах.
Это связано с тем, что информация, получаемая вторым игроком относительно состояния $s$, может передаваться лишь посредством действий первого игрока.

Стратегией первого игрока является последовательность ходов (отображений) $\sigmav = (\sigma_1, \ldots, \sigma_n)$, где $\sigma_t: S \times I^{t-1} \rightarrow \Delta(I)$.
Множество стратегий первого игрока обозначим $\Sigma$.

Стратегией второго игрока является последовательность ходов (отображений) $\tauv = (\tau_1, \ldots, \tau_n)$, где $\tau_t: I^{t-1} \rightarrow \Delta(J)$.
Множество стратегий второго игрока обозначим $\Tau$.

При использовании игроками стратегий $\sigmav$ и $\tauv$ ожидаемый выигрыш первого игрока равен
\begin{equation*}
  \K(\p, \sigmav, \tauv) =
  \E_{(\p, \sigmav, \tauv)} \sum_{t=1}^n \as(i_t, j_t),
\end{equation*}
где математическое ожидание берется по мере, индуцированной $\p$, $\sigmav$ и $\tauv$ на множестве $S \times I^n \times J^n$.
Заданную таким образом игру обозначим $\theG(\p)$.

Если для некоторых стратегий $\sigmav^* \in \Sigma,$ $\tauv^* \in \Tau$ выполняются равенства
\begin{equation*}
  \inf_{\tauv \in \Tau} \K(\p, \sigmav^*, \tauv) =
  \K(\p, \sigmav^*, \tauv^*) =
  \sup_{\sigmav \in \Sigma} \K(\p, \sigmav, \tauv^*) \eqdef
  \V(\p),
\end{equation*}
то говорят, что игра $\theG(\p)$ имеет значение $\V(\p)$, а стратегии $\sigmav^*$ и $\tauv^*$
называются оптимальными.

Нижнее и верхнее значения игры $\theG(\p)$ обозначим соответственно
\begin{equation*}
  \LowV(\p) =
    \sup_{\sigmav \in \Sigma}
    \inf_{\tauv \in \Tau}
    \K(\p, \sigmav, \tauv), \quad
  \HighV(\p) =
    \inf_{\tauv \in \Tau}
    \sup_{\sigmav \in \Sigma}
    \K(\p, \sigmav, \tauv).
\end{equation*}
Данные функции являются вогнутыми на $\MM$.

В \emphasis{разделе 2.2} получена оценка сверху выигрыша первого игрока.

Следующие множества распределений зададим ограничениями на математическое ожидание состояния:
\begin{gather*}
  \Theta(x) = \left\{ \p \in \MM: \E \p = x \right\}, \\
  \Lambda(x, y) = \left\{ \p \in \MM: x < \E \p \leqslant y \right\}.
\end{gather*}

Пусть $\tauv^*$ --- стратегия второго игрока, состоящая в применении $\tau^k$ при $\p \in \Lambda(k-1+\beta,k+\beta)$.
Отметим, что при заданном распределении $\p$ выбор $k$ зависит от значения $\beta$.

\begin{theorem}
  \label{ch2:upper-bound:theorem}
  При использовании вторым игроком стратегии $\tauv^*$, выигрыш первого игрока в игре
  $\theG[\infty](\p)$ ограничен сверху функцией
  \begin{equation*}
    \High(\p) = \inf_{k \in J} \sum_{s \in S} p^s  h^s_\infty(\tauv^k).
  \end{equation*}
  Функция $\High(\p)$ является кусочно-линейной вогнутой с областями линейности $\Lambda(k - 1 + \beta, k + \beta)$ и областями недифференцируемости $\Theta(k+\beta)$ при $k \in S$.
  Для распределений $\p$ с $\E \p = k - 1 + \beta + \eta, \; \eta \in (0, 1]$, ее значение равно
  \begin{equation}
    \label{ch2:upper-bound:eq:H(p)}
    \High(\p) = \left( \D \p + \beta(1-\beta) - \eta(1-\eta) \right)/2.
  \end{equation}
\end{theorem}

В \emphasis{разделе 2.3} получена стратегия первого игрока, гарантирующая ему выигрыш не менее $\High(\p)$.

Пусть $\sigma^s_i$ --- компонента хода $\sigma$ первого игрока, т.е. вероятность сделать ставку $i$ в состоянии $s$.
По правилу Байеса $\sigma^s_i = p^{s|i} q^i / p^s$.
В частности, справедливы равенства $\sum_{s \in S} \sigma^s_i p^s = q^i,\ i \in I$.
Таким образом, ход $\sigma$ первого игрока можно определить, задав следующие параметры: полные вероятности $q^i$ сделать ставку $i$ и апостериорные вероятности $p^{s|i}$ для $i \in I$.
Тогда его одношаговый выигрыш выражается следующим образом:
\begin{equation}
  \label{ch2:lower-bound:eq:K1(q,pi)}
  \K[1](\p, \sigma, j) = \sum_{i \in I} \sum_{s \in S} q^i p^{s|i} \as(i, j).
\end{equation}

Обозначим $\Low[n](\p, \sigmav)$ гарантированный выигрыш первого игрока, использующего стратегию $\sigmav$ в игре $\theG[n](\p)$, т.е.
\[
  \Low[n](\p, \sigmav) = \inf_{\tauv \in \Tau} \K[n](\p, \sigmav, \tauv).
\]
\begin{lemma}
  \label{ch2:lower-bound:lemma:convex-combination}
  Пусть $\p_1, \p_2 \in \MM$, $\sigmav_1, \sigmav_2 \in \Sigma$ --- стратегии первого игрока.
  Тогда для $\p = \lambda \p_1 + (1-\lambda) \p_2,\ \lambda \in [0, 1],$ найдется такая стратегия $\sigmav_c \in \Sigma$, что
  \[
    \Low[n](\p, \sigmav_c) \geqslant
    \lambda \Low[n](\p_1, \sigmav_1) + (1-\lambda) \Low[n](\p_2, \sigmav_2).
  \]
\end{lemma}

Обозначим $e^s$ вырожденное вероятностное распределение с носителем в точке $s$.
Пусть $\p^x(l, r) \in \Theta(x)$ --- распределение с носителем $\{l, r\},\ l<r$.
При этом распределении вероятности реализации состояний $l$ и $r$ равны $(r-x)/(r-l)$ и $(x-l)/(r-l)$ соответственно, а дисперсия
\[
  \D \p^x(l, r) = (x - l)(r - x).
\]
Любое распределение $\p = (p^s,\ s \in S) \in \Theta(x)$ может быть представлено в виде выпуклой комбинации распределений с двухточечными носителями следующим образом:
\begin{gather}
  \label{ch2:lower-bound:eq:prob-decomp-sum}
  \p = \begin{cases}
    \displaystyle
    p^x e^x + \sum_{r=x+1}^\infty \sum_{l=0}^{x-1} \alpha_{l,r}(\p) \p^x(l, r),\ & x \in S,\\
    \displaystyle
    \sum_{r=\floor{x+1}}^\infty \sum_{l=0}^{\ceil{x-1}} \alpha_{l,r}(\p) \p^x(l, r),\ & x \notin S,\\
  \end{cases}\\
  \alpha_{l,r}(\p) = (r-l) p^l p^r / \sum_{t=0}^{\ceil{x-1}} p^t (x-t). \nonumber
\end{gather}

Обозначим через $\LL$ банахово пространство последовательностей $(l^s,\ s \in S)$ с нормой $\norm{l} = \sum_{s = 0}^\infty s^2 |l^s|$.
Множества $\MM$ и $\Theta(x)$ являются выпуклыми замкнутыми подмножествами пространства $\LL$.

\begin{lemma}
  \label{ch2:lower-bound:lemma:decomp-convergence}
  Для любого распределения $\p \in \Theta(x)$ ряд в разложении (\ref{ch2:lower-bound:eq:prob-decomp-sum}) сходится к $\p$ по норме.
\end{lemma}

В силу того, что функционал $\LowV(\p)$ вогнут на $\MM$ и по теореме~\ref{ch2:upper-bound:theorem} ограничен на данном множестве, то он непрерывен на $\MM$.
Отсюда и из леммы~\ref{ch2:lower-bound:lemma:decomp-convergence} следует, что для распределений $\p \in \Theta(x)$ выполнено
\begin{equation*}
  \left\{
  \begin{aligned}
    \LowV(\p) &\geqslant
      p^x \LowV(e^x) + \sum_{r=x+1}^\infty \sum_{l=0}^{x-1} \alpha_{l,r}(\p) \LowV \left( \p^x(l, r) \right),&\ x \in S,\\
    \LowV(\p) &\geqslant 
      \sum_{r=\floor{x+1}}^\infty \sum_{l=0}^{\ceil{x-1}} \alpha_{l,r}(\p) \LowV \left( \p^x(l, r) \right),&\ x \notin S.
  \end{aligned}
  \right.
\end{equation*}

Из данных неравенств, теоремы~\ref{ch2:upper-bound:theorem} и леммы~\ref{ch2:lower-bound:lemma:convex-combination} следует, что для доказательства совпадения верхней и нижней оценок выигрыша в игре $\theG[\infty](\p)$ можно ограничиться рассмотрением только распределений %
$\p = \p^{k+\beta}(l, r) \in \Theta(k + \beta), \; k \in S,\ l = \overline{0, k},\ r = \overline{k+1, \infty}$.
Для таких распределений мы построим стратегию первого игрока $\sigmav^*$, для которой $\Low[\infty](\p, \sigmav^*) = \High[\infty](\p)$.
Отсюда будет следовать, что $\V[\infty](\p)~=~\High[\infty](\p)$, а $\sigmav^*$ и $\tauv^*$ --- оптимальные стратегии игроков в игре $\theG[\infty](\p)$.

Обозначим $\sigmak_k$ ход первого игрока, состоящий в выборе ставки из множества $\{k, k+1\}$.
Ход $\sigmak_k$ определяется заданием полных вероятностей $q^k, q^{k+1}$ и апостериорных распределений $\p^k, \p^{k+1}$, причем $q^k + q^{k+1} = 1$.

Определим стратегию $\sigmav^*$ первого игрока в игре $\theG[\infty](\p)$.
Введем множество распределений
\begin{equation*}
  P(l,r) = \left\{
    \p^k(l, r), \, \p^{s+\beta}(l, r), \, k = \overline{l,r}, s = \overline{l,r-1}
  \right\}.
\end{equation*}
При $\p \in P(l,r)$ первый ход $\sigma^*$ стратегии $\sigmav^*$ определяется следующим образом.
Если $\p = \p^l(l,r)$ или $\p = \p^r(l,r)$, то первый игрок использует ставки $l$ и $r$, соответственно, с вероятностью 1.
В противном случае он использует $\sigmak_k$ с параметрами из таблицы~\ref{ch2:tab:insider-strategy}.

\begin{table}[htb]
  \centering
  \renewcommand{\arraystretch}{1.5}
  \captionsetup{width=12cm}
  \caption{Параметры хода $\sigma^*$ при $\p \in P(l, r)$}
  \label{ch2:tab:insider-strategy}
  \begin{tabular}{|P{2cm}||P{2cm}|P{2cm}|P{2cm}|P{2cm}|}
    \hline
    \hline
    $\p$                 & $q^k$     & $q^{k+1}$ & $\p^{k}$               & $\p^{k+1}$           \\ \hline
    $\p^k(l, r)$         & $\beta$   & $1-\beta$ & $\p^{k-1+\beta}(l, r)$ & $\p^{k+\beta}(l, r)$ \\ \hline
    $\p^{k+\beta}(l, r)$ & $1-\beta$ & $\beta$   & $\p^k(l, r)$           & $\p^{k+1}(l, r)$     \\
    \hline
    \hline
    \multicolumn{1}{c}{}
    \vspace{-2.5em}
  \end{tabular}
\end{table}

На последующих шагах игры ход $\sigma^*$ применяется рекурсивно для соответствующих значений апостериорных вероятностей.
В результате определили стратегию $\sigmav^*$ для распределения $\p \in P(l,r)$.

Для произвольного распределения $\p \in \Theta(k),\ k \in S$, стратегию $\sigmav^*$ определим следующим образом.
Если реализуется состояние $s = k$, то гарантированный выигрыш первого игрока не превышает $0$ и он прекращает игру.
Таким образом, первый игрок, следуя стратегии $\sigmav^*$, прекращает игру с вероятностью $p^k$.
В противном случае игрок использует конструкцию леммы~\ref{ch2:lower-bound:lemma:convex-combination} для построения стратегии, соответствующей выпуклой комбинации распределений $\p^k(l, r)$ в разложении $\p$.
Первый ход такой стратегии использует две ставки $k$ и $k+1$ с полными вероятностями $(1-p^k)\beta$ и $(1-p^k)(1-\beta)$ соответственно.
Апостериорные вероятностные распределения являются выпуклыми комбинациями соответствующих апостериорных двухточечных распределений и даются следующими формулами:
\begin{gather*}
  \p^k = \frac{1}{1-p^k} \sum_{r=k+1}^\infty \sum_{l=0}^{k-1} \alpha_{l,r}(\p) \p^{k-1+\beta}(l, r), \\
  \p^{k+1} = \frac{1}{1-p^k} \sum_{r=k+1}^\infty \sum_{l=0}^{k-1} \alpha_{l,r}(\p) \p^{k+\beta}(l, r).
\end{gather*}
Для распределений $\p$ со счетным носителем сходимость по норме данных рядов устанавливается аналогично доказательству леммы~\ref{ch2:lower-bound:lemma:decomp-convergence}.
Аналогичные рассуждения справедливы и для распределений $\p \in \Theta(k+\beta) \cup \Lambda(k, k+\beta),\ k \in S$.

В диссертации показано, что для $\p \in P(l,r)$ значения $\Low[\infty](\p, \sigmav^*)$ и $\High[\infty](\p)$ совпадают.

В \emphasis{разделе 2.4} дана теорема о значении игры $\theG[\infty](\p)$.
\begin{theorem}
  \label{ch2:solution:theorem}
  Игра $\theG[\infty](\p)$ имеет значение
  \[
    \V[\infty](\p) = \High(\p) = \Low(\p),
  \]
  а $\sigmav^*$ и $\tauv^*$ --- оптимальные стратегии игроков.
\end{theorem}

В \emphasis{разделе 2.5} приведена вторая оптимальная стратегия инсайдера $\xiv^*$.
Введем множество распределений %
\begin{equation*}
  P'(l,r) =
  \{\p^l(l, r), \p^r(l, r)\}
  \cup
  \left\{
    \p^{k+\beta}(l, r), \, k = \overline{l, r-1}
  \right\}.
\end{equation*}
При $\p \in P'(l,r)$ первый ход $\xi^*$ стратегии $\xiv^*$ определяется следующим образом.
Если $\p = \p^l(l,r)$ или $\p = \p^r(l,r)$, то первый игрок использует ставки $l$ и $r$ соответственно с вероятностью 1.
В противном случае он использует $\sigmak_k$ с параметрами из таблицы~\ref{ch2:tab:insider-strategy2}.
\begin{table}[htb]
  \centering
  \renewcommand{\arraystretch}{1.5}
  \captionsetup{width=12cm}
  \caption{Параметры хода $\xi^*$ при $\p \in P'(l, r)$}
  \label{ch2:tab:insider-strategy2}
  \begin{tabular}{|P{2cm}||P{2cm}|P{2cm}|P{2cm}|P{2cm}|}
    \hline
    \hline
    $\p$                   & $q^k$ & $q^{k+1}$                 & $\p^{k}$                & $\p^{k+1}$                                      \\
    \hline
    $\p^{l+\beta}(l, r)$           & $\frac{1}{1+\beta}$       & $\frac{\beta}{1+\beta}$ & $\p^l(l, r)$           & $\p^{l+1+\beta}(l, r)$ \\
    \hline
    $\p^{r-1+\beta}(l, r)$         & $\frac{1-\beta}{2-\beta}$ & $\frac{1}{2-\beta}$     & $\p^{r-2+\beta}(l, r)$ & $\p^r(l, r)$           \\
    \hline
    $\p^{k+\beta}(l, r)$   & $\frac{1}{2}$             & $\frac{1}{2}$           & $\p^{k-1+\beta}(l, r)$ & $\p^{k+1+\beta}(l, r)$  \\
    \hline
    \hline
    \multicolumn{1}{c}{}
    \vspace{-2.5em}
  \end{tabular}
\end{table}

Для остальных распределений $\p$ стратегия $\xiv^*$ определяется аналогично тому, как это было сделано для стратегии $\sigmav^*$.

Использование стратегии $\xiv^*$ при $\p \in P'(l, r)$ порождает случайное блуждание последовательности апостериорных вероятностей.
Данное случайное блуждание симметрично с вероятностями перехода в соседние состояния равными $1/2$, симметрия нарушается только в крайних и соседних к ним состояниях.

% * Третья глава
\emphasis{Третья глава} посвящена исследованию 

% * Conclusion
В \emphasis{заключении} приведены основные результаты работы, которые заключаются в следующем:
\input{common/concl}

%\newpage
% При использовании пакета \verb!biblatex! список публикаций автора по теме
% диссертации формируется в разделе <<\publications>>\ файла
% \verb!../common/characteristic.tex!  при помощи команды \verb!\nocite! 

\ifdefmacro{\microtypesetup}{\microtypesetup{protrusion=false}}{} % не рекомендуется применять пакет микротипографики к автоматически генерируемому списку литературы
\ifnumequal{\value{bibliosel}}{0}{% Встроенная реализация с загрузкой файла через движок bibtex8
  \renewcommand{\refname}{\large \authorbibtitle}
  \nocite{*}
  \insertbiblioauthor                          % Подключаем Bib-базы
  %\insertbiblioother   % !!! bibtex не умеет работать с несколькими библиографиями !!!
}{% Реализация пакетом biblatex через движок biber
  \insertbiblioauthor                          % Подключаем Bib-базы
  \insertbiblioother
}
\ifdefmacro{\microtypesetup}{\microtypesetup{protrusion=true}}{}


%%% Local variables:
%%% mode: latex
%%% TeX-master: "../synopsis"
%%% End:
